

\maketitle


\abstract{An understanding of structuralist philosophical foundations for physics as \emph{idealist} rather than \emph{realist} is warranted. I aim to reconstruct and understand justification for such a position by examining texts from influential proponents like Eddington, Cassirer, and Weyl among others.  I will pursue this research project using quantum probabilities as a first case study of an example where \emph{structural idealism} may make more sense than structural realism or alternatives like ``participatory realism'' (which might represent more of a difference in terminology and historical coherence than a difference in substance).  

I will attempt to argue that structural idealism is not only consistent with a Bayesian approach to quantum probabilities, it bolsters Bayesian accounts of probability generally by showing why they are \textbf{epistemologically compelling beyond traditional normative accounts}.  This is arguably a central point of Eddington's ``selective subjectivism'', which can be considered an influential and early view of structural realism because of the focus on group structures central to an agent's phenomenological experience. However, Eddington contends that the position is \emph{idealist}, and so I think a position of this sort can justifiably be characterized as \emph{structural idealism}.  

At present I believe I have also identified an interesting second case study, that of open systems as advocated for in Hartmann and Cuffaro.  Currently I have identified several passages from Hermann Weyl's work which seem to support an open systems view.  This view might be compared also with other notions from transcendental idealism and process philosophy.

%One central aspect of the project will be to compare this view with what has been called participatory realism, and how one might find additional support for a Bayesian view of quantum probabilities.  

So, while it is clear that Eddington's and Weyl's views are central to this project, I will also follow relevant leads in the work of Poincare, Cassirer, and perhaps Husserl and Brouwer among others (although not sure how deep into the philosophy of math I need to go).  I expect there might be good reason to expand beyond, but to begin with I will prioritize to avoid scope creep. Secondary literature discussing this cluster of idealist views (which is arguably consistent with Eddington's) will also be prioritized, for example the extensive discussion by Ryckman in the context of relativity theory, and I would like to know to what extent I can apply the views for the case studies.}


\tableofcontents

%\abstract{Empirical data may be theory laden, but theories can be local or non-local.  This presents a problem of locality underdetermination for empiricism.  Not only could it be that there are other local theories which are consistent with the data, there can also be non-local theories.  The problem is worse: a correct theory could be non-local and normatively force our empiricism to be non-local as well.  What does this mean?  Either (i) empiricism has to revise itself to accommodate the reality, that seemingly local events are actually informative of other non-distinct (yet apparently distinct) separate events, or (ii) it would cleave in two with different domains or branches of empiricism.  Naturally, (ii) is not an option.  I discuss some history of why both relativity and quantum theory have practically redefined empiricism, and discuss why (i) is tenable. }



\section{How to Read This Document}

\textbf{This document is a work in progress, and very rough around the edges.} I am updating it when I have time to work on it, and pushing version updates to a github repository.  Much of the content is currently typed out quotes from literature and my notes.  No doubt a lot will need to be corrected.  In this document I am trying to outline where I am at, and where there are still open questions I would like to address.  I am sure some of my open questions have been addressed in the literature, but I am including an honest status of my project in the interests of transparency and completeness.  

\textbf{The material in this document are not final, actively under construction, and where original comments are made, is copyright Cameron Beebe, The SciPhi Initiative, LLC, $\braket{\texttt{sci}|\texttt{phi}}_i$.}




\subsection{Generative Model Affidavit}

I, Cameron Beebe, swear none of the text in this report was the result of prompting a generative model, such as ChatGPT.  As far as I can tell, the content was generated wholly or nearly wholly by my own biological neural nets, and any interactions I have had with a generative model were not particularly insightful or meaningful with respect to the overall content, direction, and literature that is discussed.  (In fact, to the contrary, I have been sent on a wild goose chases after an article that did not exist...)

\section{Project Outline}




Within the overarching framework of the cluster of ideas we might summarize as ``structural idealism'', I think it is warranted to compare what is now called participatory realism in the context of quantum bayesianism with the position advocated by Eddington (and also Cassirer, Weyl, and Husserl as discussed in \cite{Ryckman2005}).  What Eddington called ``selective subjectivism'', for example, should be explicitly be compared detail by detail with participatory realism. 


\subsection{Literature}

I've already had a first pass over a few of these, and determined there may be a payoff to spend more time on them in the light of the scope of this proposal.  I am also omitting literature in my personal library on philosophy/foundations of physics, thus I'm listing literature that is new to me. 

\subsubsection{Read or Underway}

The core of the ideas in this proposal stem from a long-time interest in the philosophy and foundations of quantum theory, as well as recent discussions on idealism with Ryan Mulally, and the (potential) connections between Husserl and Hegel and the views of Errol Harris.  The literature I have prioritized so far on this project:

\begin{itemize}
    \item \cite{Poincare1952} \checkmark
    \item \cite{Eddington1939} \checkmark
    \item \cite{Ryckman2005} $\sim \frac{1}{2}$
    \item \cite{Harris1965} $\sim \frac{1}{2}$
    \item \cite{Weyl1949} $\sim \frac{1}{2}$
    \item \cite{Cassirer1927} $\sim \frac{1}{2}$
    \item \cite{Riezler1940} \checkmark
    \item \cite{Carnap1966} \checkmark
    \item \cite{KantProlegomena} $\sim \frac{1}{2}$
\end{itemize}


\subsubsection{Prospective and Supplementary}

As I've done preliminary searching for relevant literature on the project, the following have stood out as important for me to become familiar with. Some I may have read previously but will re-read

\begin{itemize}
    \item M. Cuffaro papers re: Kant/Idealism/Quantum
    \item Fuchs et al on ``participatory realism''
    \item Weyl collection of papers
    \item \cite{SchilppCassirer}, e.g. II.1-II.8, II.21-II.23
    \item \cite{Adorno1940}
    \item \cite{Clifford1878}
    \item \cite{Ewing1934}
    \item \cite{Kilmister1994}
    \item Atmanspacher and Rickles
    \item \cite{Cartwright1983}
    \item \cite{Torretti1999}
    \item van Atten book Brouwer meets Husserl
    \item Husserl Crisis Collection
    \item \cite{Zahar2001}
    \item \cite{Zahar2007}
    \item \cite{Kelsen1946} e.g. Ch. 6



\end{itemize}




\subsection{Deadlines for Papers}

\begin{itemize}
    \item Nov. 15, 2024 \href{https://link.springer.com/collections/cabhjbifbf}{Perspectivism and Quantum Mechanics Collection}
\end{itemize}




\subsection{Structural -isms}


The story or dialectical summary that was uncritically familiar to me was that structural realism is a potential route for the scientific realist to respond to the pessimistic meta-induction (PMI).  Scientific theory changes, and so the entities or objects referred to by the theory should better be taken lightly, or as useful fictions, or else we should expect to be disillusioned just as we have been in the past for previous theory referents.  Humors, phlogiston, and luminiferous aether are typically given examples of theoretical objects that scientists once (mistakenly) thought corresponded to \emph{real} objects \emph{in the world}.

So, if we want to justifiably believe in some objects, which are rather permanent entities that potentially carry the veridical load of our scientific attention, the objects should be somewhat immune to shifts in that attention over time.  The focus of our beliefs should therefore be adjusted towards the invariant referents.

Thus, the realist, wanting to uphold the referential connection between theory and reality independent of any particular individual's beliefs or changes in theoretical perspective, focuses attention on the relational objects devoid of individuality.  Like turning a kaleidoscope until the edges all line up and the image is distorted the least, the realist supposes that the structural beliefs have lodged themselves into the joints of the real world like a cam.  Whatever way our theoretical perspectives may shift, the cams will stay lodged in the bedrock of reality.

Surely these invariant footholds in reality, which we have good reason to suppose will persist through theory change, are the prime candidates to be realists about.

It is a nice story, and it is one that I am sure many like myself would find compelling like the narrative of a fairy tale is compelling.  But, of course, the fairy tale is full of untruths, exaggerations, and absurdities, assuming that the frame of mind of the reader will be detached enough.  The reader knows there is a distance between reality (whatever that may be) and the fiction depicted.  Is there such a gap in structural realist stories?

The purpose of this project is to take a look at how 

\subsubsection{OSR vs. ESR}

Two strains that seem to be obvious.  Ontic Structural Realism.  Epistemic Structural Realism.

Structural Idealism tries to split the difference.




\subsubsection{From Structural Realism to Selective Subjectivism}

Eddington's group theoretical structuralism is combined with a `subjective' or mental apprehension fundamental to the structure's existence.  In other words, if one is trying to be a realist about these structures, for Eddington, then one is asserting the existence of properties in the mind.  These properties are about the world, but they are only \emph{in} the world to the extent that the world is constituted \emph{in} the mind.  [CITE FRENCH]  

One could perhaps distinguish between external structural realism, and internal structural realism.  I'm not sure that the external picture makes sense, and neither would Eddington.  If one is going to assert fundamental structural properties about the world, it seems to make little sense to locate these properties externally.  

Is this an inescapable slide into a form of idealism?  Can a structural realist stop at a realist position about structures in the phenomenological border of experience?  An empiricist like van Fraassen would, presumably, very much like to find pragmatic reasons to stop not just at the border for \emph{external} existence of objects, but also \emph{internal} or \emph{idealist} objects (whether these objects are structural or not).  [CITE LADYMAN]

If `entities' as they appear to us are defined by (or constituted from) their group structure, as defined mathematically, it seems hard to separate the existence of the theoretical process of the mind in this construction from the apparently external world that supposedly instantiate these structures.  In this sense, the idealist (as I am reconstructing tentatively) simply takes seriously the phenomenological border, and this drives not just Eddington but others as well to see it as \emph{necessary} to formulate physics in a rationalist or idealist fashion.  

The relations which can be characterized by group operations (e.g. transformational symmetries) are held and understood by a mind, and this mind is what constitutes the symmetries, shifting the epistemological burden onto the empiricist, onto the external structural realist, onto the anti-realist of various stripes.  Structural idealism, as exemplified by Eddington, can be considered a form of structural realism, but it aims for even more metaphysical consistency.  

While there have been objections to Eddington's particular application of these philosophical and metaphysical motivations, he was not by any means alone in pursuing this strategy.  



Cassirer

\subsection{Objective vs. Subjective Idealism}

DOES THIS MAKE SENSE

Idealism, in the present context, should not be confused as identical with some fundamental subjectivism or skepticism about the external world (or even solipsism).

Certain strains of idealism identify substance as being a more sophisticated form of universal \emph{Mind}.  I am not an expert, but it is obvious enough on a first pass that many positions are perfectly fine with there being a substance, and unifying the nature of that substance with the apparent subjective nature of the mind in e.g. a physicist's mind.  Whether this is tenable and coherent is beyond the current proposal, but there are attempts (e.g. [HEGEL PROBABLY]).

I see an analogy with subjective vs objective Bayesianism.  While ultimately both positions can define probabilities as subjective degrees of belief, it is not incoherent to say that there are properties of `the world' (as it is, or as experienced) which should be reflected by any agent's DoB.  I.e., there are, in an important sense, \emph{objective} subjective degrees of belief.  There are certain distributions, properties, or relations that \emph{will hold} because of rational constraints regardless of whether these rational conditions are concerned with reality as it is or as it is experienced.



\subsection{Weyl and Transcendental-Phenomenological Idealism}

Perhaps we can characterize positions regarding quantum foundations also along the lines of the foundations of mathematics as outlined by Weyl:

\begin{quote}
    The stages through which research in the foundations of mathematics has passed in recent times correspond to the three basic possibilities of epistemological attitude.  The set-theoretical approach is the stage of \emph{naive realism} which is unaware of the transition from the given to the transcendent.  Brouwer represents \emph{idealism}, by demanding the reduction of all truth to the intuitively given.  In axiomatic formalism, finally, consciousness makes the attempt to `jump over its own shadow,' to leave behind the stuff of the given, to represent the \emph{transcendent}---but, how could it be otherwise?, only through the \emph{symbol}.  Basically, the idealist viewpoint in epistemology has been adhered to by occidental philosophy since Descartes; nevertheless, it has searched again and again in metaphysics for an access to the realm of the absolute, and Kant, who meant to shoot the bolt once and for all, was yet followed by Fichte, Schelling, and Hegel.  It cannot be denied that a theoretical desire, incomprehensible from the merely phenomenal point of view, is alive in us which urges toward totality. Mathematics shows that with particular clarity; but it also teaches us that that desire can be fulfilled on one condition only, namely, that we are satisfied with the symbol and renounce the mystical error of expecting the transcendent ever to fall within the lighted circle of our intuition.  So far, only in mathematics and physics has symbolical-theoretical construction gained that solidity which makes it compelling for everyone whose mind is open to these sciences.  Their philosophical interest is primarily based on this fact.

    \citep[p. 65-66]{Weyl1949}
\end{quote}




Ryckman explains Husserl briefly in 5.3, noting Husserl also distinguishes phenomenology (as a form of idealism: transcendental-phenomenological idealism) is very different from e.g. Berkeleyan subjective idealism.


\section{Structural \emph{Idealism}}

Many associate one of the first explicit structural realists in the work of Eddington, who talks about the group theory structure of experience.  These structures are persistent and indicate somehow some  (Kantian?) transcendental reality that is intersubjective.  However, in chapter 7 of \cite{Ryckman2005}, he argues (as anyone should after reading Eddington's \cite{Eddington1939}) that it is perhaps not correct to try to pull Eddington's views into the modern tent of structural \emph{realism}.  Rather, it is explicitly idealist.  

So the objects in our scientific theories, including the formal mathematical objects, and their reference to the world, are expressed not in realist terms but in idealist ones.  It isn't that the persistent group structures correspond in some important way to the real structure of the (external) world, but that they are epistemologically normatively compelling from the lights of a subjective agent.  The structure is composed of relations partly or wholly determined by the subjective mind, but rejecting solipsism they are intersubjective for other minds, and this intersubjectivity is the core of the persistent structure that is synthesized from a complex of agents.  Structural realist persistence of course supposes t



Consider, as Ryckman does for Cassirer, Weyl, and Eddington in the context of relativity, that quantum probabilities may be of a similar status.  They are subjective in Eddington's sense, and in the sense of Bayesian subjective degrees of belief, but they are also synthetic or ideal in the sense that they are not arbitrary and they are intersubjective in important ways.  They are synthetic objects in the sense that if they refer, they refer to the structure of the physical world which is (per Eddington) an ideal and subjectively determined structure (physical knowledge is a subset of general knowledge which are all determined by conscious experience first and foremost).  And not necessarily to the actual physical world, and they do so in virtue of their synthetic mind-dependent character and not because they correctly pick out 





\subsection{Neo-Kantianism?}

For sake of brevity, I am lifting a hasty summary from Ladyman:


\begin{quote}
    The subtler idealism of Kant is a more palatable strategy aimed at avoiding scepticism.  Whereas Berkeley collapses the external world onto our impressions to solve the problem of how we get from knowledge of the latter to knowledge of the former, Kant agrees with metaphysical realists that there is a mind-independent world, but he agrees with sceptics that we can't have knowledge of it.  Instead, he argues, all our knowledge is of the world as it is \emph{for us}.  The world in itself he calls the \emph{noumenal} world, and the world as we experience it he calls the \emph{phenomenal} world.  Much of our knowledge is of particular facts about the phenomenal world learned through the senses, but Kant thought that some of our knowledge is \emph{a priori}.  Although we can only know the measurements of a specific triangle through our senses, we can know that any triangle we experience will have internal angles summing to $180^\circ$, by the use of reason alone.  According to Kant, arithmetic, geometry, and Newtonian mechanics are \emph{a priori} forms of knowledge, not about the noumenal world, but about the form our experience must take.  \citep[p. 146]{Ladyman2002}
\end{quote}



\subsection{Poincar\'e}




\subsection{Cassirer}

\subsubsection{Schilpp}

\begin{quote}
    The transition from the level of sense impressions to the mediated world of spatial representations is made possible by the fact that within the sequence of fluctuating impressions certain constant relations can be fixed and defined and can be asserted as something permanent and independent of the flux itself.  Each impression must then prove its objective significance by becoming an integral element of these relations or, rather, of the totality or the system of these relations.  Its fusion into the systemic context, and this alone, gives objective meaning to the individual impression.  From the very first, every formation of concepts, irrespective of the field in which it is carried through, points toward one ultimate goal, the one goal of all cognition, namely, the fusion of all specific ``positings,'' of all particular conceptual structures, into one unique and univocal all-comprehensive context of thought.  This complete synthesis, this absolute systemic unity, is the goal and driving force impelling the process of cognition---and it is this for Cassirer no less than for Natorp and Cohen.  Only at the end of the process of integration is the object of experience fully determined, and only then has truth, absolute and unchanging truth, been attained.  

    However, before the contents of experience can be integrated as here demanded they must be transformed.  The ``sense data'' or ``immediate impressions'' must be ``resolved'' into elements of theoretical thinking.  They must be ``posited'' as such elements.  Without this transformation, carried through most effectively in the physical sciences, it would be impossible to formulate the laws which describe and determine the context of experience.  And without attaining at least in some measure the systemic unity according to law we could not even speak about ``nature.''  ``Nature''---for Cassirer as well as for Natorp---is the unity according to law, the systemic context of all particulars in experience, the totality of progressive integration and objective determination of the ``objects'' of experience.  

    In the field of physics the ``transformation'' referred to involves a change from the quale of immediate impressions to concepts of measure and number.  The laws of physics are stateable only with respect to such transformed ``objects.''  And, \emph{vice versa}, the significance of an ``object'' \emph{as object} now depends exclusively upon the clarity and univocality with which it reflects or represents the law or the determinateness of the context, upon its inclusion within a system of law.  Cassirer and Natorp would agree on this point.  They differ, however, in their reference to the specific laws determining the content.  Natorp based his interpretation exclusively upon Newtonian mechanics; Cassirer, on the other hand, took into consideration more recent developments in the field of physics.  For Natorp, ``existence'' means the complete and absolute determination of an ``object'' with respect to space and time.  Cassirer, contemplating the conclusions reached by quantum mechanics, knows that such complete determination is impossible even in theory, and that we must rest satisfied with a less rigid demand.  Let us follow Cassirer's arguments in greater detail.  

    Cassirer finds that quantum mechanics has confirmed rather than disproved the general position of the neo-Kantians.  At least it has cut the ground from under all realistic interpretations of reality.  ``Things'' no longer provide the starting-point of cognition but are the ultimate goal of our interpretations.  Laws can no longer be derived from ``things'' through a process of abstraction; they constitute the basis upon which alone we can assert the existence of ``things.''  The concept of law is logically prior to the concept of thing.  Our knowledge of ``nature'' extends only so far as does our concept of law.  Objective ``reality'' can be asserted only in so far as there is order in accordance with law.  ``Things'' are the ``limit,'' the ultimate goal toward which the process of cognition moves but which it never actually reaches.  The ``object'' of experience is not something completely determined in itself but something determinable without end in the process of cognition.  Except through the medium of laws, no ``object'' is ``given'' or known.

    So far Cassirer is in complete agreement with Paul Natorp.  But, whereas Natorp believed that Newtonian mechanics provided the means, in principle, for a complete determination of an object in space-time, Cassirer points out that this thesis involves an over-simplication of the facts.  ``Field'' theories, the phenomena of ``entropy,'' and the ``uncertainty relations'' of quantum mechanics involve problems which cannot be solved within the framework of classical mechanics.

    ``Fields of forces,'' for example, are not ``entities'' in the classical sense of ``material bodies.''  As far as such ``fields'' are concerned, ``mass'' can no longer be regarded as ``ponderable reality'' but must be resolved into electric ``charges.''  The whole conception of a ``physical body'' must therefore be redefined.  The ``field'' is not a ``thing,'' but a ``system of effects.''

    Similarly, the ``atom'' can no longer be conceived as a ``thing.''  It has turned out to be an intricate ``system'' of dynamic relations and can be described only through the laws which express its effects.  To assert that ``electrons'' exist within the atom and that they move in definite orbits actually means only that certain laws, formulated to describe observable phenomena of cathode rays and line spectra, are valid; that they are descriptive of the phenomena.  Neither the ``electrons'' nor their ``orbits'' are ``things-in-themselves,'' mere ``stuff,'' ``given'' to us prior to cognition.  They are, rather, terminals within the integrative process of cognition.  The electron ``exists'' only relative to a ``field,'' relative, that is, to a ``system of effects,'' and as a particular ``place'' of that field.  

    The laws of classical mechanics are so formulated that they are valid only under two assumptions.  First, all physical objects must be reducible to mass-points; and, second, these mass-points must be definitely localizable in space at any given time and with any given momentum.  Quantum mechanics shows, however, that it is impossible to determine the exact location of an electron if we determine its momentum at the same time with an accuracy required by the classical laws.  The impossibility here involved is not merely of a practical nature but is one in principle.  We must therefore conclude that the individuality of an electron can no longer be defined or determined as that of a ``thing'' in space and time.  If we continue to speak about individual electrons we can do so only indirectly.  That is, we can speak of their ``individuality,'' not as something ``given,'' but only as constituting specific focal points of relations, ``intersections'' within a system of effects.  All formulations of quantum mechanics are systemic formulations concerning functional dependencies, not statements concerning individual ``things'' called ``electrons.''  \citep[p. 773-776]{WerkmeisterCassirer}
\end{quote}


\subsubsection{The Individual and the Cosmos in Renaissance Philosophy}

Cassirer expositing Cusanus' philosophy.  Platonic division/duality (can't get to ideal form from empirical, but appearances point to form).  Sensible/intelligible.



\begin{quote}
    A physical circle or sphere never corresponds to the pure concept of either but rather must necessarily remain far behind it.  We can refer the physical to the ideal; we can determine that a given, visible being corresponds with greater or less exactitude to the concept of the sphere or of the circle which is invisible \emph{per se}.  But the essential difference between archetype and copy can never be overcome.  For what characterizes the pure truth of the archetype is precisely that it can never be `more' or `less'.  To take away or to think away even the tiniest part of it is to destroy it in its essence.  The sensible, on the other hand, not only suffers indeterminateness, but possesses therein its very nature.  Insofar as being is attributable to it, the sensible `is' only within this limitlessness of becoming, in this oscillating between being this-way and being that-way.  \citep[p. 21]{Cassirer1927}
\end{quote}

Cusanus talks about finite/infinite and Maximum.  

participation(!)

\begin{quote}
    The division that separates the sensible from the intelligible, sense experience and logic from metaphysics, does not cut through the vital nerve of experience itself; indeed, precisely this division guarantees the validity of experience.  With the same decisiveness and acuteness that he applied to the idea of `separation', Cusanus now works out the idea of `participation'.  Far from excluding each other, separation and participation, [GREEK GOES HERE], can only be thought of \emph{through} and \emph{in relation} to each other.  In the definition of empirical knowledge, \emph{both} elements are necessarily posited and connected with each other.  For no empirical knowledge is possible that is not related to an ideal being and to an ideal being-thus.  But empirical knowledge does not simply contain the truth of the ideal, nor does it comprehend that truth as one of its constituent elements.  The character of empirical knowledge is, as we have seen, its limitless determinability; the character of the ideal is its delimitation, its necessary and unequivocal \emph{determinateness} which gives to determinability a definite form and direction.  Thus, everything conditioned and finite aims at the unconditioned, without ever being able to attain it.  That is the second basic thought in the \emph{docta ignorantia}.  In relation to theology, this concept affirms the idea of knowing ignorance; with relation to experience and empirical knowledge, it affirms the idea of ignorant \emph{knowledge}.  Experience contains genuine knowledge; but certainly this knowledge must recognize that, although it may go far, it can only reach a relative aim and end, never an absolute.  And it must further recognize that in this realm of the relative there can be no exactness, no \emph{praecisio}: rather, every pronouncement and every measurement, be it ever so precise, can and will be superseded by another, more precise.  In this sense, all of our empirical knowledge remains a `probability', an attempt, a hypothesis which, from the very beginning, is reconciled to being superseded by better, more exact attempts.  Through this concept of probability, of \emph{conjecture}, the notion of the eternal `otherness' of idea and appearance is joined with the notion of the participation of the appearance in the idea.  Only this union renders possible Cusanus' definition of empirical knowledge: `conjectura est positiva assertio in alteritate veritatem uti est participans.'  \citep[p. 22-23]{Cassirer1927}
\end{quote}

- Me: non-local hidden variable theory (god) interpretation of some of Cusanus cosmology and individual relationship to god comments. From Cusanus \emph{De visione Dei} and example of portrait with all-angle looking eyes, and a discussion of what might be considered similar to theory-laden observation or an ``observer effect''

\begin{quote}
    At the beginning of the work, he recalls the self-portrait of Rogier van der Weyden, which he had seen in the town hall at Brussels.  The portrait possessed a peculiar property: it seemed to look directly at the viewer, no matter where he stood.  Imagine a portrait of this kind in the sacristy of a cloister, hung perhaps on the north wall, and the monks standing in a semi-circle around it.  Each of them will believe that the eye in the picture is looking directly at him.  Not only must we attribute to the picture the ability simultaneously to face south, west, and east, but also a triple simultaneous movement; for while it is still for the stationary observer, it follows the moving one with its glance, so that if one of the brothers walks from east to west and another from west to east, it participates in both these opposite movements.  We see, therefore, that this one and the same immobile face can move in such a way towards the east, that it simultaneously moves towards the west, and similarly, moves to the north and simultaneously to the south; a face that, standing fixed in one place, is simultaneously in all other places and which, while it is involved in one movement, is simultaneously involved in all the others.

    This represents for us, in a sensible parable, the nature of the basic relationship between God, the all-encompassing being, and the being of the finite, the ultimate particular.  Each particular and individual being has an immediate relationship to God; it stands, as it were, face to face with Him.  But the true sense of the divine first discloses itself when the mind no longer remains standing at \emph{one} of these relationships, nor even at their simple total, but rather collects them all in the unity of a vision, a \emph{visio intellectualis.}  Then we can understand that it is absurd for us even to want to think the absolute in itself without such a determination through an individual point of view.  But we also understand that none of these points of view has any priority, because only the concrete totality of them can mediate a true picture of the Whole for us.  In this whole every single viewpoint is included and recognized both in its accidentality and its necessity.  And of course, every view of God is as much conditioned by the nature of the `object' as by the nature of the `subject'; every view includes the \emph{thing seen} as well as the manner and the direction of the \emph{seeing}.  Each man can see himself only in God; just as he can see God only in himself.  This pure \emph{interpenetration} cannot be adequately characterized by any quantitative expression, or by any expression that is tied to the opposition of the `part' to the `whole'.  `Your true face is free of all limitations.  It is neither of this size, nor of this shape, neither spatial nor temporal, for it is itself the absolute form, the face of faces.  And when I consider how this face is the truth and the most adequate measure of all faces, I am astounded.  For this face, that is the truth of all faces, is not this or that large, has no ``more'' or ``less'', nor is it like any other; as the absolute, it transcends all measure.  So I see, oh Lord, that your face precedes every visible face, that it is the truth and the model of all faces.  Therefore, any face that looks into yours sees nothing different from itself, because it sees its own truth.  When I look at this picture from the east, it seems to me that I am not looking at it but it at me; the same is true when I look at it from the south or the west.  Likewise, your face is turned to all who look at you.  Whoever looks at you with love feels you looking lovingly at him---and the more he tries to look upon you with love, the more lovingly does your face look back at him.  Whoever looks at you in anger finds your look angry; whoever looks at you joyfully finds you joyful.  For as everything appears red to the physical eye when it looks through a red glass, so the spiritual eye, in its limitedness, sees you, the goal and object of the mind's observation, according to the nature of its own limitation.  Man is capable only of human judgement.  \dots If the lion attributed a face to you, he would attribute that of a lion, the ox that of an ox, and the eagle that of an eagle.  Ah, God, how wonderful is your face: the youth, if he would conceive of it, must imagine it as young, the man as male, the old man as old.  In all faces the face of faces appears, veiled, as in an enigma---but it cannot be seen uncovered unless it be when we go beyond all faces to that secret, dark silence, wherein nothing remains of the knowledge and the concept of face.'  [NOTE: TRANSLATED CASSIRER EARLY, THEN TRANSLATED CUSANUS]  \citep[p. 31-33]{Cassirer1927}
\end{quote}

We could say that each individual ``particle'' in a NLHVT has an immediate relationship to a motion from a tangent space (e.g. vibrating fluid bath example, driven from speaker ``outside'' of bath).  Non-local to the droplet, the speaker is imparting and participating in the sustaining energy and tension and other properties of the fluid which characterize the trajectories and correlations and behaviors of the individual (or many) droplets.


\begin{quote}
    Cusanus borrows the \emph{terminology} of the old `division of the world', the \emph{divisio naturae} made by Johannes Scotus Erigena.  Scotus Erigena distinguished the nature which creates and is not created from (a) that which is created and creates, (b) that which is created and does not create, and finally, (c) that which neither creates nor is created.  But this terminology now has an essentially new meaning.  When Erigena speaks of the created and at the same time creating being, he is referring to the non-temporal emergence of things from their Ideas, i.e., from their eternal prototypes and archetypes.  But Cusanus does not consider ideas to be creative forces in the Neo-Platonic sense.  Instead, he requires a \emph{concrete} subject as the central point and as the point of departure for all truly creative activity.  And this subject, according to him, can exist nowhere but in the mind of man.  The first and foremost result of this point of view is a new version of the \emph{theory of knowledge}. Genuine and true knowledge is not merely directed towards a simple reproduction of reality; rather, it always represents a specific direction of intellectual activity.  The necessity we recognize in science, and especially inmathematics, is due to this free activity.  The mind attains genuine insight not when it reproduces external existence, but only when it `explicates' itself and its own nature.  Within itself, the mind finds the simple concept and `principle' of the point; and from this, after continuously repeated movements, it produces the line, the surface, and the entire world of extension.  Within itself, the mind finds the simple idea of `now', out of which unfolds the infinity of temporal series.  And just as the basic forms of intuition---space and time---are in this sense `implied' by the mind, so too are the concepts of number and of size, as well as all logical and mathematical categories.  In the development of these categories the mind creates arithmetic, geometry, music, and astronomy.  In fact, everything logical---the ten predicates, the five universals, etc.---is included in this basic power of the mind.  It is the necessary prerequisite to all `discretion', i.e., all categorization of multiplicity according to species and classes; and it is the necessary prerequisite to the possibility of tracing the empirical-mutable back to strictly defined laws.  In this foundation of the sciences the creative power of the rational soul reveals itself in both its basic aspects; by virtue of this power the human mind enters into time and yet remains above time understood as mere succession.  For, as the origin and creator of science, the human mind is not so much in time, as time is in it.  The mind itself, by virtue of its power of discretion, creates definite time intervals and time divisions and draws the boundaries between the hours, months, and years.  Just as all essential differences come from God, so all conceptual differences emerge from the human intellect.  And thus it is the primary source of that harmony which is always the resolution of \emph{opposites}. In Ptolemy, the human intellect created the astrolabe; in Orpheus, the lyre.  Invention does not come from without; it is simply the material and sensible realization of the concept.  

    Time is to the soul as the eye is to vision.  Time is the organ the soul uses to fulfil its basic function, which is to order and sift the multiplicity, i.e., that which is variously dispersed.  With this idealist conception, Cusanus lays the groundwork for the modern concept of time in mathematics and physics---a concept that will later emerge in the works of Kepler and in Leibniz.  Furthermore, Cusanus initiates therewith a new view and a new evaluation of \emph{history}.  The interpretation of historical existence will now also be subjected to the fundamental antithesis of \emph{complicatio} and \emph{explicatio}.  This existence, too, is no mere external `happening', but rather represents the \emph{activity} most appropriate to man. Only in history can man prove himself to be truly creative and free.  Here it becomes clear that, despite the course of fortuitous events, and despite the force of external circumstances, man still remains the `created God'.  Man is completely enclosed in time; indeed, he is completely entrapped in the particularity of any given moment and completely enmeshed in the conditions of that moment; and yet, despite all this, man proves to be a \emph{deus occasionatus}.  He remains enclosed within his own being, never transgressing the limits of his own specifically human nature.  But inasmuch as he develops and expresses every facet of his nature, man represents the divine in the form and within the limits of the human.  Like every being, man has the right to fulfil and to realize \emph{his} form.  He may, he even must affirm this form, this limitation of his; for only by doing that can he honour and love God within it and give evidence of the purity of his own origin.  

    \citep[p. 40-43]{Cassirer1927}
\end{quote}

-Latter sounds like Hegel?

- Humans as determiners of value and religious turn (from inherent worthlessness/original sin) 

\begin{quote}
    And although man's being is completely derived from God, there is nevertheless a sphere in which he functions as a free creator and in which he reigns autonomously.  This is the sphere of \emph{value}. Without human nature there would be no such thing as value, i.e., there would be no principle for evaluating things according to their greater or lesser perfection.  Imagine human nature removed from the world; with it will disappear every value-preference of one thing above another.  God is, of course, the Master who strikes the coins; but the human mind determines how much they are worth.  `For although the human intellect does not give being to the value, there would nevertheless be no distinctions in value without it.  Thus, if one leaves the intellect aside, one cannot know whether value exists.  Without the power of judgment and of comparison, every evaluation ceases to exist, and with it value would also cease.  Wherewith we see how precious is the mind, for without it, everything in creation would be without value.  When God wanted to give value to his work, he had to create, besides the other things, the intellectual nature.'  [CUSANUS QUOTE]

    These sentences completely express the religious humanism and the religious optimism of Cusanus.  How could that which is the principle and the source of value be worthless?  How could it be lost to corruption and to sin?  Just as nature was earlier raised up to God through the mediation of humanity, so now human culture has found its true theodicy.  Culture confirms the freedom of the human spirit, which is the seal of its divinity.  The spirit of asceticism is overcome; mistrust of the world disappears.  The mind can come to know itself and to measure its own powers only by devoting itself completely and unconditionally to the world.  Even sensible nature and sense-knowledge are no longer merely base things, because, in fact, they provide the first impulse and stimulus for all intellectual activity.  The mind is the living illustration of eternal and infinite wisdom; but until it is stimulated to movement by that admiration which arises from contemplation of the sensible, it is, so to speak, asleep within us.  This movement, which begins and ends in the mind itself, must pass through the world of the senses.  The mind always `assimilates' itself to the sensible world; mind becomes sight when presented with colour, hearing when presented with sounds.  This descent into the world of perception is now no longer considered a decadence, a kind of sinful fall of knowledge; instead, it accomplishes the ascent of the sense-world itself which now raises itself from multiplicity to unity, from limitations to generality, from confusion to clarity.  
    
    Cusanus summarizes all of these thoughts in a pregnant metaphor.  The human mind, he writes, is a divine seed that comprehends in its simple essence the totality of everything knowable; but in order for this seed to blossom and to bear fruit, it must be planted in the soil of the sensible world.  The basic character of that `copulative theology' sought by Cusanus lies in this reconciliation of mind and nature, of intellect and sense.  With complete consciousness of method, he now opposes this to all theology that is merely `disjunctive', negating, and divisive.

    \citep[p. 44-45]{Cassirer1927}
\end{quote}

- Phenomenological turn?


- Leonardo and Cusanus shared method

- Measurement as basis of Cusanus' De docta ignorantia

\begin{quote}
    The \emph{De docta ignorantia} had begun with the proposition that all knowledge is definable as measurement.  Accordingly, it had established as the medium of knowledge the concept of \emph{proportion}, which contains within it, as a condition, the possibility of measurement.  \emph{Comparativa est omnis inquisitio, medio proportionis utens.}  But proportion is not just a logical-mathematical concept: it is also a basic concept of aesthetics.  Thus the idea of measurement becomes the connecting link, joining the natural scientist to the artist who creates a second `nature'.  In the words of \emph{Luca Pacioli}, the friend of Leonardo, proportion is not only the mother of knowledge; it is the `mother and queen of art'.  Thus, the speculative-philosophical, the technical-mathematical, and the artistic tendencies of the period converge in the concept of proportion.  And this convergence makes the \emph{problem of form} one of the central problems of Renaissance culture.

    \citep[p. 51]{Cassirer1927}
\end{quote}

- p. 52-55 ***** book of nature vs. book of god, logic/mathematics must be used to understand god/nature.  Schelling, Galileo

\begin{quote}
    The world may no longer remain a divine hieroglyph, a holy sign; instead, we must analyse and systematically interpret this sign.

    Depending on the direction this analysis takes, it may lead either to a new metaphysic or to an exact science of nature.  The natural philosophy of the Renaissance took the first path.  It took up the idea that nature is the `book of God', and then transformed it into a host of new variations.  \emph{Campanella} built his entire theory of knowledge and his entire metaphysics upon this foundation.  For him, `to know' means simply to read the divine signs that God has written into nature.  \emph{Intelligere} means nothing but \emph{intus legere}.  `The world is the statue, the living temple, and the codex of God, into which He wrote and designed those infinitely worthy things He carried in his spirit.  Blessed is he who reads in this book and learns from it the way things are and who does not invent things according to his own fancy or according to the opinion of others.'  [CITE CAMPANELLA]  Here, a new and specific feeling for nature is expressed in an old parable that can be traced through Cusanus to medieval philosophy, to Augustine and Thomas.  But it is significant that these sentences occur at the end of the work entitled \emph{De sensu rerum et magia}.  The bond that holds together the innermost recesses of nature and that joins nature to man is still conceived of completely as a magical-mystical bond.  Man can only understand nature by inserting his own \emph{life} into it.  The limits of his feeling for life, the barriers to a direct \emph{sympathetic feeling} of nature, are at the same time the limits of his \emph{knowledge} of nature.

    The opposite form of interpretation is found in that study of nature that leads from Cusanus through Leonardo to Galileo and Kepler.  It is not satisfied with the imagistic and sensible force of the signs in which we read the spiritual structure of the universe; instead, it requires of these signs that they form a system, a thoroughly ordered whole.  The \emph{sense} of nature must not be mystically felt; it must be understood as a logical sense.  And this requirement can only be fulfilled by means of mathematics.  Only mathematics establishes unequivocal and necessary standards against the arbitrariness and uncertainty of opinions.  For Leonardo mathematics becomes the dividing line between sophistry and science.  Whoever blames the supreme certainty of mathematics feeds his mind with confusion.  Whoever relies on individual words falls prey to the uncertainty and ambiguity characteristic of the single word, and finds himself entangled in endless logomachies.  [CITE DA VINCI]  Only mathematics can give a purpose to these disputes in that it fixes the meanings of words and subjects their connections to definite rules.  Instead of a mere aggregate of words, mathematics gives us a strictly syntactical structure of thoughts and propositions.

    Galileo takes this path to its very end.  For him, the individual sense perception, no matter how intense or forceful it may be, is a mere `name'; it neither `says' anything nor has any objectively definite meaning.  [CITE GALILEO]  Such meaning is born only when the human mind relates the content of the perception to the basic forms of knowledge, the archetypes of which are in the mind itself.  Only through this relationship and this interpenetration does the book of nature become readable and comprehensible.  Thus, from Cusanus' basic notion of `indestructible certitude' (\emph{incorruptibilis certitudo}), which is proper to none of the symbols necessary and possible to the mind except the mathematical signs, we move in a continuous historical line and arrive at those famous fundamental and guiding principles by which Galileo defines the aim and the character of his research.  And when the revelation of the `book of nature' is juxtaposed to the revelation of the bible, the process of secularization is completed.  There can be no fundamental opposition between them since both represent the same spiritual sense in different forms, i.e., since the unity of the divine originator of nature is manifested in them.  But if a disagreement between them should nevertheless seem to arise for us, it can only be settled in one way: we must prefer the revelation in \emph{works} to that in \emph{words}; for the word is something of the past and of tradition, whereas the work, as something at hand and enduring, stands before us, immediate and present, ready to be questioned. [CITE GALILEO]

    \citep[p. 53-55]{Cassirer1927}
\end{quote}

- Renaissance theme of having courage to use own reason, Leonardo preferring experience over academic language

- referring to Olschki

- ************* VERY IMPORTANT SECTION **************

\begin{quote}
    The liberation from medieval Latin, the gradual construction and development of the \emph{volgare} as an independent scientific form of expression was the necessary prerequisite for the free development of scientific thought and its methodological ideals.  This confirms the truth and depth of Humboldt's basic view, according to which language does not merely follow thought but, rather, is one of the essential moments in its formation.  The difference between Scholastic Latin and modern Italian is not merely a `difference of sounds and of signs'; rather, it expresses a `difference in views of the world'.  Here again, language did not merely serve as the vessel for the new view of the world; rather it brought that view forth from within itself, letting it be born together with the form and shape of the language itself.  

    The technical thought of the Renaissance moved in the same direction as the linguistic. [CITE Olschki]  In this, too, surprising though it may seem, Cusanus led the way.  For in his philosophy, a new meaning and a new place are given to the technical spirit, the spirit of the `inventor'.  When Cusanus sets up and defends his basic view of knowledge, when he explains that all knowledge is nothing but the unfolding and explication of the complication that lies within the simple essence of the mind, he is referring not only to the basic concepts of logic, of mathematics, and of mathematical natural science, but also to the elements of technical knowledge and technical creation.  The mind develops space out of the principle of the point, which is in the mind; it develops time out of the simple `now', and number out of unity.  In like manner, an ideal `blueprint' must precede the mind's \emph{working} upon nature.  Every art and every skill is based on such a blueprint.  Besides the categories of logic, the concepts of geometry and arithmetic, music and astronomy, Cusanus cites such technical accomplishments as the lyre of Orpheus and the astrolabe of Ptolemy as evidence of the independence and eternity of the mind. [CITE CUSANUS]  To be sure, in exercising its own creative power, the mind does not remain within itself but must have recourse to sensible `matter', which it forms and transforms.  But this does not indicate a retreat from the purely intellectual nature and essence of the mind.  For here, again, the way up and the way down are one and the same; the intellect descends to the sensible only to raise the sense-world up to itself.  Its action upon a world made of apparently opposite stuff is the condition for its recognizing and realizing its own form, and for translating this form from potential to actual being.  [CITE CUSANSU]

    From this we can understand that a strong `realistic' influence could stem from the Idealism of Cusanus.  And we can also understand that the man who revived the Platonic doctrine of \emph{anamnesis} could become the founder of modern empirical science and the leader of the great `empiricists'.  They also see no contradiction between `apriorism' and `empiricism'; because what they seek in experience is necessity---it is reason itself.  When Leonardo refers to experience, it is to discover there the eternal and unchangeable order of reason.  His true object is not experience itself but the rational principles, the \emph{ragioni} that are hidden and, so to speak, incorporated in experience.  And he emphatically states that nature is full of `rational principles' that have not yet been part of experience: \emph{la natura \`e piena d'infinite ragioni che non furono mai in isperienza.} [CITE DA VINCI]  Galileo follows the same path.  Though he considered himself a champion of experience, he nevertheless emphasized that the mind can only create true, \emph{necessary} knowledge by its own principles (\emph{da per s\`e}).  In view of this attitude on the part of the leading scientific minds, it becomes understandable that while science was freeing itself from Scholasticism, it felt no need to sever the bond that joined it both to ancient philosophy itself, and to the efforts at its restoration.  In fact, that bond could now be strengthened. 

    \citep[p. 56-58]{Cassirer1927}
\end{quote}

- ********* VERY IMPORTANT SECTION ************* 

- Quantum probabilities, under structural idealism, are synthetic objects according to \emph{rational principles of experience}.  \textbf{This is more than Bayesian normativity.}

\subsection{Ryckman Reign of Relativity}

- Everyone thought GR confirmed their own metaphysics... Logical empiricist interpretation of GR as refuting Kantianism and synthetic apriori.  Schlick (Ph.D. under Planck, supported by Carnap and Reichenbach and Neurath) as authority.  

\begin{quote}
    It will be seen that, however rhetorically useful, the claim that general relativity sounded the death knell of ``the Kantian position'' follows only if, as Schlick did, one ignored important neo-Kantian developments of Kant's thought as well as many of the most significant developments in relativity theory in the period 1915-1925.  Schlick's judgment was narrowly based and by no means universally shared.  To sample but one countering opinion, the Nobel prize winner and fellow Planck student Max von Laue stated, in the first actual textbook on general relativity in 1921, that Kantian epistemology was confirmed by the new theory, although ``not every sentence of \emph{The Critique of Pure Reason}'' could be regarded as sacrosanct.  Yet as pious children of this world, to borrow an expression of Hermann Weyl's, we know that if an assertion is repeated sufficiently often, while remaining unchallenged in the forum of debate, it commonly enters into currency as accepted background knowledge.  Certainly the claim that general relativity decisively refuted transcendental idealism \emph{tout \`a coup} is strewn through the literature of logical empiricism, percolating beyond to its prodigal progeny.  Nor was it explicitly challenged in philosophical circles by anyone having the \emph{gravitas} of authority possessed by Schlick, and then by Reichenbach, who would take over the mantle of authority on relativity theory within logical empiricism, as Schlick fell under the influence of Wittgenstein and turned away from philosophical investigations of physics.  As a result, the allegation has remained unimpeached amidst the triple assault that proved fatal to the rest of logical empiricism: Quine's attack on the analytic-synthetic distinction, Hanson's and Toulmin's on the observational-theoretic distinction, and Kuhn's critique of logical empiricism's inductivism and its method of rational reconstruction.  So it was that, when scientific realism began again to stir in late 1950s and early 1960s, as it always will, against the thin gruel of positivism and instrumentalism, there were scarcely any parties to the conflict who grasped the possibility of an alternative to \emph{both} realism \emph{and} instrumentalism or, beginning in the 1970s, to realism and the resuscitated bogey of ``relativism''.
    
    That alternative already existed, and it assumed several different, but related forms, in the ``reign of relativity'' from 1915 to 1925 through the efforts of Ernst Cassirer, Hermann Weyl, and Arthur Stanley Eddington.  It is a philosophy that exists only in various incomplete realizations having at most a ``family resemblance'' among themselves.  In this book it is called \emph{transcendental idealism}, and although Kant is the paramount figure historically, its development by no means ended with Kant, as Cassirer, Husserl, Weyl, and others have shown.  I will therefore use the term ``transcendental idealism'' far more broadly than is customary in most philosophical discussions.  But for present purposes, the core constituent of the doctrine concerns the ``transcendental constitution of objectivity'' in fundamental physical theory, according to a ``transcendental postulate'', in broad generality affirming that ``[a] nature is not thinkable apart from the coexistent subjects capable of experiencing that nature''.  The details of the various and differing conceptions of ``transcendental constitution'' in general relativity are described in detail below in discussions of Cassirer, Weyl, and Eddington.
    
    \citep[p. 5-6]{Ryckman2005}
\end{quote}

- Cassirer neo-Kantianism not well known/translated

\begin{quote}
    Yet the Marburg tradition of neo-Kantianism, within which Cassirer had been educated, long before rejected the original Kantian distinction between the mental faculties of sensibility and understanding, and on this ground Cassirer could reinterpret the doctrine of pure intuition in \emph{conceptual terms} as pertaining only to ``the order in general of coexistence and succession''.  In his 1921 book of ``epistemological reflections'' on Einstein's theory of relativity, as discussed in chapter 2, he was in a position to grasp what is arguably the most philosophically significant aspect of general relativity, the principle of general covariance, as a ``regulative principle'' and constituent part of an ideal of physical objectivity from which all traces of ``anthropomorphic'' subjectivity have been removed.  In an enlightened understanding (which is fully in the spirit of Cassirer's discussion), this is the requirement that dynamical laws must be formulated without a ``background'' space and time, a constitutive requirement of general relativity, but utterly violated in the standard operator formalism of quantum field theory.
    
    \citep[p. 7]{Ryckman2005}
\end{quote}


- Weyl formulating advances towards GR in Husserlian transcendental phenomenology (contributing to lack of translations/understanding/wide awareness), debating foundations of math with Hilbert and Brouwer, Lie groups

- EPISTEMOLOGY IN THE TANGENT SPACE

- Overview:

\begin{quote}
    In the spring of 1918, Weyl had proposed a geometric unification of gravitation and electromagnetism, a further step along the road of general relativity.  The basis of the unification was a ``pure infinitesimal geometry'' permitting neither direct comparisons ``at a distance'' of direction nor, unlike the Riemannian geometry of Einstein's theory, of magnitude.  Within such a geometry, Weyl recast Einstein's theory together with electromagnetism on the privileged epistemological basis of fundamental differential geometric notions having immediate validity only in the tangent space attached to each manifold point $P$, corresponding to a localized space of intuition.  In opposition to the scientific realism of his day, and in a characteristically distinctive fashion combining Husserlian ``essential analysis'' of space and time as ``forms of intuition'' with mathematical construction, Weyl sought in this way to provide a transcendental-phenomenological account of the constitution of the \emph{sense} of the objective world of relativity theory, the sense of a ``being \emph{for} consciousness''.  However, Weyl's epistemological motivations were expressed in the obscure language of Husserl, and his theory, thus misunderstood, was critically rejected on both physical and general methodological grounds.
    
    The ties of Weyl's theory to observation \emph{are} indirect; and, if we accept Weyl's recognition of the existence of a ``natural gauge'' of the world, simply presupposed in Einstein's posit of rods and clocks, they are also present in general relativity.  The values of the metric at a point can be determined through the use of freely falling neutral ``test particles'' and by observing the arrival of light at points in the immediate neighborhood of that point.  However, neither of these hypotheses, of ``freely falling'' test particles or of the behavior of light in a gravitational field, is independent of gravitational theory.  Both can be derived from the Einstein field equations for particular models of space-time.  For this reason, as Weyl repeatedly stressed regarding Einstein's theory, only the theory as a whole, comprising physics, geometry, and mechanics, can be confronted with observation.  If that is so, then, as Schlick put it, there is no place for an empiricism worthy of the name to gain a place to stand.  A different epistemology of science would have to be found.  For without such an empiricist Archimedean point for general relativity, allegedly endorsed by Einstein and therefore to be retained at all cost, there could be no room for subsequent logical empiricist methodology of science to thrive.  So too for the fruits of its analysis of science: an empiricist semantics for theoretical terms and sentences, the empiricist criterion of cognitive meaning, and the positivist rhetoric that any nonempirical statement was either analytic or meaningless ``metaphysics''.  When, a full generation later, these invidious doctrines finally faded from the scene under assault from different quarters, the lack of a clear alternative was perhaps noticeable only to those whose horizon stretched back to the philosophically fecund first years of general relativity.  In its absence came the inevitable backlash of scientific realism and its several antitheses.
    
    As it happened, of course, such an epistemology of science was developed, in part in bits and pieces of Weyl's mathematical and physical oeuvre and, in broader generality, in his monograph on philosophy mathematics and natural science in 1926.  By then, Weyl had returned for good, except for a brief excursion into the new quantum theory, to purely mathematical pursuits.  This left the playing field of ``scientific philosophy'' open to Reichenbach's ``constructive axiomatization'' of the theory of relativity (1924), where the mechanism of ``coordiative definitions'' took over from Schlick's still-born ``empiricism with constitutive principles'', and in this guise the new empiricist analysis of scientific theories acquired its mature form.  After the ``linguistic turn'' of the early 1930s, the discourse became one of two vocabularies, or languages, ``theoretical'' and ``observational'', and of defining the former in terms of the latter, eventually through ``meaning postulates''.  Citing Einstein as a guiding spirit, the logical empiricists claimed the authority of philosophical expertise regarding relativity theory, a title they are still perceived in many circles to hold, as it were, from beyond the grave, and despite Einstein's later public disavowals of their core positions.  Ironically, Einstein's own philosophical evolution after 1915 carried him further and further away from the empiricism Schlick viewed as present in general relativity and toward neo-Kantian conceptions and the mathematical speculative methodology for which he had once chastised Weyl.
    
    One more figure played a central role in the possible alternative tradition to logical empiricism and its successors that may be loosely associated with ``the Kantian position''.  If one were to name the grand masters of general relativity in the early 1920s, besides the names of Einstein, Weyl, Hilbert, the young Wolfgang Pauli, Jr., and on the mathematical side, \'Elie Cartan and George D Birkhoff, only that of Arthur Stanley Eddington remains.  Eddington, Plumian Professor of Astronomy at Cambridge since 1914, was already an internationally known astronomer in 1915.  He would become, in the assessment of S. Chandrasekhar, ``the most distinguished astrophysicist of his time''.  He was also the first in Britain to have any detailed knowledge of Einstein's new theory during the first World War.  With his mathematical skills, he was also a highly creative relativity theorist.  In fact, he was so connected to the new theory, as exponent, expositor, and theoretician, that he became known in Britain as ``the apostle of relativity'', and we have it from no less a source than Paul Dirac that in the early 1920s, his name, not Einstein's, was most closely linked there with the new theory.
    
    Eddington was also heretical enough to accept Weyl's generalization of Einstein's theory and to generalize it further, for epistemological reasons essentially similar to Weyl's.  Weyl had reconstructed the objective world of relativity physics within a ``purely infinitesimal geometry'', corresponding to the phenomenological standpoint of methodological solipsism wherein only such linear relations as could be present to an infinitesimally bounded spatio-temporal intuition were immediately evident.  Eddington sought the same goal of constituting the ``real world of physics'' by reconstructing relativity theory within a differential geometry capable of yielding only objects that are a ``synthesis of all aspects'' present to all conceivable observers.  The external world of physics might be \emph{defined} in this way as a world conceived ``from the viewpoint of no one in particular'', a standpoint both necessary and sufficient for \emph{objective} representation in physics.  The epistemological significance of relativity theory lay in showing that the attempt to portray the physical world from this impersonal perspective resulted in its geometrization.  In turn, the physical knowledge captured in such a portrayal is knowledge only of the world's structure.  Physics \emph{could be} about \emph{no} other world than that expressly incorporating all viewpoints at once, an ``absolute world'' as opposed to the ``relative'' world of each individual perspective, that is, any ``conceivable observer''.  The relation between the relative and the absolute is mathematically captured by the tensor calculus and physical knowledge accordingly must be represented in the form of tensor identities through a method Eddington called ``world building''.
    
    As we shall see in chapters 7 and 8, Eddington was adamantly convinced that Weyl's ``epistemological principle of the relativity of magnitude'' (the origin of the modern ``gauge principle'') was an essential addition to the outlook of relativity of continually incorporating additional ``points of view'' into physics.  But, in the intricacies of Weyl's transcendental-phenomenological framework of constitution, Eddington judged, Weyl had erred.  For Weyl had not made clear that his geometry was \emph{ideal} and purely mathematical, a geometrical skeleton for the ``graphical representation'' of existing physics from ``the point of view of no one in particular''.  Eddington's idea, therefore, was to develop such an ideal geometry independently of physics, basing it on a purely local and \emph{nonmetrical} relation of comparison, a symmetric linear connection.  In a geometry based on such an ``affine connection'', rather than a metric, a more general kind of invariant than tensors can be ``built up''; nonetheless, only one of these is mathematically identical to the metric tensor of Einstein's theory.  Setting the two equivalent, one can proceed to ``graphically represent'' the tensorial quantities of existing physical theory, gravitation, and electromagnetism.  The ideal geometry of Eddington's affine field theory then shows that Einstein's geometry, not Weyl's, is exact, but this is a demonstration from the most general ``the point of view of no one in particular'' available to a continuum theory in 1921.  Eddington's theory is not a physical hypothesis but an explicit attempt to cast light on the origin and significance of the great field laws of gravitation and electromagnetism.  Within the epistemological reconstruction of ``world building'', the differential geometric invariants appearing in these laws are structures selected from a vast number of other possible invariant structures derivable from given axioms of ``primitive relation structure''.  Mind is the principle of selection; in particular, it is mind's interest in ``permanence'' that identifies the Einstein curvature tensor, regarded in ``world building'' as a purely geometrical quantity, with the physical energy-momentum tensor of matter.  Hence, Einstein's law of gravitation for ``matter'' sources is simply a world geometric definition of matter.  In the absence of matter, Einstein's law of gravitation for empty space (as amended with the cosmological constant) is a statement that the world is ``self-gauging'', that rods and clocks, apparatus of course part of the world (and explicitly so, in ``world building''), are used in measuring the world.  As Eddington pointed out later on, there [are] similarities between his view of physical knowledge and those of Kant.  One difference, certainly, is that Eddington's account of the constitution of physical objectivity simply assumes relativity theory, where Kant had assumed Newton.  I shall show that the similarities are considerably more noticeable when set in the context of transcendental idealism, more broadly conceived.
    
    In the pages that follow it will be seen that the emergence of logical empiricism in the 1930s as the apotheosis of ``scientific philosophy'' (a reputation still widely upheld) had little to do with its purported expertise regarding relativity theory but was achieved largely through rhetoric and successful propaganda rather than through philosophical argument.  Its most (and still) alluring appeal lay in a self-styled contrast of enlightenment versus reaction, and in its identification of science as the primary instrument of human advance from the dreary annals of superstition, dogma, and fanaticism that permeate human history.  Its great myths even today have hardly been questioned: that relativity theory had overthrown any form of ``Kantianism''; that ``empiricism'' stood opposed only to an antiscientific and dogmatic ``rationalism''; that logical empiricism, itself modeled on the methodology of relativity theory, was \emph{d'accord} with modern physics (relativity theory and quantum mechanics).  The doctrinal triumph of logical empiricist philosophy of science itself, of course, was not lasting.  Its employment of a new favorite tool, symbolic logic, as the \emph{organon} of philosophy of science, an \emph{ersatz} for actual knowledge of science, still succeeds to some extent in reviving the desiccated corpse of logical empiricism through the boom-and-bust cottage industry of mainstream philosophy of science.  But even symbolic logic could not save ``the received view'' from the inevitable cognitive discord induced by a glaring awareness of the enormous gap between its rational reconstructive portrait of science and that of a new history of science, reinvigorated by Koyr\'e and, above all, Kuhn, as was recognized by Hempel in his last writings.  Rather, these myths live on institutionally, subconsciously continuing in the sclerotic distinction between ``analytic'' and ``continental'' philosophy.  Surmounting that artificial distinction, the family resemblance among the ``transcendental idealisms'' of Cassirer, Weyl and Eddington contains the seeds of promise for an actual philosophical understanding of the \emph{non plus ultra} role of abstract mathematics in fundamental physical theory.
    
    In 1931, P.A.M. Dirac prefaced his celebrated paper on magnetic monopoles with several remarks that announce a sea change in the methodology of theoretical physics.  Stating that drastic revision of fundamental concepts may be required to address the current problems of theoretical physics, Dirac nonetheless cautioned that such a transformation in outlook is likely to be beyond the power of human intelligence to directly grasp the required new ideas without the assistance of mathematical speculation.  In the face of these cognitive limitations, a more indirect approach is suggested, wherein ``the most powerful method of advance'' would be 
    
    \begin{quote}
        to perfect and generalize the mathematical formalism that forms the existing basis of theoretical physics, and \emph{after} each success in this direction, to try to interpret the new mathematical features in terms of physical entities (by a process like Eddington's Principle of Identification).
    \end{quote}
    
    Now this principle, as Eddington himself made clear, was directly inspired by Weyl's mathematical identification of the vector and tensor structures of his purely infinitesimal world geometry with those of gravitation and electromagnetism.  That being the case, Weyl's 1918 theory can be justly regarded as the locus of the modern revival of the method of \emph{a priori} mathematical conjecture in fundamental physical theory.  How such a method can ever be fruitful in constructing well-confirmed fundamental physical theories has long appeared a mystery, for which extreme solutions (such as Platonism) have been seriously proposed.  The argument of this book suggests that less desperate measures may have been overlooked.  The work of Cassirer, Weyl, and Eddington on general relativity provides a needed ``Copernican about-face'' on the question, by demonstrating how and why \emph{a priori} constraints of reasonableness can be imposed on nature without proudly (but naively) presuming them to be inherent in nature itself.  They did not leave us a fully worked out presentation of an alternative epistemology of science, each going on to other endeavors that effectively removed their work from the sphere of the familiar that so bounds human understanding, even in philosophy.  In all likelihood, such a completed account doesn't, or shouldn't, exist except as an ideal guiding inquiry.  What they did leave has been allowed here to ``speak for itself'', a presentation that comes at times at the cost of effusive length, but that appeared necessary in the light of the unfamiliarity, and even inaccessibility, of many of their core writings.  Perhaps any further development, any ``future music'', to quote Weyl again, might be well advised to at least consider what they once had to say.
    
    \citep[p. 8-12]{Ryckman2005}
\end{quote}

- ch. 2 general covariance, philosophy of science followed Reichenbach's neo-Kantian amendments instead of Cassirer's.  Following Schlick, Reichenbach's coordination principles/definitions between math and empirical observations 

\begin{quote}
    Following Schlick's lead, Reichenbach came to see coordination principles as playing so ``thin'' a ``constitutive'' role as to be indistinguishable from stipulations that certain empirically accessible objects and processes are (approximately) described by core relations of the mathematical framework of a physical theory.  Yet the most significant aspect of this reevaluation is that it consolidated a fundamental shift of epistemological discussion initiated by Schlick's influential \emph{definition} of cognition as a ``univocal coordination'' in 1918.  Subsequently, philosophers of science would have progressively less and less understanding of the relevance of any account of ``physical objectivity'' in accordance with conformity to presupposed ``conditions of possible experience''.  Instead, the relevant epistemological issues of interest concerned the applicability of an uninterpreted mathematical formalism to an empirically given concrete subject matter or, in terms more redolent of mature logical empiricism, the semantical rules through which a mathematical framework acquires empirical content, and so ``cognitive meaning'' in physics.  
    
    It is my contention that Cassirer's different articulation of a role for the relativized \emph{a priori} has been rather amply confirmed in the subsequent development of physical theory.  Namely, Cassirer expressly pinpointed the specific ``meta-empirical'' standing of invariance principles in physical theory, in particular, emphasizing that the principle of general covariance significantly transformed the concept of ``objectivity'' in physics.  In this role, principles of invariance have \emph{both} a ``constitutive'' \emph{and} an ideal ``regulative'' \emph{a priori} significance.  To be sure, in Kant's account of ``constitution of the object of knowledge'' from the two independent contributions of sensibility and understanding, ``regulative'' principles, systematic ideals of unity of the ``higher faculty'' of pure reason, can play no direct ``constitutive'' role.  Hence, one salient division between Cassirer's and Reichenbach's epistemological analysis of relativity theory pertains to just where modification or amplification of original Kantian doctrine is required in order to retain a constitutive but nonconventional meaning of the ``relativized \emph{a priori}''.  Ultimately, the different determinations reduce to opposing answers to the question of \emph{whether there are nonanalytic} a priori \emph{elements in physical theory}.  As shown in chapter 3, due in large measure to Schlick's considerable authority regarding the new theory as well as his rhetorical ability to pose the issue in his own terms, this was a very short debate that, in the eyes of ``scientific philosophy'', Cassirer lost.
    
    In this chapter, and in those subsequent to it, I venture to challenge this received wisdom on grounds internal to various epistemological analyses of the theory of general relativity, all carried out within a broader genus of ``transcendental idealism'' than is to be explicitly found in Kant.  Here, attention is directed toward how, constrained by the resources afforded by their competing revisions of Kantian doctrine, Reichenbach and Cassirer respectively assessed the implications of the principle of general covariance for the ``epistemology of physical science''.  Of course, the matter of precisely what, if any, physical significance this principle may have, has long been perhaps the most controversial issue in the foundations of general relativity.  Einstein's considered judgment, that the principle is not physically vacuous but has ``considerable heuristic force'' in the construction of physical theories, was explicitly recognized by Cassirer, but also has been adopted (or insisted upon) by several leading members of the current generation of theorists of quantum gravity.  Following Cassirer's lead, I argue that, in epistemological terms, the ``heuristic force'' of general covariance is located in the principle's ``constitutive'' significance in constraining the concept of possible object in field theory to objects that are ``background independent''.  This is to be understood as the expression of an ``ideal of reason'', namely, that ``the objects of which the world is made do not live over a stage and do not live on space-time; they live, so to say, over each other's shoulders''[Rovelli quote, 2001, p. 108], a goal not yet attained in the present state of fundamental theory.
    
    \cite[p. 14-15]{Ryckman2005}
\end{quote}

- hole argument, Einstein's general covariance with reference frames was noted by Kretschmann not to actually say something about physics but about mathematical restriction

\begin{quote}
    General covariance, if mere coordinate generality is intended, is merely a formal constraint on the theory's mathematical form, having \emph{per se} nothing to do with a ``principle of general relativity'' or with the theory of gravitation.  In a purely formal sense, an equation is generally covariant just in case it preserves its form (is ``covariant'') under arbitrary transformation from one coordinate chart to another, $\Bar{x} \Rightarrow \Bar{x}'$.  Moreover, Kretschmann claimed that since, as Einstein affirmed, the totality of physical experience must ultimately refer to coincidences, any physical theory that preserves the lawful connections among coincidences can be written in generally covariant form, subject only to the introduction of additional variables.  If it had been Einstein's intent to lend physical significance to general covariance, he had not succeeded in distinguishing that meaning from this purely formal constraint.  In a response the next year, Einstein admitted the correctness of Kretschmann's objection, nonetheless maintaining that the ``relativity principle'', according to which laws of nature find ``their sole natural expression in generally covariant equations'', has a ``significant heuristic force''.  By contrast, he argued, if one were to write down the equations of Newtonian gravitational mechanics in (four-dimensional) generally covariant form, the result would be seen to be so unnatural as to be readily excluded from theoretical consideration.  One can only speculate about Einstein's criteria of theoretical naturalness, but in any case, his reply has been widely judged inadequate, or at least as an essential backpedaling, from his earlier claims on behalf of general covariance.
    
    \citep[p. 17]{Ryckman2005}
\end{quote}

- hole argument, active general covariance idea (diffeomorphism moving points) vs. passive general covariance (passive being just like a symmetry property of a tensor, relabeling w/o physical implications)

\begin{quote}
    Clearly, Einstein's difficulty pertained to the interpretation of the diffeomorphic point transformations rather than to any trivial confusion regarding coordinate transformations, as has been frequently alleged.  In late 1915, Einstein realized the faulty presupposition required for the discordant conclusion that these distinct solutions correspond to different \emph{physical} situations.  The answer lay in seeing that the coordinates $x^{\sigma}$ have no metrical or other physical meaning but serve as essentially arbitrary labels for space-time points, required for the operations of the differential calculus on a manifold.  In other words, the points of the space-time manifold (and so also those within the ``hole'') \emph{do not inherit their individuality, hence physical existence, from the underlying differential-topological structure} of the manifold.  To the contrary, their \emph{physically} distinguishing properties and relations derive not from coordinate labels, but from the fields assigned to them by the generally covariant equations of physical theory; in general relativity these include \emph{at least} the metric field functions $g_{\mu\nu}$.  In turn, in a generally covariant space-time theory of fields, only the thus-designated events (possible ``point-coincidences'') and the relations between them are the ``true observables'', a (topological) structure preserved under one-to-one continuous diffeomorphic pooint transformations.  In the current parlance stemming from Hawking and Ellis (1973), general relativistic space-times are regarded as equivalent if they have isomorphic models $\{\langle M,g_{\mu\nu}, T_{\mu\nu}\rangle \langle M, D^*g_{\mu\nu}, D^*T_{\mu\nu}  \rangle\}$, physically indistinguishable under a manifold diffeomorphism $D$.  The physical equivalence of these models express the principle of general covariance, understood actively as diffeomorphism invariance.
    
    Having now recognized his mistake, Einstein in 1916 sought to underscore this new understanding by adopting a programmatic characterization of what is physically observable as, in principle, reducible to the broad category of ``point-coincidences'' (or intersections of world lines).  This ensures that the conclusion of the hole argument can no longer go through, since only a physical process---the metric field (and possibly other physical fields)---can accord physical existence to the events that make up the space-time manifold.  For according to this criterion there is truly no ``empty space'', no space-time points bereft of \emph{at least} the metric field and so no (merely) ``topological space''.  In holding that space has existence ``only as a structural quality of the field'', Einstein is underscoring his heuristic postulate that ``spatio-temporal individuation of the points of the manifold in a general-relativistic model is possible only after the specification of a particular metric field, that is, only after the field equations of the theory (which constitutes its dynamical problem) have been solved''.  [Stachel 1989a quote]  Then the striking statement situating physical reality in ``point-coincidences'' represents an attempt to distinguish clearly what is required for certain mathematical structures of the theory to have physical significance.  It is not the positivist credo that, since the \emph{in-principle observable} is found in the coincidence of points (intersections of world lines), only such coincidences as are actually observed are real.  Alas, this was the message received in Machian circles and welcomed as a confirmation of Mach's positivist philosophy.  But once the largely hidden context of the hold argument is restored, it is clear that in locating the ``physically real'' in ``point-coincidences'', Einstein gave rhetorical force to the \emph{fact} that, in general relativity unlike special relativity, space-time coordinates alone can have no immediate physical---that is, no chronogeometrical---meaning.
    
    \citep[p. 21-22]{Ryckman2005}
\end{quote}

- general covariance vs. general invariance (different groups) and GR general covariance should be general invariance


\begin{quote}
    To Einstein, the ``most essential thing'' lay in removing from phyiscal theory, once and for all, the idea of an inertial system, of any notion of background space-time structures that act (in the explanation of the inertial motion) but which in turn are not acted upon.  \emph{A fortiori} this holds for a unified field theory, or any ``consistent field theory'', where ``representing reality by everywhere continuous, indeed even analytic functions'' means that the very notion of a ``particle'' does not exist in ``the strict sense of the word''.  [Einstein to Besso]  In such a theory of the ``total field'', the dualism of matter and field is fully resolved in favor of the latter.  ``Particles'' are everywhere to be described as ``singularity free solutions of the completed field equations'', representing localized large concentrations of electromagnetic, gravitational, and perhaps other forms of energy.  Moreover, the law of motion of such ``particles'' must be derivable from the field equations governing the fundamental field variables, a requirement that is only met by a nonlinear theory and, Bergmann has argued, a direct consequence of the theory's generally covariant field equations.  In point of fact, if the field equations are nonlinear (as are the Einstein field equations), there is no unambiguous way to separate the total field into the self-field of the particle (notoriously infinite, before ``renormalization'', in the usual nonalgebraic formulation of quantum field theory), and the finite external ``incident'' field immediately surrounding the particle's spatially local extended volume, primarily responsible for its instantaneous state of motion.  Successful derivation of an equation of motion within such a theory thus entails the nonexistence of causal influences on the particle not mediated through the immediately adjacent field.  In any theory of this kind, the very possibility of such ``objects of experience'' as ``particles'' with determinate properties, presupposes some criterion for the individuation of distinct physical systems that nowhere relies upon \emph{a priori} structures of a ``background'' space and time.  
    
    \citep[p. 23-24]{Ryckman2005}
\end{quote}

- general covariance as a priori constitutive guiding requirement from Einstein and Cassirer, meta-level principles

- Reichenbach/Schlick coordination between concepts and reality, objects of latter unchanged and as they are; given vs posed, gegeben vs aufgegeben: Marburg (Cassirer) interpreting Kant as latter.  But Schlick disagreed with realist way Reichenbach was going with coordinating reality as given.

- Cassirer general notion of invariance in scientific methodology, alternative "cognition" of physics compared to Reichenbach and Schlick

\begin{quote}
    Resisting the pull of mentalism, Cassirer refrained from characterizing anything but the logical form of this ``intellectual \emph{coordination}'' (\emph{gedankliche \textbf{Zuordnung}}) through which diverse elements are connected into a systematic unity.  The object of knowledge does not arise from the mere application of formal concepts to sensible experience but is ``an expression for the form and mode of conceiving itself''.  Hence, on the functional theory of the concept, only a relative distinction can be made between the ``form'' and ``content'' of cognition.  These are not completely independent realms of existence, but only reciprocal ``moments'', as concept and as intuition, of a basic process of cognitive synthesis that determines the concept of object.  ``Content'' \emph{is} only as determined through the serial relations of space and time, and the forms of magnitude and number.  In physics, the epistemological high point of this (pre-relativistic) development had been attained by Hertz and especially Duhem, who stressed that concepts are pure symbols for relations and functional connections, not in any sense copies, or images, of the real.
    
    In this genealogy of the doctrine of the concept, no particular principle of form or order characteristic even of the present state of science can be taken as immutable or having \emph{apodictic} validity.  What remains unchanged through the successive changes in scientific knowledge is merely the ``objectifying function'' itself, the ``supreme law of objectification''.  A fundamental axiom is Kant's claim that ``objective validity and necessary universality (for everyone) are interchangeable concepts''.  Cassirer's guiding analogy is Felix Klein's \emph{Erlanger Programm} where a geometry is characterized by the group of transformations under which given relations between points of the space are invariant.  Similarly, the method of ``transcendental philosophy'' is to be a ``\emph{general invariant theory of experience'' (\emph{eine ``\textbf{allgemeine Invariantentheorie der Erfahrung}}''}---original emphasis), isolating and investigating the most general elements of form that persist through all change in the material content of experience.  Among these are the ``categories'' (``\emph{Kategorien}'') of space and time, of magnitude and functional dependence between magnitudes, presupposed in any empirical judgment or system of judgments.  The aim of critical philosophy is to provide a complete inventory of the ultimate \emph{logical invariants} (\emph{de letzten \textbf{logischen Invarianten}}) common to all possible forms of scientific experience, persisting from theory to theory as necessary and constitutive factors of any theory.  That this is a goal neither completely attained nor attainable at any stage of knowledge is readily admitted.  Rather, the significance of this aim is that it is a ``\emph{demand}'' that a fixed direction is prescribed to ``the continuous unfolding and development of systems of experience''.
    
    \citep[p. 40-41]{Ryckman2005}
\end{quote}


- general covariance a principle of objectifying unity, bringing knower/epistemologist closer to ideal form of objective object of knowledge [p. 44], towards relational and structural view of the objects of knowledge of scientific methods, satisfying maxim for methodological investigation of nature [Cassirer relating to Kant, Ryckman doesn't mention here but I'm thinking of universalizable maxim---i.e. if everyone follows it physics is composed of ideally intersubjective structures] (Cassirer)


\begin{quote}
    The interpretation of general covariance as a further development of the methodological principle of ``objectifying unity'' is the central theme in the remainder of Cassirer's essay.  Where experience had unexpectedly failed to find the preferred reference frame posited by Galilean-Newtonian mechanics for the motion of the solar system or the motion of the earth in Michelson's experiment, the theory of general relativity made a virtue out of necessity by requiring that there \emph{cannot} and \emph{must} not be such a preferred system.  The general theory of relativity thus adopts the principle (\emph{Prinzip}) ``that for the physical description of the processes of nature [\emph{Naturv\"organge}] no particular reference body should be distinguished above all the others''.  The requirement of general covariance (``that all Gaussian coordinate systems are of equal value for the formulation of the general laws of nature'') is designated a ``rule of the understanding'' (``\emph{Regel des Verstandes}'') adopted within physics not only as a formal requirement on mathematical representation, but as a ``principle that the understanding uses hypothetically, as a norm of investigation, in the interpretation of experience''.  The sole meaning and justification of such a principle rests upon the fact that, through its application, it will be possible to attain the ``synthetic unity of phenomena in their temporal relations'' (``\emph{synthetische Einheit der Erscheinungen nach Zeitverh\"altnissen}''), that is, lawful explanation of all observed phenomena.  The guiding norm itself is unconditioned, and so ideal: it is just the ``idea of unity of nature, of univocal determination itself''.  Nonetheless, with the requirement of general covariance, the general theory of relativity has given a new meaning to the Kantian idea of unity of nature as a ``unity of determinate functional relations'', assimilating under arbitrary transformations of the coordinates, all measurement results obtainable in particular reference systems.  The concept of object of physics has become the concept of what remains invariant under such arbitrary transformation, and dynamics is more and more resolved into geometry (\emph{reine Metrik}), a tendency, Cassirer observed, most clearly evident in Weyl's treatment of general relativity.
    
    \citep[p. 43]{Ryckman2005}
\end{quote}

\begin{quote}
    Cassirer thus represented the principle of general covariance as a qualitatively new stage in the continual development of the conception of physical objectivity stretching back to the birth of modern science.  In that process can be documented a progressive ``movement of thought'' (\emph{Denkbewegung}), an unmistakable trend of the replacement of ``substance'' or ``thing'' concepts, uncritical ``anthropomorphic'' modes of representation, by functional and relational concepts.  A yet further step, and a decisively higher stage of ``de-anthropomorphization'', has been taken with general relativity, for in its wake, the concept of ``physical objectivity'' incorporates the \emph{methodological norm} of general covariance: that the laws of nature find their only natural expression in generally covariant equations.  Although ``objects of experience'' require the choice of a suitable coordinate system (through the concrete calculation of a result to be compared with experimental data), there can be no general \emph{preferred} set of coordinates (reference frames, or foliations of the space-time manifold).  Singling out any reference frame for such distinction violates the spirit, and the letter, of general covariance, according to which \emph{any} adopted reference object is itself a dynamical, not an absolute, object.  As so ``relativized'', the fundamental concept of ``object of nature'' is not a picturable but a ``pure structure'' entity identifiable only in relation to other structures of the field.  Deprived of the anthropomorphic stage of a background space-time that is always presupposed picturable or visualizable ``thing-concepts'', such a dynamical object is completely resolved into the pure measure relations (\emph{reine Ma{\ss}beziehungen}) of a fully relational dynamics.
    
    \citep[p. 45]{Ryckman2005}
\end{quote}

- Reichenbach's (neo)Kantian interpretation towards realism, Cassirer's towards idealism

\begin{quote}
    Stemming from a fundamental difference in the interpretation of Kantian epistemology, the 1920 monographs of Cassirer and Reichenbach on the theory of relativity point in diametrically different directions for subsequent philosophy of science.  Each proposed a conception of the ``relativized \emph{a priori}'' as meta-level constitutive principles governing empirical laws.  However, the ``relative'' standing of Reichenbach's principles of coordination is counterbalanced by two epistemological methods consonant only with the commitments of scientific realism, a fact evidenced in his later writings, even as Schlick retreated from realism to a Wittgenstein-inspired positivist distaste of all ``metaphysics''.  To philosophers not independently persuaded of the virtues of realism or positivism, Cassirer, the ``historical'' philosopher, proposed a significantly richer appreciation of the epistemological innovation of the theory of general relativity.  While lacking the language and mathematical tools of symmetry readily available today, Cassirer nevertheless succeeded in grasping that the revolutionary epistemological idea of general relativity lies in general covariance, the regulative idea of all fundamental physical objects interacting through dynamical laws completely without reference to a background space-time.  Such a conception of general covariance as an ``idea of reason'' constraining fundamental physical theory is no longer constitutively \emph{a priori} in Kant's sense.  That \emph{regulative} ideals can play a heuristic but still \emph{constitutive} role in physical cognition is then not Kantian orthodoxy.  But it is universally agreed that general relativity needs occasion some revision or clarification in those deep, and often murky, waters.
    
    \citep[p. 46]{Ryckman2005}
\end{quote}

- Einstein read Schlick's book on epistemology \emph{Allgemeine Erkenntnislehre} and thought Schlick was intelligent and should get a professorship (and perhaps helped him get Vienna position).  

\begin{quote}
    This reading had a visible influence in Einstein's widely read essay ``Geometry and Experience'' (``\emph{Geometrie und Erfahrung}''), originating as a rare public lecture on 27 January 1921.  There, Einstein not only commended the book's epistemological emphasis of the method of implicit definition, he also wrote of a ``geometrical-physical theory'' as ``necessarily unintuitive, a bare system of concepts'', the geometrical and some of the physical laws of which are conventions, whose relation to ``experimental objects of reality (experiences)'' is one of ``coordination'', all views found in Schlick's book.  Perhaps having this reference in mind, the mathematician Hermann Weyl lamented to Edmund Husserl in March 1921 (see chapter 5, \S 5.2.1), that Schlick's epistemology book had a considerable resonance with ``the leading theoretical physicists''.  The editors of the \emph{Kant-Studien} could not possibly have regarded Schlick as neutral toward the Kantian or ``critical'' (``\emph{kritizistische}'') philosophy, for his epistemology book pointedly defended, in explicit opposition to all varieties of Kantianism (including Husserlian phenomenology) and Machian positivism, a form of scientific realism.  Nonetheless, Schlick, as both philosopher and \emph{Fachmann} regarding the theory of relativity, could be regarded as uniquely placed to assess what would be the most philosophically sophisticated attempt to link the general theory of relativity with the broad trend of Kantian thought.
    
    \citep[p. 49]{Ryckman2005}
\end{quote}

- Schlicks assessment turning point against kantianism and towards logical empiricism, and was unfair towards Cassirer's neo-kantianism

\begin{quote}
    Third, and finally, on a careful reading, Schlick's argument bears not upon Cassirer's understanding of the ``synthetic \emph{a priori}'' as regulative principles or ``rules of the understanding'' governing the development of concepts of physical objectivity, but upon a more traditional Kantian conception of apodictically certain and unrevisable principles.  Perhaps to avoid tiresome discussions of Kant interpretation, perhaps because he considered it the identifying characteristic of all Kantian philosophy, perhaps for rhetorical purposes, Schlick located ``the essence of the critical viewpoint'' in the claim that the constitutive principles of physical knowledge 
    
    \begin{quote}
        are to be \emph{synthetic judgments a priori} in which to the concept of the \emph{a priori} inseperably belongs the characteristic of \emph{apodeicticity} (universal, necessary and inevitable validity). [1921 Critical or Empiricist Interpretation of Modern Physics]
    \end{quote}
    
    The ``critical'' (i.e. neo-Kantian) philosopher must maintain this understanding of the synthetic \emph{a priori}, or else, in Schlick's lexicon, he is no longer a ``critical'' philosopher.  Still more, continuing a reading of Kant given in his \emph{Allgemeine Erkenntnislehre} (1918), Schlick refused to allow that the Kantian doctrine of ``pure intuition'' could ever be purged of its psychological trappings and so could not be revised or refined to be a ``method of objectivification'' in the manner Cassirer had adopted.  The gauntlet thus laid down, Schlick had little trouble in dispatching such claims of Cassirer's book as could be represented in this fashion, misleadingly, since Schlick completely ignored the genetic character and historical evolution of the ``regulative principles'' and ``rules of the understanding'' that comprised the core of Cassirer's account of the development of the concept of physical objectivity culminating in general covariance.  Accordingly, with this declaration the issue is no longer joined, for Cassirer had been denied any possibility of distinguishing his conception of constitutive \emph{a priori} principles from an orthodoxy that Schlick could easily show was rendered obsolete by the new physics.  In one recent assessment, Schlick's ``challenge'' to Cassirer to produce examples of such unrevisable synthetic \emph{a priori} principles ``represents a fundamental misconstrual of Cassirer's conception of the \emph{a priori}''.  In any case, Schlick's traditional reading of the synthetic \emph{a priori} was not a necessary one, as he himself already knew.  The principal thesis of a 1920 monograph from the neo-Kantian perspective of Schlick's logical empiricist colleague-to-be, Hans Reichenbach, denied that apodictic certainty is inseparably attached to synthetic \emph{a priori} principles.  Schlick had reviewed Reichenbach's book and subsequently expended considerable effort, in correspondence with Reichenbach in late November, 1920, arguing that Reichenbach's theory-relative conception of synthetic \emph{a priori} principles did not suffice to distinguish them from conventions in the sense of Poincar\'e.  Showing some understandable sensitivity on this interpretive point, in his essay Schlick still insisted on this view of the \emph{a priori}, while stating that his was ``an inquiry directed to systematic rather than historical questions''.  Thus, he gave himself an easy target indeed.
    
    \citep[p. 50-51]{Ryckman2005}
\end{quote}

\begin{quote}
    Based on a highly selective reading of these texts of Einstein, and of Helmholtz, Schlick's new empiricism is an almost ``on-the-spot'' improvisation, seeking to find the resources for an empiricist interpretation of the metric of spacetime in observable facts about measurement bodies and light rays whose fiduciary behavior has been fixed by conventional stipulation.
    
    \citep[p. 52]{Ryckman2005}
\end{quote}

\begin{quote}
    Yet while celebrating Helmholtz as the Elijah of the new empiricism, Schlick also found it necessary to modify his previous unqualified endorsement of the holist conventionalism he had associated with Poincar\'e, a change that occasioned wider reaching ramifications within his general epistemology.  Thus, in order to present the ``consistent empiricism'' he opposed to the neo-Kantians, Schlick eliminated the gray area recognized in the first edition of that work between ``hypotheses'' and ``definitions''.  In the book's second edition (1925), the classification of types of judgment was revised to feature a sharp distinction between definitions and empirical judgments.  This new discrimination was the prototype for the particular version of the analytic/synthetic distinction that became a defining characteristic of logical empiricism and the principal target, in an ironical turn of the wheel of fortune, of Quinean holism.
    
    \citep[p. 52-53]{Ryckman2005}
\end{quote}


\subsection{Weyl}

Weyl here clearly seems to be indicating not a structural realist view, but an idealist view, which is not anti-realist.  The symbols are something to satisfy the idealist agent, not the fundamental structures of reality, and not making transcendental reality bare to the mind.  [IS THAT ACCURATE?]

\begin{quote}
    The stages through which research in the foundations of mathematics has passed in recent times correspond to the three basic possibilities of epistemological attitude.  The set-theoretical approach is the stage of \emph{naive realism} which is unaware of the transition from the given to the transcendent.  Brouwer represents \emph{idealism}, by demanding the reduction of all truth to the intuitively given.  In axiomatic formalism, finally, consciousness makes the attempt to `jump over its own shadow,' to leave behind the stuff of the given, to represent the \emph{transcendent}---but, how could it be otherwise?, only through the \emph{symbol}.  Basically, the idealist viewpoint in epistemology has been adhered to by occidental philosophy since Descartes; nevertheless, it has searched again and again in metaphysics for an access to the realm of the absolute, and Kant, who meant to shoot the bolt once and for all, was yet followed by Fichte, Schelling, and Hegel.  It cannot be denied that a theoretical desire, incomprehensible from the merely phenomenal point of view, is alive in us which urges toward totality.  Mathematics shows that with particular clarity; but it also teaches us that that desire can be fulfilled on one condition only, namely, that we are satisfied with the symbol and renounce the mystical error of expecting the transcendent ever to fall within the lighted circle of our intuition.  So far, only in mathematics and physics has symbolical-theoretical construction gained that solidity which makes it compelling for everyone whose mind is open to these sciences.  Their philosophical interest is primarily based on this fact.  \citep[p. 65-66]{Weyl1949}
\end{quote}


Objectivity can only come from experience (context of geometry).  Section 13 "The Problem of Relativity".

\begin{quote}
    Our knowledge stands under the norm of \emph{objectivity}.  He who believes in Euclidean geometry will say that all points in space are objectively alike, and that so are all possible directions.  However, Newton seems to have thought that space has an absolute center.  Epicurus certainly thought that the vertical is objectively distinguishable from all other directions.  He gives as his reason that all bodies when left to themselves move in one and the same direction.  Hence the statement that a line is vertical is elliptic or incomplete, the complete statement behind it being something like this: the line has the direction of gravity at the point $P$.  Thus the gravitational field, which we know to depend on the material content of the world, enters into the complete proposition as a contingent factor, and also an individually exhibited point $P$ on which we lay our finger by a demonstrative act such as is expressed in words like `I,' `here,' `now,' `this.'  Only if we are sure that the truth of the complete statement is not affected by free variation of the contingent factors and of those that are individually exhibited (here the gravitational field and the point $P$) have we a right to omit these factors from the statement and still to claim objective significance for it.  Epicurus's belief is shattered as soon as it is realized that the direction of gravity is different in Princeton and in Calcutta, and that it can also be changed by a redistribution of matter.  Without claiming to give a mechanically applicable criterion, our description bears out the essential fact that objectivity is an issue decidable on the ground of experience only.  It also accounts for the two main sources of the error so often committed in the history of knowledge, that of mistaking a statement for objective that is not: (1) one overlooked certain relevant circumstantial factors on which the meaning of the statement depends although they are not mentioned explicitly in its elliptic form, (2) though these factors were recognized, one did not investigate carefully enough whether or not the truth of the statement is affected by their variation.  It is no wonder then that at several phases in the course of the history of science the realm of that which is considered objective has shrunk.  \citep[p. 71-72]{Weyl1949}
\end{quote}

\section{Introduction}

If we are to load the truth values into our statements about the world, there will be a structure to our interactions with the world. In a technical sense, our observations will be augmented by measurement devices, and these measurement devices as part of the world will have dynamics under certain measurement conditions.  

The dynamics of the total system can transition to a state that we distinguish as an informative signal, a meaningful event that we call a ``measurement''.  A canonical formal representation of measurement events can be characterized by certain states that are invariant or symmetric under certain operations.  The information of these states is more robust, and if we are carefully explicit about how representations of these states reflect the knowledge of an agent, robust states can be distinguished from other states due to information-theoretic properties.

Innovations in what a measurement might consist of, or the theoretical possibilities of what an agent could learn from measurement interactions, will adjust the information-theoretic characteristics that an engineer or decision maker could exploit.  The structure of our knowledge of the world is dependent on our representation of measurement interactions in a theory of the world (which includes and is not separate from the measurement apparatus).  This structure can, will, and probably should change in at least some accordance to a relevant domain.

It is not my intention to defend any particular historical strain of empiricism.  Indeed, not everyone is convinced there is much of a consensus among empiricists beyond the basic assertion that at least a very important class of statements about reality find all or most of their meaning and justification through empirical inquiry and the experience of events observed in the world.  

Rather, as other

\subsection{The Descent in an Idealist Gradient}



[ADD PSILLOS PATHS TO STRUCTURAL REALISM.  AINSWORTH AND MAXWELL TOO?  ZAHAR TRANSCENDENTAL IDEALISM. SEP.]



I hope to sketch in what follows the number of angles, hints, and potential philosophical burdens in the philosophy of physics which might lead one unknowingly down a path towards idealism.  I am calling this, tentatively, the descent down an \emph{idealist gradient}.  For philosophers, the recognition of this gradient from a metaphysical point of view, from a birds eye view of the idea landscape, is crucially important.  Historical views indicating in this direction, thought to be coherent by their proponents, cannot be scavenged piece-meal by modern philosophers without recognizing that the pieces originally pointed in a particular direction.

To this extent, for this proposal, I will be sketching the positions of a few prominent philosophers and philosophical positions, using \emph{-isms} liberally to provide a coarse-grained view of the landscape.  For example, the \emph{-isms} of: structuralism, realism, empiricism, rationalism, intuitionism, and of course idealism.  The central characters in the story, for now, are Poincare, Eddington, Cassirer, Weyl, Bohm, 

The end goal of sketching this gradient, is to eventually evaluate certain foundational positions in the philosophy of physics with respect to this gradient.  In particular, those positions of Bohm (and, to the extent it is related to Bohm's ideas in particular, to the proponents of Bohmian mechanics) and QBism.  


If we can model the philosophical foundations of physics, specifically concerning the work of a number of prominent thinkers on quantum and relativistic foundations, as a surface or fabric that has a gradient, is there an attractor or minimum point in the surface?  In other words, if we start from phenomenology, rationalism, structuralism, or empiricism, are we bound to a trajectory towards some area in the fabric?  

In this proposal, I will suppose that the question is a worthwhile one to ask, and consider an affirmative answer.  For a slogan underpinning the investigation to follow, I will suppose that there is an \emph{elephant of idealism} that, when acknowledged, can both explain and explicate why we might see aspects of the gradient as pulling us towards an idealist attractor.  The ultimate nature of this idealist attractor, and it's relation to e.g. Kant and Hegel and others, is still fuzzy and unclear.  

However, at this preliminary stage, I hope to convincingly show that there is a general gradient towards idealism that has gone unnoticed which should be acknowledged and reckoned with by the foundations of physics community.  Whether the anomalies are sufficient to pick up a potentially more parsimonious idealist solution, it is in my opinion far too early to tell.  It does seem, however, than an idealist position should not be expected to fare worse than other highly speculative answers to major philosophical issues in the foundations of physics.  This should be unsurprising, given the relative lack of attention in analytic philosophy departments (that do philosophy of science and in particular philosophy of physics) to e.g. the intricacies of ``continental'' philosophy like Hegelianism and synthetic metaphysics.\footnote{Or, at least, this is the present author's experience, at the risk of generalizing.  Perhaps there is a network of individuals and their work that I am wholly ignorant of!}


- Eddington Quote
- Clifford Quote
- Ryckman on Weyl, Cassirer, and importantly Husserl
- Dont necessarily need to find one particular idealist position but can explore cluster for hints of what might apply or be useful for understanding quantum foundations and measurement in a participatory view.

%\subsection{Quantum Mysticism and Woo Woo}


%\section{Structure of Empirical Events}

\section{Quantum Bayesianism}

The normatively compelling aspect of Bayesian probability theory and epistemology is usually summed up with reference to Dutch Book Arguments (DBA).  Alternatively, there are reasons to prefer what are called \textbf{proper scoring rules}.  I think it is reasonable to understand de Finetti considered proper scoring rules to be superior to DBA for the purposes of purity of elicitation and philosophical consistency avoiding game theoretic problems having to do with the information from published books of bets from the bookies.  In a previous unpublished manuscript while at the MCMP I noted as much.  [CITE OR BRING PASSAGES FROM THAT PAPER]  See e.g. \citep{deFinetti1981a, deFinetti1990, deFinetti2008}.  I would be interested if historians have a definitive account of de Finetti's position, but for now I would like to take what I find to be a reasonable interpretation and build upon it.




For present purposes, it is important to note that, compared to objective or more physical interpretations of probability, these accounts treat probabilities as formal epistemological objects of a subjective agent first and foremost.  Probabilities \emph{are} subjective degrees of belief, and there are arguments that, for an agent, these numbers should behave according to certain rules.  Otherwise there is trouble: sure losses, incoherence, irrationality...

If quantum probabilities might be of the same Bayesian character (subjective, epistemological, normatively compelling) it might be in part because they (the numbers) are generated by a more general procedure, in a sense inheriting the account from ``classical'' probabilities.  However, there are important differences which make them seem much more \emph{objective}.  Surely, a quantum physicist or quantum information theorist should also respect some normative epistemological principles.  
 

% \section{Revising Logic}

% Perhaps one of the most notorious and ambitious attempts at revising the structure of our knowledge of the world can be found in the attempts of characterizing a quantum logic.

% For many reasons, a number of these projects have either been abandoned, or failed to find killer apps which convince adopters.  Taking a step back, even some who might be open to a revision still find the motivation unclear why a logic characterizing interactions with the quantum world would be relevant for human reasoning.  

% A related project has tried to make the case on an even deeper level: that cognition is quantum-like, and follows quantum structural properties.  

% CITE ALSO AERTS AND KHRENNIKOV



\section{Theory-Laden Observation}

Or just mention in intro?



\section{Local vs. Non-Local}

One lesson from quantum foundations, relevant also to the discussion over implications for what form empiricism can take, is that sometimes what is ruled out isn't so clear.  For example, von Neumann was considered to have proven that \emph{no} hidden variable amendments to quantum mechanics would be possible and consistent with observations.  [SOURCE]  This was the received view, until John Bell helped clarify exactly what assumptions, and for what kinds, of hidden variables von Neumann's theorem applied.  It was \emph{local} hidden variables that were ruled out, but certain \emph{non-local} amendments like Bohmian mechanics are legitimately viable.  [SOURCe]


THIS PARAGRAPH SEEMS LIKE NON-SEQUITUR WHAT WAS I THINKING?
Likewise, we might take care to interpret the upheavals in positivism, logical empiricism, and any associated framework for loading up meaningful statements about the world from sense observations.  What did objections \emph{actually} show was untenable about empiricism?  Certain amended forms of empiricism, like van Fraassen's \emph{constructive} empiricism, or slight variations called \emph{structural} empiricism, might be just fine.  [CITE VF AND OTAVIO BUENO]  Indeed, I will contribute to the arguments in favor of the general direction of these empiricist responses. 

The point is that fundamentally, local interactions (if we grant that that even makes sense) are somehow structural windows in the interface that contain non-local information of "the world" regardless of what you think the world is.

% \section{Holism and Theory-Laden Perception vs. Non-local interface of reality}

% What I am talking about is not just a flavor of theory-laden observations.  Rather, someone who likes to talk about theory-laden observations might also appeal to the non-local phenomenological structure of experience as a concrete reason \emph{why} observations are theory-laden.  I can imagine such an account, however I am also skeptical that these levels and concepts relate in a rigorously corresponding manner.

% On the one hand, I am still sympathetic to the notion that the metaphysical implications of relativity and quantum non-locality are not particularly relevant for the sense-making of an evolved human nervous system.  Yet, there is still an attractor that seems to draw many researchers towards the idea that these metaphysical implications \emph{must} be acknowledged.  If not for everyday life, at least for scientifically minded philosophy and transcendental phenomenology.  It seems likely that if we can just grasp in our minds the metaphysical implications of what it appears like the world is like from our experiences (of consciousness, of experimental observations, etc.) then we can see new nails in the frame of reality that beckon hammering.

% \section{Nonlocal phenomenology}

% \section{Structural phenomenology}

% Surely structural empiricism (of some sort) is safer than the "empirical" data.  They have obvious recourse to phenomenological structures of a special kind.  But it isn't clear once you go a bit further to idealism or a mind monism.

% If the "empirical data" are just "sense data, reports of observation", how are they different from other sense data if EVERYTHING is just sense data in a form of idealism?  Why are those particular sense data worth saving?  You have to tell a story about why THAT sense data, from the scientists who think they are observing and interacting with the world to produce "empirical data", is still "empirical data".

% How do we distinguish the mental substance forms of "empirical data" from other sense data and other mental substance forms that are not worth saving as fundamental structures/data of reality?

% I think there are potentially viable forms of "materialist ontological structural realism" as opposed to what I am calling for now "pragmatic/phenomenological ontological structural realism"

% So the position is something like that of Weyls, developed by Ladyman and French and I suspect is what Bitbol is working on.  Cassirer and Eddington are also in the same area.  Something in that vein, but I am only now collecting literature for the research project proposal.

% Basically the idea is that mathematical groups characterize certain symmetries of observation.  Whether these observations occur only in "experimental apparati" or in the phenomenological experience of a conscious agent is the part I am struggling with (even Heisenberg was already talking about something similar with the Heisenberg "cut").  Helmholtz I guess was the originator of group theory notions in the theory of perception.

% The mathematical structure is "real" in some fundamental sense.  Some people then might go towards Pythagoreanism, where math is fundamental in the universe instead of substance, like Tegmark.  Some might go towards idealism.

% \section{The slide to idealism}

% Suppose our mathematical descriptions of the quantum world (or what we take to be descriptions of an external quantum world) are instead primarily to be understood as descriptions of our \emph{beliefs} about the subset of phenomenological experiences we label the  ``quantum world''.  What does the measurement problem mean under this characterization?


% But even under that boost, I still see the (relatively minor) point that the wheat of empiricism, under an idealism/process philosophy lens and without the chaff of dumb logical empiricism, can still make sense.  I was saying it another way (either with you or with others): you can bring "empiricism" (i.e. loading meaning into statements via "observation") all the way up into the observer.  That is, you move the "cut" between observations and the subject of the observations from external apparatus out there in the world, up to the point in the phenomenological experience of an agent (from there it seems a relatively trivial step further into idealism).

% You are just getting hung up on the mere suggestion of (the interpretation of Harris) any salvaging of "empiricism" whatsoever, even though you keep reassuring me (that Harris also says) we can keep everything from science.  It is just absorbed in the idealist perspective.  I am not "so concerned" about it, except in relation to YOUR resistance to the suggestion that the phenomenological structure of "empiricism" can stay.  It isn't salvaged FROM idealism, but salvaged WITHIN it.

% If I am a positivist, it is in a form that was rare or non-explicit, or not well worked out by the positivists.  I am not sure yet where Weyl fits, but I think much closer to you and Harris, but maybe still with a focus on mathematical structures of interactions (observations) between conscious agent and the world (what I am calling structural empiricism)

% just because you like QBism or think it is metaphysically right doesn't mean there aren't fully consistent alternatives, or that QBism can't just be a structurally epistemic empiricist middle ground. 

% Probably that is where I am at and have been for a while but there isn't a lot of work on QBism nor "structural empiricism" let alone the overlap, although one might say the correct interpretation of what qbists are saying is a form of structural empiricism...  I still think you should try to come around to the middle ground I am sniffing out before you continue with Hegel, just so you can get a grip on the kind of "progress", if there might be any, with analytic/logical/empiricist/positivist philosophy.

% The trick is that I think for you to get to that middle ground I do think we need to actually make some progress on e.g. Weyl that hasn't already been widely recognized

% \section{Structural Realism}

% What does non-locality mean for a structural realist?

% \section{More notes}

% Fourth, the quantum measurement problem is also not the same thing as quantum uncertainty associated with a measurement, or the uncertainty principle (i.e. a general feature of Fourier transforms).

% Fifth, the observer effect might "apply to conscious agents/observers" if I understand what you mean, e.g. some psychological phenomenon about perception, but the quantum measurement problem is specifically about the appearance of quantum state collapse in (representations of) the quantum world, and what it means and how to interpret it.   You have to spell out how/why consciousness would affect the quantum world (not sure why you need/want to do that anyways if you think all of quantum mechanics are, like Hoffman notes, structures of experience and space time external reality is likely not as real as consciousness anyways...)

% hings like decoherence and "Heisenberg cut" are relevant here.  A scientific epistemology of the world pretty much requires writing down some basic math.  That math has certain invariances and structures to represent the displayed outcome of a measurement in a total system (= detector + system).  The detector is a part of the same reality.  They are entangled.  To say it alter's reality seems like a mistake to me.

% I would think that the discussion around Heisenberg cut and decoherence and collapse of wave function (from apparatus) in quantum theory could be used to marshal an argument against the latter half of your sentence.  I.e. quantum mechanics really does somehow decohere/collapse into something completely classical (and not waves), so the brain and mind and consciousness are completely cut off from the oneness at that lower level.  I think that would be wrong, and I think no collapse of state vector probably correct, but the persistent waves do not imply that they are of the same substance and interactable with whatever consciousness is.  There is work to do to to rule out some kind of dualism.

% The GENERAL IDEA of an "observer effect" is somewhat classical to begin with...  IF it applies to quantum measurement, you have to carefully relate it through the uncertainty principle... but the whole thing stinks and undermines itself, since the people like Heisenberg and Bohr were trying to provide new quantum concepts in the first place that were not dependent on the classical physical concepts.  Which is why so many people go in ANOTHER DIRECTION from there, proposing various interpretations/solutions to The Measurement Problem, none of which would equate it AT ALL with some sort of "observer effect".

% The math we use to represent a quantum system in an experiment says one thing.  Then we have an apparatus whose state changes to something, and we then have another math description.  How do we relate those two descriptions?  Qbists e.g. would say that our description is like subjective degrees of belief about the way the world appears, and not at all [or not as much as other interpretations] representing anything about the world.  In that picture, for example, there is no "observer effect".

% I'm not sure what you mean by it's being BOTH.  So, it would help you to understand the math part of the measurement problem.  Because the math is how we are representing what we think we know about the world.  It might be BOTH, but then that is just one interpretation.  An idealist could do this, unclear about the phenomenologist.  This is kind of the point of my current work on project proposal for the postdoc, whether the phenomenological take slides into idealism.  [You said yes, because of Hegel or Husserl, and I would like to know that specifically]

% If you start talking about the measurement problem, and "having" an interpretation of it, it is probably necessary to actually grasp what is going on.

% For example, I thought we were in agreement that science and scientists, the majority of them, are in a krisis and devoid of proper metaphysics.  But then you come in guns-a-blazing claiming that THESE scientists, over here, obviously aren't caught up in the century old metaphysical quagmire.

% But to me, they ABSOLUTELY ARE!  Especially the ones that are still repeating century old Bohr and Heisenberg equating the measurement problem to some kind of observer effect!  That is why I keep harping on Bohmian mechanics, and although I find issues with many worlds, it is still better (metaphysically speaking) than the observer effect subject/object hard cut that is involved in Heisenberg's discussions.

% And the math makes it SO MUCH CLEARER what you have to do to "solve" the measurement problem.  Because you have to say whether the math of "measurements" is a property of our epistemology/phenomenology/agent or a property of the world, and that is the meat of the shakedown of different interpretations (one of the meaty aspects).

% The word "problem" in the measurement problem is referring to a problem of interpretation (which is the "right" one, and reasons why...).  The math itself doesn't tell you.

% It doesn't mean there is a general problem with measurements, like an "observer effect" asserts, although one could maintain the situation in the quantum world is such as to make it look like that, and emphasize the quantum uncertainty relations (which are general properties of Fourier transforms between non-commuting "observables", or wave-like systems).  But as Heisenberg will tell you, one can always move the "cut" in your description arbitrarily (i.e. the threshold where a quantum description becomes classical).

% Still, the uncertainty relations are not the same as the measurement problem.  If one is very careful and nuanced in interpreting the math + experiment descriptions, there are some relationships that can be drawn, since ultimately the observables can be connected to experiments and measurement interactions.  But even the editors of the wikipedia article on uncertainty relations says they are often confused with an "observer effect".  (Probably in part due to Heisenberg himself...)

% Now, some go a step further to say that the problem of measurement interpretation cannot be solved by just shifting the "cut" between "observer" and "observed", and say the Schrdinger equation of all matter in the universe is what is really real (setting aside any mind or consciousness for the moment).  These are the increasingly popular "many world" interpretation adherents.  Contrary to other interpretations of QM, there is no "collapse of the wave function" or "observer effect" or "decoherence" in reality as reality is in itself.


% A quantum state is possibly represented on paper by $\ket{psi} = a\ket{0} + b\ket{1}$.  Both parts (1 and 0) are crucial for our representation on paper.  However, when we measure, we NEVER observe both 0 and 1.  Only either with probabilities determined by the amplitudes (a and b).  So, if we observed 0 when we measured, what happened to the 1 component?  Was it really ever there?

% Collapse theories either talk about the physical dynamics of collapse or some sort of epistemological collapse.  Other interpretations say that quantum mechanics is only ever unitary, i.e., all of the "parts" keep going whether we saw them or not.

% I never really understood why it was necessary to use the talk as if there are literally multiple parallel "worlds" or "universes"  but I'm also not an expert.  For sure they get more press.

% Depends on the details.  Entanglement is for some a property of nonlocal reality, some might be a bit more cautious and relate it just to phenomenology of measurement correlations... sounds like a sexy mash up of ideas but really not sure if e.g. Schrdinger was aware of Hegel (and if not, probability that they mean the same thing is very low, and even if they could be construed as talking about the same "entanglement" somehow that connection would always have an achilles heel)

% Second, the quantum measurement problem is not the same thing as an "observer effect", which is much more general and present in many other areas (e.g. psychology, biology, etc.), not just the quantum world and quantum "observations".  The method of observation, or interaction of measurement apparatus with the system to be measured, affects the data.  Simple.  One response to the quantum measurement problem essentially categorizes it as an observer effect.  Make sure that you understand this point.  Other responses are also perfectly legitimate, and naturally has lead to heated arguments for 100 years in quantum foundations.  If the quantum measurement problem is about the apparent collapse of the wave function, then responses to the measurement problem seek to explain or interpret this apparent collapse.  Some responses argue that there is no collapse at all.  The wave function dynamics of the combined quantum system + measurement apparatus are fully coherent and keep evolving as a single coherent wave (somehow, perhaps here or perhaps in multiple worlds, etc.)

% Fourth, the quantum measurement problem is also not the same thing as quantum uncertainty associated with a measurement, or the uncertainty principle (i.e. a general feature of Fourier transforms).

% Fifth, the observer effect might "apply to conscious agents/observers" if I understand what you mean, e.g. some psychological phenomenon about perception, but the quantum measurement problem is specifically about the appearance of quantum state collapse in (representations of) the quantum world, and what it means and how to interpret it.   You have to spell out how/why consciousness would affect the quantum world (not sure why you need/want to do that anyways if you think all of quantum mechanics are, like Hoffman notes, structures of experience and space time external reality is likely not as real as consciousness anyways...)

% The best way to interpret that sentence in a veridical way that is pretty uncontroversial (compared to that outrageous statement) is that the interaction of a quantum system with a measurement apparatus appears to change the quantum state.  But what is the quantum state?  Even quantum bayesians are not required to assume consciousness monism of some kind.  They just take the quantum state to be a probability distribution reflecting knowledge about the world, but that world is still there!

% The measurement problem arises because of linear dynamics of the wave equation (or of a state represented in Hilbert space).  But we only observe one component, not both, when the system interacts with the measurement apparatus (which is not presumed to be conscious, absent some very specific assumptions about the world).

% So our equation, that we wrote on the paper, to describe the quantum system is post-measurement "collapsed".  So what does that mean?  Did the physical system actually collapse in a non-deterministic or random manner?  Or did the other half keep going somewhere else?

% They indeed talked about these kinds of implications, yes!   This is part of the reason that the mistaken idea has continued to persist in things like "What the Bleep do we Know" and quantum mysticism.

% Again, though, if you are talking about the causal effects on the quantum system by the observation, that is coming only from the physics of the apparatus and not by the conscious agent that set the system up.  Even if we could somehow slot the human into the apparatus such that the rods and cones in our eyes "detected" the photons for some measurement outcome... consciousness is not causally effective.

% Or, if it was in some convoluted way because the person consciously concentrated on squinting such that the rods and cones were set up right to be a photon detector (which eyes are lol), it would be unclear why that is profound.  Certainly it wouldn't entail that there is a substance to consciousness.  Alternatively, if you assumed a substance to consciousness, you have to argue why it is the same as the matter wave substances.  I really see similarities to the monism and dualism debate, if I'm not mistaking something here.


%\section{Is Phenomenology more Pragmatic than a form of Rational Idealism?}

% \subsection{Sliding into Idealism}

% On the topic of the role of the mind in the apparent collapse of the wave function, Bohm notes a potential slide into some form of idealism (generally defined, in the German idealist context, as a commitment to a universal mind of some sort).  Without commenting on the accuracy of the reconstruction, Bohm's characterization of the slide starts from von Neumann, through Wigner, but he is skeptical of what it would mean to resolve the problem from the idealist perspective of a universal mind.  Bohm begins by discussing issues with where to locate the `cut' of a collapse in von Neumann's view, and how this problem arises from assigning even a minimal ontology to the quantum state (in contrast to e.g. Bohr).

% \begin{quote}
%     However, in so far as von Neumann effectively gave the quantum state a certain ontological significance, the net result was to produce a confused and unsatisfactory ontology.  This ontology is such as to imply that the collapse of the wave function must also have an ontological significance (whereas for Bohr it merely represents a feature of the quantum algorithm which arises in the treatment of a new experiment).  [CITE]p. 23
% \end{quote}

% Noting how another, third, apparatus could be introduced, and another on top of that, and so on, there is a meta-collapse problem in the sense that a `cut' is arbitrary and there is an indefinite regress.  Where would this regress end, even in principle?  

% \begin{quote}
%     And, as von Neumann himself pointed out, one could even include parts of the human brain within the total quantum system, so that the collapse could be brought about as a function of the brain.
    
%     It is evident that this whole situation is unsatisfactory because the ontological process of collapse is itself highly ambiguous.  Perhaps Bohr's rather more limited ambiguity may seem preferable to von Neumann's indefinitely proliferating ambiguity. [CITE]p. 23
% \end{quote}

% Then, Bohm notes that Wigner goes even further than von Neumann's speculation on the brain, to that of the \emph{mind} (and noting also a related sentiment from Pauli).  [CITE Bohm's refs on Wigner and Pauli]

% \begin{quote}
%     Wigner has carried this argument further and has suggested that the above ambiguity of the collapse can be removed by assuming that this process is definitely a consequence of the interaction of matter and mind.  Thus he is, in effect, placing the cut between these two and implying that mind is not limited by quantum theory.  (Pauli has also felt for different reasons that mind plays a key role in this context.)
    
%     We can see several difficulties in the attempt to bring in the direct action of the mind to give an ontological interpretation of the current physical laws of the quantum theory.  Thus in a laboratory, it is hard to believe that the human mind is actually significantly affecting the results of the functioning of the instruments (which may, as we have already pointed out, be recorded on a computer that is not even examined for a long time).  Moreover quantum theory is currently applied to cosmology, and it is difficult to believe that the evolution of the universe before the appearance of human beings depended fundamentally on the human mind (e.g. to make its wave function `collapse' in an appropriate way).  Of course one could avoid this difficulty by assuming a universal mind.  But if we know little about the human mind, we know a great deal less about the universal mind.  Such an assumption replaces one mystery by an even greater one.  [CITE] p. 24
% \end{quote}

% It is obvious here, given the context of the ideas of e.g. Wigner, why Bohm mentions some kind of universal mind.  But, if strains of German idealism are, for example, where a worked out theory of universal mind is to be found, is his quick dismissal sufficient for us to ignore such a position?  Indeed, Bohm seems to think that even Bohr's position is better and more consistent than any of these points of view (at this point in his analysis).

% Bohm does also discuss many minds, and problems with it, motivating his own position on the implicate order [CITE p. 311-, 381-]

% [REWRITE/EXTEND ABOVE]

% \section{Bohr and the phenomenological boundary of empiricism}

% As discussed by none other than Bohm (whose position depends on the ability to point it out), Bohr's view that has had a stranglehold simply \emph{assumes} that physical concepts derive meaning via their connection with observation and measurement.

% \begin{quote}
%     We can summarize Bohr's position as saying that all physical concepts must correspond to phenomenon, i.e. appearances.  Each phenomenon is an abstraction.  This is also true classically.  But because the correspondence between the phenomenon and the independent reality which underlies it may, in principle, be unambiguous, and because all the phenomena are mutually compatible, we may say that the independent reality can be reflected completely in the whole set of phenomena.  This means in effect that we can know the independent reality itself.  But quantum mechanically we cannot apply all relevant abstractions together in an unambiguous way and therefore whatever we say about independent reality is only implicit in this way of using concepts.
    
%     What then is the meaning of the mathematics of the quantum theory (which is very well defined indeed)?  Bohr describes this as the \emph{quantum algorithm} which gives the probabilities of the possible results for each kind of experimental arrangement.  Clearly this means that the mathematics must not be regarded as reflecting an independent quantum reality that is well defined, but rather that it constitutes in essence only \emph{knowledge about the statistics of the quantum phenomena}.  [CITE]p. 17
% \end{quote}

% Stated another way, in the limit of our capacity to measure the (quantum) physical world, our phenomenological experiences are identical with the empirical methods in a holistic way.  These methods, limited as they are by the uncertainty relations, mean that someone like Bohr \emph{must also} conclude that this stops the classical ontological train in it's tracks.  

% We can weaken the above by saying that all \emph{good} physical concepts are such, presumably because they are the only ones with any meaning (achieved via some positivist or empiricist criterion of verification).  Then, one simply imposes this standard to justify the view.  

% While this passage by Bohm was written much after the fact, we might suggest a rational reconstruction of the history as Bohm rejecting the philosophical assumptions of Bohr, and pursuing---\emph{come what may}---a new physical concept underpinning the phenomenological limitations.\footnote{Questions of experimental differences of Bohmian mechanics being, for present purposes, set aside.}  




% \section{Nonlocal Empiricism}

% Underpinning interactions in classical mechanical metaphysics was the notion of indefinite contiguity between points, to ensure gapless causal relations, and to ensure that observations are reliable and contained within the natural causal laws.  [CITE WHO?]

% Information, and the `transfer' of it in representations of interactions, was purely local.  Naturally, assumptions of locality (and there are many ways to cash out the notion of locality [CITE VF Charybdis?]) must be essentially given up (Bohm's theory is non-local).

% So, when we receive information in an experiment about a state of the world, and it appears to include information that is beyond any local interaction, an empiricism based on loading meaning into statements from observation is then loading statements not just about the observation \emph{here}, but statements about the world \emph{there!}

% Counterfactual

% \section{Rationalism ala Milne, Eddington, Bohm?}

% The phenomenological-empiricist identity, perhaps in structural form, can perhaps be granted as a minimal commitment from the philosopher of physics.  However, the realist and the metaphysician will not be happy.  A rationalist, furthermore, might try certain axiomatizations with fundamental concepts that can be combined to \emph{derive} the phenomenological boundary.

% One might say that the foundations of quantum mechanics has been driven to rationalist debates among concepts like locality, 

% [DO I WANT TO DO THIS?  I AM SURE THERE ARE RATIONALIST QM...]

% Harris has a useful summary of some of the rationalist ideas present for example in Milne, related to an alternative account of general relativity, as well as Eddington concerning potential unification of relativistic cosmology and quantum theory.  [CITE]

% \begin{quote}
%     But as we recall, Bohr's entire position depended crucially on his assumptions of the nature of the quantum of action.  Therefore from what we have said above it follows that there is no inherent necessity to adopt Bohr's position, and that there is nothing in Bohr's analysis that could rule out a quantum ontology.  But of course, this latter would require the introduction of new concepts beyond that of the wave function and the quantum state.  \emph{We would have to begin by simply assuming the new concepts and defining them through their participation in the laws of physics.} [emph mine]
    
%     In doing this we have to differ from Bohr who at least tacitly required that all basic physical concepts be defined by referring them to specific phenomena in which they are measured.  In tontrast we \emph{derive} the possible phenomena as forms on the overall structure of concepts and their ralationships. [\dots]  The test of the theory is then to see whether the derived phenomena, not only explain the general form of the observed phenomena, but also their detailed relationships.  In such an approach, the epistemology follows naturally from the ontology (just as it does in classical physics). [\dots]
    
%     We conclude that there are no sound reasons against seeking an ontological interpretation of the quantum theory.
%     [CITE] p. 25-26
% \end{quote}

% An ontological program can be viewed not just as permitted, but also pragmatically useful.

\section{The Pragmatic Ontologists}

\subsection{Carver Mead}

If our purpose is to do theoretical physics or advance foundational understanding, and we don't stop at the phenomenological border, then we might wish to explore different ontologies behind the phenomenal and epistemic statistics. 

The minimal statistical phenomenological and epistemological border, which admittedly has been extremely effective for most calculations and engineering purposes, might not be sufficient for philosophical understanding or potential theoretical unification efforts. [CITE  Hossenfelder criticisms]  But even if we look to the engineering scientist's understanding of quantum mechanics, there might be a pragmatic inference to the best explanation of entities existing in the world such that produce the appearances at the phenomenological border.  One account in this vein might be arguably found in Carver Mead [CITE] who emphasizes the wave nature of matter, rejecting point particles, and the \emph{conceptual understanding} which enables an engineer.

Indeed, macroscopic quantum states in superconductors are also emphasized by Mead to provide support for a conceptual understanding of the ontological reality of matter waves, as opposed to the statistical picture I have outlined at the phenomenological border.  Likewise with lasers for the nature of light.  Reality \emph{has to be so}, according to this view, which flips the burden onto the epistemologist.  In other words, if before the burden was on the realist or ontologist to provide sufficient grounds to go \emph{beyond} the phenomenological or empiricist border, Mead either assumes (or is forced into) different (metaphysical) principles to account for very specific technical arrangements.  

While I cannot vouch for the historical accuracy, Mead summarizes the historical development of the approach which emphasizes the statistical phenomenological border as contingent on the particular systems and experiments of the era:

\begin{quote}
    In 1913 Niels Bohr introduced his first approach to what is now called ``the old quantum theory''. The theory was not well defined, but was able to provide a classical conceptual basis for many of the observed properties of the emission spectral lines of excited gasses. Many physicists worked on improving and extending the theory, with some notable successes. A central conceptual aspect of the theory that has survived is that ``quantum jumps'' between energy states of atoms, give rise to emitted ``photons''. Efforts on the old quantum theory persisted well into the 1920s. In the mid-to-late 1920s, the work of de Broglie, Schr\"odinger, Heisenberg, Born, Pauli, and Dirac led from the old quantum theory to the quantum theory that is taught in schools today. Experiments during that formative period were still based on spectra from excited gasses, and hence were, by their very nature, only statistical in nature. The limitations of those experiments were built into the conceptual foundations of the new quantum mechanics, and remain there to this day. In fact, the limitation to statistical predictions was turned into a religion by Bohr and Heisenberg.
\end{quote}

Mead also talks sympathetically of the transactional view, and the transactional interpretation of e.g. Cramer [SOURCE]  Further detail on Mead's view in that direction are unnecessary for present purposes.


Also his approach, focused on the engineering of coherent populations of electrons (or photons), and transactions between coherent macroscopic states, leads one to expect in the future ``more and more coherent forms of detection''.[CITE]  That is, if the world is such as to have persistent properties like phase of populations, which is physically important even though in measurement transactions it might be obliterated in a naive epistemology, we expect to be able to have `weaker' forms of interactions that are useful.  

\begin{quote}
    We are at the stage of detector evolution corresponding to the era of ``crystal sets'' in the evolution of radio receivers. We have already developed several forms of distributed coherent optical amplification. In the near future we will surely evolve more and more coherent forms of detection, which will then allow the kind of coherent systems at optical wavelengths that we routinely enjoy at radio wavelengths. The development of such coherent detectors has been seriously retarded by the Copenhagen view of laser beams made up of ``photons''little bullets carrying $h\nu$ of energy. Einstein got past that hangup, and we can as well. At that point the ``Copenhagen photon'' will take its proper place with all the other ``noise'' bequeathed us by the Copenhagen clan!
\end{quote}

\subsection{David Bohm}

One might read Bohm and see a pragmatic side to introducing non-local hidden variables... I think that is what I was originally considering here.  Not sure if this is in scope.


% \section{Quantum Metrology}

% One potential way to bolster the philosophical underpinnings of quantum metrology is to look to extremely successful scientists and engineers, to see if there is any innovation in ``threading the needle'' of realism, pragmatism, phenomenology and epistemology.

% One aspect of my proposed project is to look at what is called Collective Electrodynamics, and the views of Carver Mead.  Mead is an extremely successful electrical engineer, who has written 

% NOTE: Perhaps out of scope now.



\section{Poincar\'e}

\begin{quote}
    Instead of a summary condemnation we should examine with the utmost care the role of hypothesis; we shall then recognise not only that it is necessary, but that in most cases it is legitimate.  We shall also see that there are several kinds of hypotheses; that some are verifiable, and when once confirmed by experiment become truths of great fertility; that others may be useful to us in fixing our ideas; and finally, that others are hypotheses only in appearance, and reduce to definitions or to conventions in disguise.  The latter are to be met with especially in mathematics and in the sciences to which it is applied.  From them, indeed, the sciences derive their rigour; such conventions are the result of the unrestricted activity of the mind, which in this domain recognises no obstacle.  For here the mind may affirm because it lays down its own laws; but let us clearly understand that while these laws are imposed on \emph{our} science, which otherwise could not exist, they are not imposed on Nature.  Are they then arbitrary?  No; for if they were, they would not be fertile.  Experience leaves us our freedom of choice, but it guides us by helping us to discern the most convenient path to follow.  Our laws are therefore like those of an absolute monarch, who is wise and consults his council of state.  Some people have been struck by this characteristic of free convention which may be recognised in certain fundamental principles of the sciences.  Some have set no limits to their generalisations, and at the same time they have forgotten that there is a difference between liberty and the purely arbitrary.  So that they are compelled to end in what is called \emph{nominalism}; they have asked if the \emph{savant} is not the dupe of his own definitions, and if the world he thinks he has discovered is not simply the creation of his own caprice.  Under these conditions science would retain its certainty, but would not attain its object, and would become powerless.  Now, we daily see what science is doing for us.  This could not be unless it taught us something about reality; the aim of science is not things themselves, as the dogmatists in their simplicity imagine, but the relations between things; outside those relations there is no reality knowable.  \citep[p. xxii-xxiv]{Poincare1952}
\end{quote}

Poincar\'e discusses definitions and proofs in mathematics requiring mathematical induction (that is, the process of showing a property holds for $n = 1$, and that \emph{if} it also holds for $n - 1$ \emph{then} it also holds for $n$, and concluding that it is true for all $n$).  He equates this to what he calls (in the translation) ``recurrence'' of essentially infinite syllogisms condensed, in mathematical reasoning \emph{par excellence}, in a ``cascade'', one following the other.  \citep[p. 9]{Poincare1952}  

\begin{quote}
    But however far we went we should never reach the general theorem applicable to all numbers, which alone is the object of science.  To reach it we should require an infinite number of syllogisms, and we should have to cross an abyss which the patience of the analyst, restricted to the resources of formal logic, will never succeed in crossing.  \citep[p. 10-11]{Poincare1952}
\end{quote}

Recurrence is ``the only instrument which enables us to pass from the finite to the infinite.''  \citep[p. 11]{Poincare1952}  But what is his  philosophical foundation or justification for this principle?  Without going into too deep of philosophy of mathematics waters, it is in the vein of \emph{intuitionism}.  This seems like a vitally important point to follow up on, in the present context, since intuitionism has close relations to idealism.  [DOES IT?  WHERE?]

\begin{quote}
    We cannot therefore escape the conclusion that the rule of reasoning by recurrence is irreducible to the principle of contradiction.  Nor can the rule come to us from experiment.  Experiment may teach us that the rule is true for the first ten or the first hundred numbers, for instance; it will not bring us to the indefinite series of numbers, but only to a more or less long, but always limited, portion of the series.  
    
    Now, if that were all that is in question, the principle of contradiction would be sufficient, it would always enable us to develop as many syllogisms as we wished.  It is only when it is a question of a single formula to embrace an infinite number of syllogisms that this principle breaks down, and there, too, experiment is powerless to aid.  This rule, inaccessible to analytical proof and to experiment, is the exact type of the \emph{\'a priori} synthetic intuition.  On the other hand, we cannot see in it a convention as in the case of the postulates of geometry.
    
    Why then is this view imposed upon us with such an irresistible weight of evidence?  It is because it is only the affirmation of the power of the mind which knows it can conceive of the indefinite repetition of the same act, when the act is once possible.  The mind has a direct intuition of this power, and experiment can only be for it an opportunity of using it, and thereby of becoming conscious of it. 
    
    But it will be said, if the legitimacy of reasoning by recurrence cannot be established by experiment alone, is it so with experiment aided by induction?  We see successively that a theorem is true of the number 1, of the number 2, of the number 3, and so on---the law is manifest, we say, and it is so on the same ground that every physical law is true which is based on a very large but limited number of observations.
    
    It cannot escape our notice that here is a striking analogy with the usual processes of induction.  But an essential difference exists.  Induction applied to the physical sciences is always uncertain, because it is based on the belief in a general order of the universe, an order which is external to us.  Mathematical induction--i.e., proof by recurrence---is, on the contrary, necessarily imposed on us, because it is only the affirmation of a property of the mind itself.\citep[p. 12-13]{Poincare1952}
\end{quote}

The latter comments here, I take it, idealists of some schools would disagree with in the sense that they can \emph{solve by metaphysical assumptions} the apparent differences in justification for mathematical and scientific induction.\footnote{Discussions on Hegel's idealism in particular with Ryan Mullaly have been helpful for my understanding on nuanced aspects of idealism.}  That is, scientific induction is \emph{also} the ``affirmation of a property of the mind itself''.  They might also qualify or contrast a particular scientist's ``mind'' with that of a universal organizing principle as ``Mind'' (of which mind is an inseparable and integrated sub-part looking-onto-itself).  \footnote{I will capitalize the `M' as a convention the potentially more sophisticated notion, and as I'm not an expert on e.g. German idealism, I will imagine and construct for the moment an idealist position.}

For such an idealist, the mind's \emph{reasoning about} experiences of particular scientific observations (of Mind) in scientific principle of induction, are \emph{in} Mind.  Likewise, the mind's \emph{reasoning about} experiences of particular syllogisms (of Mind) in mathematical induction are \emph{in} Mind.  The distinction fades for such an idealist, who doesn't stop where Poincar\'e seems to.  

\begin{quote}
    Mathematics may, therefore, like the other sciences, proceed from the particular to the general.  This is a fact which might otherwise have appeared incomprehensible to us at the beginning of this study, but which has no longer anything mysterious about it, since we have ascertained the analogies between proof by recurrence and ordinary induction.
    
    No doubt mathematical recurrent reasoning and physical inductive reasoning are based on different foundations, but they move in parallel lines and in the same direction---namely, from the particular to the general.
    
    \citep[p. 14]{Poincare1952}
\end{quote}

But, is stopping and \emph{not} solving the problem in an idealist framework the most coherent philosophical position?  An idealist wouldn't see just a surface-level analogy between the two forms of induction, with different background justifications, but rather \emph{homologous} rational processes in Mind (and understood by apparently distinct mind's of agents).  Is there an epistemological impetus to \emph{descend the idealist gradient}?

To rejoin the earlier discussion: If we are going to pursue a structural view of the phenomenological border, and identify the structures (of quantum theory) with those experienced by an agent, 

A structuralist which takes an idealist position, going a bit further than Poincar\'e, would consider relations (characterized mathematically) of the world to be \emph{absolute} in the sense that they are not subjective perspectives on an external world, but are \emph{characteristic of the world as a unified existence of Mind}.  Thus, any group structures wouldn't make sense as being of a phenomenological border \emph{with} the world.  

They are structures \emph{of} the world, and the world is constituted as such that e.g. mathematical and scientific induction are both rational processes of Mind.  

It seems to me that, while perhaps consistent, many of us will want to resist such a position.  It seems that it assumes a common cause, if not outright circularity, just to solve the problem.  But, of course, the picture isn't that simple, as there are independent arguments for forms of idealism that are not contingent on solving the problem of induction.

Proponents would say that their metaphysics \emph{explains} or solves many apparent paradoxes.

Poincar\'e's structuralism of scientific objects is also obviously related to his thoughts on topology and what he calls \emph{analysis situs}.  The point being that \emph{analysis situs} is the study of (relational) structures (like shapes) which persist across a variety of deformations.  Topology is thus a natural field of mathematics for the structuralist to appeal to, and the group operations about topological structures.

\subsection{Poincar\'e on Correlative Movement (relation to Cybernetics)}

OUT OF SCOPE?

\begin{quote}
    Suppose a solid body to occupy successively the positions $\alpha$ and $\beta$; in the first position it will give us an aggregate of impressions $A$, and in the second position the aggregate of impressions $B$.  Now let there be a second solid body, of qualities entirely different from the first---of different colour, for instance.  Assume it to pass from the position $\alpha$, where it gives us the aggregate of impressions $A'$ to the position $\beta$, where it gives the aggregate of impressions $B'$.  In general, the aggregate $A$ will have nothing in common with the aggregate $A'$, nor will the aggregate $B$ have anything in common with the aggregate $B'$.  The transition from the aggregate $A$ to the aggregate $B$, and that of the aggregate $A'$ to the aggregate $B'$, are therefore two changes which \emph{in themselves} have in general nothing in common.  Yet we consider both these changes as displacements; and, further, we can consider them the \emph{same} displacement.  How can this be?  It is simply because they may be both corrected by the \emph{same} correlative movement of our body.  ``Correlative movement,'' therefore, constitutes the \emph{sole connection} between two phenomena which otherwise we should never have dreamed of connecting.  
    
    On the other hand, our body, thanks to the number of its articulations and muscles, may have a multitude of different movements, but all are not capable of ``correcting'' a modification of external objects; those alone are capable of it in which our whole body, or at least all those in which the organs of our senses enter into play are displaced \emph{en bloc---i.e.}, without any variation of their relative positions, as in the case of a solid body.  
    
    To sum up: 
    
    1.  In the first place, we distinguish two categories of phenomena:---The first involuntary, unaccompanied by muscular sensations, and attributed to external objects---they are external changes; the second, of opposite character and attributed to the movements of our own body, are internal changes.
    
    2.  We notice that certain changes of each in these categories may be corrected by a correlative change of the other category.
    
    3.  We distinguish among external changes those that have a correlative in the other category---which we call displacements; and in the same way we distinguish among the internal changes those which have a correlative in the first category.
    
    Thus by means of this reciprocity is defined a particular class of phenomena called displacements.  \emph{The laws of these phenomena are the object of geometry.}
    
    \emph{Law of Homogeneity.}---The first of these laws is the law of homogeneity.  Suppose that by an external change we pass from the aggregate of impressions $A$ to the aggregate $B$, and that then this change $\alpha$ is corrected by a correlative voluntary movement $\beta$, so that we are brought back to the aggregate $A$.  Suppose now that another external change $\alpha'$ brings us again from the aggregate $A$ to the aggregate $B$.  Experiment then shows us that this change $\alpha'$, like the change $\alpha$, may be corrected by a voluntary correlative movement $\beta'$, and that this movement $\beta'$ corresponds to the same muscular sensations as the movement $\beta$ which corrected $\alpha$.
    
    This fact is usually enunciated as follows:---\emph{Space is homogeneous and isotropic.}  We may also say that a movement which is once produced may be repeated a second and a third time, and so on, without any variation of its properties.  In the first chapter, in which we discussed the nature of mathematical reasoning, we saw the importance that should be attached to the possibility of repeating the same operation indefinitely.  The virtue of mathematical reasoning is due to this repetition; by means of the law of homogeneity geometrical facts are apprehended.  To be complete, to the law of homogeneity must be added a multitude of other laws, into the details of which I do not propose to enter, but which mathematicians sum up by saying that these displacements form a ``group.''
    
    \citep[p. 61-64]{Poincare1952}
    
\end{quote}

In general Poincar\'e pursues the strategy of saying what geometry one \emph{would} come to use to characterize transformations in experience (or equivalently, transformations in points of view) if an idealized subject were embedded in a different space or world.  Ashby would perhaps be content with an effective list of state transitions, at least from the perspective of ``the system'', but if we are on a meta-level as scientists and philosophers, parsimonious summaries of these transitions, as found in one or another suitable system of geometry, are fine to construct.  So long as at the systems-level of analysis, it is realized that the organism is not ``comprehending'' or ``knowing'' a geometry, rather it has learned an adaptive set of transitions (which can be summarized by meta-cognitive agents).

One can also pursue the idealized-agent-embedded-in-a-world idea to consider how e.g. self-similarity on a fractal surface (created by one of Poincar\'e's much appealed to recurrent processes, and characterized e.g. by a Hausdorff dimension $d_H$) would come to be reflected in the agent's epistemology.  Not just the ``cognitive geometry'' but the \emph{rules} that can be relied upon.  These rules being, naturally, a deductive form of the rule of induction (both mathematical and scientific observation forms).  On the ``surface'' of such a world, an agent would come to characterize the world by a certain property at each point in his experienced world, e.g. $d_H$.  Much like how a property of curvature in Riemannian geometry is \emph{embedded} in a fundamental way, and reflected by us as experiencers of a world that is summed up in general relativity.

\begin{quote}
    The sense of light, even with one eye, together with the muscular sensations relative to the movements of the eyeball, will suffice to enable us to conceive of space of three dimensions.  The images of external objects are painted on the retina, which is a plane of two dimensions; these are \emph{perspectives}.  But as eye and objects are movable, we see in succession different perspectives of the same body taken from different points of view.  We find at the same time that the transition from one perspective to another is often acccompanied by muscular sensations.  If the transition from the perspective $A$ to the perspective $B$, and that of the perspective $A'$ to the perspective $B'$ are accompanied by the same muscular sensations, we connect them as we do other operations of the same nature.  Then when we study the laws according to which these operations are combined, we see that they form a group, which has the same structure as that of the movements of invariable solids.  Now, we have seen that it is from the properties of this group that we derive the idea of geometrical space and that of three dimensions.  We thus understand how these perspectives gave rise to the conception of three dimensions, although each perspective is of only two dimensions,---because \emph{they succeed each other according to certain laws.}  Well, in the same way that we draw the perspective of a three-dimensional figure on a plane, so we can draw that of a four-dimensional figure on a canvas of three (or two) dimensions.  To a geometer this is but child's play.  We can even draw several perspectives of the same figure from several different points of view.  We can easily represent to ourselves these perspectives, since they are of only three dimensions.  Imagine that the different perspectives of one and the same object to occur in succession, and that the transition from one to the other is accompanied by muscular sensations.  It is understood that we shall consider two of these transitions as two operations of the same nature when they are associated with the same muscular sensations.  There is nothing, then, to prevent us from imagining that these operations are combined according to any law we choose---for instance, by forming a group with the same structure as that of the movements of an invariable four-dimensional solid.  In this there is nothing that we cannot represent to ourselves, and, moreover, these sensations are those which a being would experience who has a retina of two dimensions, and who may be displaced in space of four dimensions.  In this sense we may say that we can represent to ourselves the fourth dimension.  
    
    \citep[p. 68-70]{Poincare1952}
\end{quote}

\begin{quote}
    The object of geometry is the study of a particular ``group''; but the general concept of group pre-exists in our minds, at least potentially.  It is imposed on us not as a form of our sensitiveness, but as a form of our understanding; only, from among all possible groups, we must choose one that will be the \emph{standard}, so to speak, to which we shall refer natural phenomena.
    
    Experiment guides us in this choice, which it does not impose on us.  It tells us not what is the truest, but what is the most convenient geometry.  It will be noticed that my description of these fantastic worlds has required no language other than that of ordinary geometry.  Then, were we transported to those worlds, there would be no need to change that language.  Beings educated there would no doubt find it more convenient to create a geometry different from ours, and better adapted to their impressions; but as for us, in the presence of the same impressions, it is certain that we should not find it more convenient to make a change.
    
    \citep[p. 70-71]{Poincare1952}
\end{quote}

Is he saying that we shouldn't change our internal agentic geometric conceptions from Euclidean to non-Euclidean?  How does this compare to a cybernetics/Ashby perspective?

-Interior Angles of Triangles in non-Euclidean geometries

\subsection{Pragmatic Poincar\'e}

-Geometrical systems as convention

-Measurement/Experiment not capable of being a crucial experiment to decide one geometrical system over another

-Chapter 5 point 6... isn't this wrong?

\begin{quote}
    6.  Experiments only teach us the relations of bodies to one another.  They do not and cannot give us the relations of bodies and space, nor the mutual relations of the different parts of space.  ``Yes!'' you reply, ``a single experiment is not enough, because it only gives us one equation with several unknowns; but when I have made enough experiments I shall have enough equations to calculate all my unknowns.''  If I know the height of the main-mast, that is not sufficient to enable me to calculate the age of the captain.  When you have measured every fragment of wood in a ship you will have many equations, but you will be no nearer knowing the captain's age.  All your measurements bearing on your fragments of wood can tell you only what concerns those fragments; and similarly, your experiments, however numerous they may be, referring only to the relations of bodies with one another, will tell you nothing about the mutual relations of the different parts of space.
    
    \citep[p. 79-80]{Poincare1952}
\end{quote}

Contrast this with e.g. what Harris says is implied by quantum and relativity.  

-p. 84 "Hence, \emph{experiments have reference not to space but to bodies.}

- Reread section 8 in chapter 5, more relationship to Ashby?

\begin{quote}
    [Kirchoff] wanted a definition of a force, and he took the first that came handy; but we do not require a definition of force; the idea of force is primitive, irreducible, indefinable; we all know what it is; of it we have direct intuition.  This direct intuition arises from the idea of effort which is familiar to us from childhood.  But in the first place, even if this direct intuition made known to us the real nature of force in itself, it would prove to be an insufficient basis for mechanics; it would, moreover, be quite useless.  The important thing is not to know what force is, but how to measure it.  Everything which does not teach us how to measure it is as useless to the mechanician as, for instance, the subjective idea of heat and cold to the student of heat.  
    \citep[p. 105-106]{Poincare1952}
\end{quote}

Intuitionism (about physical concepts) into pragmatics about measurement.

- Contrary hypothesis to relativity (principle of relative motion) would be ``repugnant to the mind.'' \citep[p. 111, 113]{Poincare1952}

- Physical laws, not just geometry, as expressions of convenience to satisfy the mind. (e.g. p. 117)


- Energetics (conservation of energy kinetic + potential energy, and Hamilton's principle of least action) \href{https://en.wikipedia.org/wiki/Hamilton%27s_principle}{wiki}

\begin{quote}
    Every change that the bodies of nature can undergo is regulated by two experimental laws.  First, the sum of the kinetic and potential energies is constant.  This is the principle of the conservation of energy.  Second, if a system of bodies is at $A$ at the time $t_0$, and at $B$ at the time $t_1$, it always passes from the first position to the second by such a path that the \emph{mean} value of the difference between the two kinds of energy in the interval of time which separates the two epochs $t_0$ and $t_1$ is a minimum.  This is Hamilton's principle, and is one of the forms of the principle of least action.  
    
    The energetic theory has the following advantages over the classical.  First, it is less incomplete---that is to say, the principles of the conservation of energy and of Hamilton teach us more than the fundamental principles of the classical theory, and exclude certain motions which do not occur in nature and which would be compatible with the classical theory.  Second, it frees us from the hypothesis of atoms, which it was almost impossible to avoid with the classical theory.  \citep[p. 123-124]{Poincare1952}
 \end{quote}
 
 \begin{quote}
     If $T + U + Q$ were of the particular form that I have suggested above, no ambiguity would ensue.  Among the functions $\phi(T + U + Q)$ which remain constant, there is only one that would be of this particular form, namely the one which I would agree to call energy.  But I have said this is not rigorously the case.  Among the functions that remain constant there is not one which can rigorously be placed in this particular form.  How then can we choose from among them that which should be called energy?  We have no longer any guide in our choice.
     
     Of the principle of conservation of energy there is nothing left then but an enunciation:---\emph{There is something which remains constant.}  In this form it, in its turn, is outside the bounds of experiment and reduced to a kind of tautology.  It is clear that if the world is governed by laws there will be quantities which remain constant.  Like Newton's laws, and for an analogous reason, the principle of the conservation of energy being based on experiment, can no longer be invalidated by it.  \citep[p. 127-128]{Poincare1952}
 \end{quote}
 
 - law of errors reference: \href{https://en.wikipedia.org/wiki/Laplace_distribution}{wiki}
 
 \begin{quote}
     An eminent physicist said to me one day, \emph{\'apropos} of the law of errors:---every one stoutly believes it, because mathematicians imagine that it is an effect of observation, and observers imagine that it is a mathematical theorem.  And this was for a long time the case with the principle of the conservation of energy.  It is no longer the same now.  There is no one who does not know that it is an experimental fact.  But then who gives us the right of attributing to the principle itself more generality and more precision than to the experiments which have served to demonstrate it?  This is asking, if it is legitimate to generalise, as we do every day, empiric data, and I shall not be so foolhardy as to discuss this question, after so many philosophers have vainly tried to solve it.  \citep[p. 129]{Poincare1952}
 \end{quote}
 
 - Is he referring to e.g. Hume?  Yes I think so given subsequent paragraphs.
 
 - Mayer's law (thermodynamic conservation energy) \href{https://en.wikipedia.org/wiki/Julius_von_Mayer}{wiki}
 
 \begin{quote}
     If the future state of the system is not entirely determined by its present state, it is because it further depends on the state of bodies external to the system.  But then, is it likely that there exist among the parameters $x$ which define the state of the system of equations independent of this state of the external bodies? and if in certain cases we think we can find them, is it not only because of our ignorance, and because the influence of these bodies is too weak for our experiment to be able to detect it?  If the system is not regarded as completely isolated, it is probable that the rigorously exact expression of its internal energy will depend upon the state of the external bodies.  Again, I have supposed above that the sum of all the external work is zero, and if we wish to be free from this rather artificial restriction the enunciation becomes still more difficult.  To formulate Mayer's principle by giving it an absolute meaning, we must extend it to the whole universe, and then we find ourselves face to face with the very difficulty we have endeavoured to avoid.  To sum up, and to use ordinary language, the law of the conservation of energy can have only one significance, because there is in it a property common to all possible properties; but in the determinist hypothesis there is only one possible, and then the law has no meaning.  In the indeterminist hypothesis, on the other hand, it would have a meaning even if we wished to regard it in an absolute sense.  It would appear as a limitation imposed on freedom.  \cite[p. 133-134]{Poincare1952}
 \end{quote}
 
 - Clausius's principle \href{https://en.wikipedia.org/wiki/Clausius_theorem}{wiki}
 

 
 \begin{quote}
     Almost everything that I have just said applies to the principle of Clausius.  What distinguishes it is, that it is expressed by an inequality.  It will be said perhaps that it is the same with all physical laws, since their precision is always limited by errors of observation.  But they at least claim to be first approximations, and we hope to replace them little by little by more exact laws.  If, on the other hand, the principle of Clausius reduces to an inequality, this is not caused by the imperfection of our means of observation, but by the very nature of the question.  \citep[p. 135]{Poincare1952}
 \end{quote}
 
  - measurement/observation inequalities like uncertainty principle/fourier transform
  
  In summarizing section III of the book and conventionalism:
 
 \begin{quote}
     The principles of mechanics are therefore presented to us under two different aspects.  On the one hand, there are truths founded on experiment, and verified approximately as far as almost isolated systems are concerned; on the other hand, there are postulates applicable to the whole of the universe and regarded as rigorously true.  If these postulates possess a generality and a certainty which falsify the experimental truths from which they were deduced, it is because they reduce in final analysis to a simple convention that we have a right to make, because we are certain beforehand that no experiment can contradict it.  This convention, however, is not absolutely arbitrary; it is not the child of our caprice.  We admit it because certain experiments have shown us that it will be convenient, and thus is explained how experiment has built up the principles of mechanics, and why, moreover, it cannot reverse them.  
     Take a comparison with geometry.  The fundamental propositions of geometry, for instance, Euclid's postulate, are only conventions, and it is quite as unreasonable to ask if they are true or false as to ask if the metric system is true or false.  Only, these conventions are convenient, and there are certain experiments which prove it to us.  At the first glance, the analogy is complete, the role of experiment seems the same.  We shall therefore be tempted to say, either mechanics must be looked upon as experimental science and then it should be the same with geometry; or, on the contrary, geometry is a deductive science, and then we can say the same of mechanics.  Such a conclusion would be illegitimate.  The experiments which have led us to adopt as more convenient the fundamental conventions of geometry refer to bodies which have nothing in common with those that are studied by geometry.  They refer to the properties of solid bodies and to the propagation of light in a straight line.  These are mechanical, optical experiments.  
     
     In no way can they be regarded as geometrical experiments.  And even the probable reason why our geometry seems convenient to us is, that our bodies, our hands, and our limbs enjoy the properties of solid bodies.  Our fundamental experiments are pre-eminently physiological experiments which refer, not to the space which is the object that geometry must study, but to our body---that is to say, to the instrument which we use for that study.  On the other hand, the fundamental conventions of mechanics and the experiments which prove to us that they are convenient, certainly refer to the same objects or to analogous objects.  Conventional and general principles are the natural and direct generalisations of experimental and particular principles.  \citep[p. 135-137]{Poincare1952}
 \end{quote}
 
 \begin{quote}
     We now understand why the teaching of mechanics should remain experimental.  Thus only can we be made to understand the genesis of the science, and that is indispensable for a complete knowledge of the science itself.  Besides, if we study mechanics, it is in order to apply it; and we can only apply it if it remains objective.  Now, as we have seen, when principles gain in generality and certainty they lose in objectivity.  It is therefore especially with the objective side of principles that we must be early familiarised, and thhis can only be by passing from the particular to the general, instead of from the general to the particular.
     
     Principles are conventions and definitions in disguise.  They are, however, deduced from experimental laws, and these laws have, so to speak, been erected into principles to which our mind attributes an absolute value.  Some philosophers have generalised far too much.  They have thought that the principles were the whole of science, and therefore that the whole of science was conventional.  This paradoxical doctrine, which is called Nominalism, cannot stand examination.  How can a law become a principle?  It expressed a relation between two real terms, $A$ and $B$; but it was not rigorously true, it was only approximate.  We introduce arbitrarily an intermediate term, $C$, more or less imaginary, and $C$ is \emph{by definition} that which has with $A$ \emph{exactly} the relation expressed by the law.  So our law is decomposed into an absolute and rigorous principle which expresses the relation of $A$ to $C$, and an approximate experimental and revisable law which expresses the relation of $C$ to $B$.  But it is clear that however far this decomposition may be carried, laws will always remain.  We shall now enter into the domain of laws properly so called.  \citep[p. 138-139]{Poincare1952}
 \end{quote}
 
 - conventionalism about geometry but not mechanics, and if fundamental mechanical laws are strictly false it is in a justified way different from the justifications for choosing a particular geometrical view applied to reality
 
 -similar to Cartwright's anti-realism about fundamental laws (because they contradict the augmented-with-assumption phenomenological laws)?
 
 
 \begin{quote}
     What, then, is a good experiment?  It is that which teaches us something more than an isolated fact.  It is that which enables us to predict, and to generalise.  Without generalisation, prediction is impossible.  The circumstances under which one has operated will never again be reproduced simultaneously.  The fact observed will never be repeated.  All that can be affirmed is that under analogous circumstances an analogous fact will be produced.  To predict it, we must therefore invoke the aid of analogy---that is to say, even at this stage, we must generalise.  However timid we may be, there must be interpolation.  Experiment only gives us a certain number of isolated points.  They must be connected by a continuous line, and this is a true generalisation.  But more is done.  The curve thus traced will pass between and near the points observed; it will not pass through the points themselves.  Thus we are not restricted to generalising our experiment, we correct it; and the physicist who would abstain from these corrections, and really content himself with experiment pure and simple, would be compelled to enunciate very extraordinary laws indeed.  Detached facts cannot therefore satisfy us, and that is why our science must be ordered, or, better still, generalised.
     
     It is often said that experiments should be made without preconceived ideas.  That is impossible.  Not only would it make every experiment fruitless, but even if we wished to do so, it could not be done.  Every man has his own conception of the world, and this he cannot so easily lay aside.  \citep[p. 142-143]{Poincare1952}
 \end{quote}
 
 ``It is far better to predict without certainty, than never to have predicted at all.'' \citep[p. 144]{Poincare1952}
 
 
 - mathematical physics directs generalisation (catalogue), analogy with library planning/expenditures
 
 - unity and simplicity.  simplicity/complexity process loop
 
 \begin{quote}
     No doubt, if our means of investigation became more and more penetrating, we should discover the simple beneath the complex, and then the complex from the simple, and then again the simple beneath the complex, and so on, without ever being able to predict what the last term will be.  We must stop somewhere, and for science to be possible we must stop where we have found simplicity.  That is the only ground on which we can erect the edifice of our generalisations.  But, this simplicity being only apparent, will the ground be solid enough?  That is what we have now to discover.  \citep[p. 148-149]{Poincare1952}
 \end{quote}
 
 -role of hypothesis, should be ASAP submitted to experimental verification, unconscious hypotheses dangerous, D/Q-like thesis and underdetermination
 
 \begin{quote}
     Let us also notice that it is important not to multiply hypotheses indefinitely.  If we construct a theory based upon multiple hypotheses, and if experiment condemns it, which of the premisses must be changed?  It is impossible to tell.  Conversely, if the experiment succeeds, must we suppose that it has verified all these hypotheses at once?  Can several unknowns be determined from a single equation?  \citep[p. 151-152]{Poincare1952}
 \end{quote}
 
 - also makes points similar to batterman?  153-157
 
 - optics
 
 \begin{quote}
     The mind has to run ahead of the experiment, and if it has done so with success, it is because it has allowed itself to be guided by the instinct of simplicity.  The knowledge of the elementary fact enables us to state the problem in the form of an equation.  It only remains to deduce from it by combination the observable and verifiable complex fact.  That is what we call \emph{integration}, and it is the province of the mathematician.  It might be asked, why in physical science generalisation so readily takes the mathematical form.  The reason is now easy to see.  It is not only because we have to express numerical laws; it is because the observable phenomenon is due to the superposition of a large number of elementary phenomena which are \emph{all similar to each other}; and in this way differential equations are quite naturally introduced.  It is not enough that each elementary phenomenon should obey simple laws: all those that we have to combine must obey the same law; then only is the intervention of mathematics of any use.  Mathematics teaches us, in fact, to combine like with like.  Its object is to divine the result of a combination without having to reconstruct that combination element by element.  If we have to repeat the same operation several times, mathematics enables us to avoid this repetition by telling the result beforehand by a kind of induction.  This I have explained before in the chapter on mathematical reasoning.  But for that purpose all these operations must be similar; in the contrary case we must evidently make up our minds to working them out in full one after the other, and mathematics will be useless.  It is therefore, thanks to the approximate homogeneity of the matter studied by physicists, that mathematical physics came into existence.  In the natural sciences the following conditions are no longer to be found:---homogeneity, relative independence of remote parts, simplicity of the elementary fact; and that is why the student of natural science is compelled to have recourse to other modes of generalisation.  \citep[p. 158-159]{Poincare1952}
 \end{quote}
 
 - associationist structure building?
 
 - ch. X The Theories of Modern Physics goes through examples where relations hold but objects we picture the relations holding change.  E.g. Fresnel, Coloumb, Carnot [structuralism]
 
 \begin{quote}
     No theory seemed established on firmer ground than Fresnel's, which attributed light to the movements of the ether.  Then if Maxwell's theory is today preferred, does that mean that Fresnel's work was in vain?  No; for Fresnel's object was not to know whether there really is an ether, if it is or is not formed of atoms, if these atoms really move in this way or that; his object was to predict optical phenomena.
     
     This Fresnel's theory enables us to do today as well as it did before Maxwell's time.  The differential equations are always true, they may be always integrated by the same methods, and the results of this integration still preserve their value.  It cannot be said that this is reducing physical theories to simple practical recipes; these equations express relations, and if the equations remain true, it is because the relations preserve their reality.  They teach us now, as they did then, that there is such and such a relation between this thing and that; only, the something which we then called \emph{motion}, we now call \emph{electric current}.  But these are merely names of the images we substituted for the real objects which Nature will hide for ever from our eyes.  The true relations between these real objects are the only reality we can attain, and the sole condition is that the same relations shall exist between these objects as between the images we are forced to put in their place.  \citep[p. 160-161]{Poincare1952}
 \end{quote}
 
 -when contradiction between two theories ``Let us not be troubled, but let us hold fast to the two ends of the chain, lest we lose the intermediate links.''
 
 \begin{quote}
     In case of contradiction one of them at least should be considered false.  But this is no longer the case if we only seek in them what should be sought.  It is quite possible that they both express true relations, and that the contradictions only exist in the images we have formed to ourselves of reality.  \citep[p. 163]{Poincare1952}
 \end{quote}
 
  - satisfying the mind; structuralism accounts for when old theories get brought back to scientific attention (Coulomb fluid example)
 
 \begin{quote}
     Hypotheses of this kind have therefore only a metaphorical sense.  The scientist should no more banish them than a poet banishes metaphor; but he ought to know what they are worth.  They may be useful to give satisfaction to the mind, and they will do no harm as long as they are only indifferent hypotheses.  
     
     These considerations explain to us why certain theories, that were thought to be abandoned and definitively condemned by experiment, are suddenly revived from their ashes and begin a new life.  It is because they expressed true relations, and had not ceased to do so when for some reason or other we felt it necessary to enunciate the same relations in another language.  Their life had been latent, as it were.  
     
     Barely fifteen years ago, was there anything more ridiculous, more quaintly old-fashioned, than the fluids of Coulomb?  And yet, here they are re-appearing under the name of \emph{electrons}.  In what do these permanently electrified molecules differ from the electric molecules of Coulomb?  It is true that in the electrons the electricity is supported by a little, a very little matter; in other words, they have mass.  Yet Coulomb did not deny mass to his fluids, or if he did, it was with reluctance.  It would be rash to affirm that the belief in electrons will not also undergo an eclipse, but it was none the less curious to note this unexpected renaissance.
     
     \citep[p. 164-165]{Poincare1952}
 \end{quote}
 
- Carnot second law example
 
 - pragmatic usefulness criteria
 
 - mechanisms, Hertz
 
 \begin{quote}
     Every time that the principles of least action and energy are satisfied, we shall see that not only is there always a mechanical explanation possible, but that there is an unlimited number of such explanations.  By means of a well-known theorem due to K\"onigs, it may be shown that we can explain everything in an unlimited number of ways, by connections after the manner of Hertz, or, again, by central forces.  \citep[p. 167-168]{Poincare1952}
 \end{quote}
 
 - ether
 
 \begin{quote}
     We may conceive of ordinary matter as either composed of atoms, whose internal movements escape us, our senses being able to estimate only the displacement of the whole; or we may imagine one of those subtle fluids, which under the name of \emph{ether} or other names, have from all time played so important a role in physical theories.  Often we go further, and regard the ether as the only primitive, or even as the only true matter.  The more moderate consider ordinary matter to be condensed ether, and there is nothing startling in this conception; but others only reduce its importance still further, and see in matter nothing more than the geometrical locus of singularities in the ether.  
     
     Lord Kelvin, for instance, holds what we call matter to be only the locus of those points at which the ether is animated by vortex motions.  Riemann believes it to be locus of those points at which ether is constantly destroyed; to Wiechert or Larmor, it is the locus of the points at which the ether has undergone a kind of torsion of a very particular kind.  Taking any one of these points of view, I ask by what right do we apply to the ether the mechanical properties observed in ordinary matter, which is but false matter?  The ancient fluids, caloric, electricity, etc., were abandoned when it was seen that heat is not indestructible.  But they were also laid aside for another reason.  In materialising them, their individuality was, so to speak, emphasised---gaps were opened between them; and these gaps had to be filled in when the sentiment of the unity of Nature became stronger, and when the intimate relations which connect all the parts were perceived.  In multiplying the fluids, not only did the ancient physicists create unnecessary entities, but they destroyed real ties.  It is not enough for a theory not to affirm false relations; it must not conceal true relations.  
     
     Does our ether actually exist?  We know the origin of our belief in the ether.  If light takes several years to reach us from a distant star, it is no longer on the star, nor is it on the earth.  It must be somewhere, and supported, so to speak, by some material agency.
     
     The same idea may be expressed in a more mathematical and more abstract form.  What we note are the changes undergone by the material molecules.  We see, for instance, that the photographic plate experiences the consequences of a phenomenon of which the incandescent mass of a star was the scene several years before.  Now, in ordinary mechanics, the state of the system under consideration depends only on its state at the moment immediately preceding; the system therefore satisfies certain differential equations.  On the other hand, if we did not believe in the ether, the state of the material universe would depend not only on the state immediately preceding, but also on much older states; the system would satisfy equations of finite differences.  The ether was invented to escape this breaking down of the laws of general mechanics.  
     
     Still, this would only compel us to fill the interplanetary space with ether, but not to make it penetrate into the midst of the material media.  Fizeau's experiment goes further.  By the interference of rays which have passed through the air or water in motion, it seems to show us two different media penetrating each other, and yet being displaced with respect to each other.  The ether is all but in our grasp.  Experiments can be conceived in which we come closer still to it.  Assume that Newton's principle of the equality of action and re-action is not true if applied to matter \emph{alone}, and that this can be proved.  The geometrical sum of all the forces applied to all the molecules would no longer be zero.  If we did not wish to change the whole of the science of mechanics, we should have to introduce the ether, in order that the action which matter apparently undergoes should be counterbalanced by the re-action of matter on something.
     
     Or again, suppose we discover that optical and electrical phenomena are influenced by the motion of the earth.  It would follow that those phenomena might reveal to us not only the relative motion of material bodies, but also what would seem to be their absolute motion.  Again, it would be necessary to have an ether in order that these so-called absolute movements should not be their displacements with respect to empty space, but with respect to something concrete.  
     
     Will this ever be accomplished?  I do not think so, and I shall explain why; and yet, it is not absurd, for others have entertained this view.  For instance, if the theory of Lorentz, or which I shall speak in more detail in Chapter XIII., were true, Newton's principle would not apply to matter \emph{alone}, and the difference would not be very far from being within reach of experiment.  On the other hand, many experiments have been made on the influence of the motion of the earth.  The results have always been negative.  But if these experiments have been undertaken, it is because we have not been certain beforehand; and indeed, according to current theories, the compensation would be only approximate, and we might expect to find accurate methods giving positive results.  I think that such a hope is illusory; it was none the less interesting to show that a success of this kind would, in a certain sense, open to us a new world.
     
     And now allow me to make a digression; I must explain why I do not believe, in spite of Lorentz, that more exact observations will ever make evident anything else but the relative displacements of material bodies.  Experiments have been made that should have disclosed the terms of the first order; the results were nugatory.  Could that have been by chance?  No one has admitted this; a general explanation was sought, and Lorentz found it.  He showed that the terms of the first order should cancel each other, but not the terms of the second order.  Then more exact experiments were made, which were also negative; neither could this be the result of chance.  An explanation was necessary, and was forthcoming; they always are; hypotheses are what we lack the least.  But this is not enough.  Who is there who does not think that this leaves to chance far too important a role?  Would it not also be a chance that this singular concurrence should cause a certain circumstance to destroy the terms of the first order, and that a totally different but very opportune circumstance should cause those of the second order to vanish?  No; the same explanation must be found for the two cases, and everything tends to show that this explanation would serve equally well for the terms of the higher order, and that the mutual destruction of these terms will be rigorous and absolute.
     
     \citep[p. 168-172]{Poincare1952}
     
 \end{quote}
 
 -unification of light, electricity, and magnetism.  Lorentz ether theory/electrons, mechanical explanation, analogies between systems
 
 \begin{quote}
     The most satisfactory theory is that of Lorentz; it is unquestionably the theory that best explains the known facts, the one that throws into relief the greatest number of known relations, the one in which we find most traces of definitive construction.  That it still possesses a serious fault I have shown above.  It is in contradiction with Newton's law that action and re-action are equal and opposite---or rather, this principle according to Lorentz cannot be applicable to matter alone; if it be true, it must take into account the action of the ether on matter, and the re-action of the matter on the ether.  Now, in the new order, it is very likely that things do not happen in this way.  
     
     However this may be, it is due to Lorentz that the results of Fizeau on the optics of moving bodies, the laws of normal and abnormal dispersion and of absorption are connected with each other and with the other properties of the ether, by bonds which no doubt will not be readily severed.  Look at the ease with which the new Zeeman phenomenon found its place, and even aided the classification of Faraday's magnetic rotation, which had defied all Maxwell's efforts.  This facility proves that Lorentz's theory is not a mere artificial combination which must eventually find its solvent.  It will probably have to be modified, but not destroyed.  
     The only object of Lorentz was to include in a single whole all the optics and electro-dynamics of moving bodies; he did not claim to give a mechanical explanation.  Larmor goes further; keeping the essential part of Lorentz's theory, he grafts upon it, so to speak, MacCullagh's ideas on the direction of the movement of the ether.  MacCullagh held that the velocity of the ether is the same in magnitude and direction as the magnetic force.  Ingenious as is this attempt, the fault in Lorentz's theory remains, and is even aggravated.  According to Lorentz, we do not know what the movements of the ether are; and because we do not know this, we may suppose them to be movements compensating those of matter, and re-affirming that action and re-action are equal and opposite.  According to Larmor we know the movements of the ether, and we can prove that the compensation does not take place.  
     
     If Larmor has failed, as in my opinion he has, does it necessarily follow that a mechanical explanation is impossible?  Far from it.  I said above that as long as a phenomenon obeys the two principles of energy and least action, so long it allows of an unlimited number of mechanical explanations.  And so with the phenomomena of optics and electricity.
     
     But this is not enough.  For a mechanical explanation to be good it must be simple; to choose it from among all the explanations that are possible there must be other reasons than the necessity of making a choice.  Well, we have no theory as yet which will satisfy this condition and consequently be of any use.  Are we then to complain?  That would be to forget the end we seek, which is not the mechanism; the true and only aim is unity.  
     
     We ought therefore to set some limits to our ambition.  Let us not seek to formulate a mechanical explanation; let us be content to show that we can always find one if we wish.  In this we have succeeded.  The principle of the conservation of energy has always been confirmed, and now it has a fellow in the principle of least action, stated in the form appropriate to physics.  This has also been verified, at least as far as concerns the reversible phenomena which obey Lagrange's equations---in other words, which obey the most general laws of physics.  The irreversible phenomena are much more difficult to bring into line; but they, too, are being coordinated and tend to come into the unity.  The light which illuminates them comes from Carnot's principle.  For a long time thermodynamics was confined to the study of the dilatations of bodies and of their change of state.  For some time past it has been growing bolder, and has considerably extended its domain.  We owe to it the theories of the voltaic cell and of their thermo-electric phenomena; there is not a corner in physics which it has not explored, and it has even attacked chemistry itself.  The same laws hold good; everywhere, disguised in some form or other, we find Carnot's principle; everywhere also appears that eminently abstract concept of entropy which is as universal as the concept of energy, and like it, seems to conceal a reality.  It seemed that radiant heat must escape, but recently that, too, has been brought under the same laws.  
     
     In this way fresh analogies are revealed which may be often pursued in detail; electric resistance resembles the viscosity of fluids; hysteresis would rather be like the friction of solids.  In all cases friction appears to be the type most imitated by the most diverse irreversible phenomena, and this relationship is real and profound.  
     \citep[p. 175 - 178]{Poincare1952}
 \end{quote}
 
 - physical chemistry and materials, unity though complex, satisfying mind again
 
 \begin{quote}
     As we get to know the properties of matter better we see that continuity reigns.  From the work of Andrews and Van der Waals, we see how the transition from the liquid to the gaseous state is made, and that it is not abrupt.  Similarly, there is no gap between the liquid and solid states, and in the proceedings of a recent Congress we see memoirs on the rigidity of liquids side by side with papers on the flow of solids.  
     
     With this tendency there is no doubt a loss of simplicity.  Such and such an effect was represented by straight lines; it is now necessary to connect these lines by more or less complicated curves.  On the other hand, unity is gained.  Separate categories quieted but did not satisfy the mind.  
     
     \citep[p. 181-182]{Poincare1952}
 \end{quote}
 
 - probability, subjective vs objective, gamblers fallacy, posterior and priors in inferring causes, base rate, curve fitting, 
 
 - a priori considerations for curves that are continuous and not sinuosities
 
 - law of errors (Gauss) as `transcendental curve', but for Poincare if it is transcendental it is because of convention and practicality that it is so.
 
 \begin{quote}
     We must calculate the probable \emph{a posteriori} value of each error, and therefore the probable value of the quantity to be measured.  But, as I have just explained, we cannot undertake this calculation unless we admit \emph{a priori--i.e.}, before any observations are made---that there is a law of the probability of errors.  Is there a law of errors?  The law to which all calculators assent is Gauss's law, that is represented by a certain transcendental curve known as the ``bell''.
     
     But it is first of all necessary to recall the classic distinction between systematic and accidental errors.  If the metre with which we measure a length is too long, the number we get will be too small, and it will be no use to measure several times---that is a systematic error.  If we measure with an accurate metre, we may make a mistake, and find the length sometimes too large and sometimes too small, and when we take the mean of a large number of measurements, the error will tend to grow small.  These are accidental errors.  
     
     It is clear that systematic errors do not satisfy Gauss's law, but do accidental errors satisfy it?  Numerous proofs have been attempted, almost all of them crude paralogisms.  But starting from the following hypotheses we may prove Gauss's law: the error is the result of a very large number of partial and independent errors; each partial error is very small and obeys any law of probability whatever, provided the probability of a positive error is the same as that of an equal negative error.  It is clear that these conditions will be often, but not always, fulfilled, and we may reserve the name of accidental for errors which satisfy them.
     
     We see that the method of least squares is not legitimate in every case; in general, physicists are more distrustful of it than astronomers.  This is no doubt because the latter, apart from the systematic errors to which they and the physicists are subject alike, have to contend with an extremely important source of error which is entirely accidental---I mean atmospheric undulations.  So it is very curious to hear a discussion between a physicist and an astronomer about a method of observation.  The physicist, persuaded that one good measurement is worth more than many bad ones, is pre-eminently concerned with the elimination by means of every precaution of the final systematic errors; the astronomer retorts: ``But you can only observe a small number of stars, and accidental errors will not disappear.''
     
     What conclusion must we draw?  Must we continue to use the method of least squares?  We must distinguish.  We have eliminated all the systematic errors of which we have any suspicion; we are quite certain that there are others still, but we cannot detect them; and yet we must make up our minds and adopt a definitive value which will be regarded as the probable value; and for that purpose it is clear that the best thing we can do is to apply Gauss's law.  We have only applied a practical rule referring to subjective probability.  And there is no more to be said.
     
     Yet we want to go farther and say that not only the probable value is so much, but that the probable error in the result is so much.  \emph{This is absolutely invalid:}  it would be true only if we were sure that all the systematic errors were eliminated, and of that we know absolutely nothing.  We have two series of observations; by applying the law of least squares we find that the probable error in the first series is twice as small as in the second.  The second series may, however, be more accurate than the first, because the first is perhaps affected by a large systematic error.  All that we can say is, that the first series is \emph{probably} better than the second because its accidental error is smaller, and that we have no reason for affirming that the systematic error is greater for one of the series than for the other, our ignorance on this point being absolute.
     
     \cite[p. 207-209]{Poincare1952}
 \end{quote}
 
 
 - ch 12 Optics and electricity, Fresnel.  THIS IS A VERY GOOD CHAPTER
 
\begin{quote}
    It is owing to Fresnel that the science of optics is more advanced than any other branch of physics.  The theory called the theory of undulations forms a complete whole, which is satisfying to the mind; but we must not ask from it what it cannot give us.  The object of mathematical theories is not to reveal to us the real nature of things; that would be an unreasonable claim.  Their only object is to co-ordinate the physical laws with which physical experiment makes us acquainted, the enunciation of which, without the aid of mathematics, we should be unable to effect.  Whether the ether exists or not matters little---let us leave that to the metaphysicians; what is essential for us is, that everything happens as if it existed, and that this hypothesis is found to be suitable for the explanation of phenomena.  After all, have we any other reason for believing in the existence of material objects?  That, too, is only a convenient hypothesis; only, it will never cease to be so, while some day, no doubt, the ether will be thrown aside as useless.
    
    \citep[p. 211-212]{Poincare1952}
\end{quote}

- Maxwell's theory

\begin{quote}
    The first time a French reader opens Maxwell's book, his admiration is tempered with a feeling of uneasiness, and often of distrust.
    
    It is only after prolonged study, and at the cost of much effort, that this feeling disappears.  Some minds of high calibre never lose this feeling.  Why is it so difficult for the ideas of this English scientist to become acclimatised among us?  No doubt the education received by most enlightened Frenchmen predisposes them to appreciate precision and logic more than any other qualities.  In this respect the old theories of mathematical physics gave us complete satisfaction.  All our masters, from Laplace to Cauchy, proceeded along the same lines.  Starting with clearly enunciated hypotheses, they deduced from them all their consequences with mathematical rigour, and then compared them with experiment.  It seemed to be their aim to give to each of the branches of physics the same precision as to celestial mechanics.  
    
    A mind accustomed to admire such models is not easily satisfied with a theory.  Not only will it not tolerate the least appearance of contradiction, but it will expect the different parts to be logically connected with one another, and will require the number of hypotheses to be reduced to a minimum.
    
    This is not all; there will be other demands which appear to me to be less reasonable.  Behind the matter of which our senses are aware, and which is made known to us by experiment, such a thinker will expect to see another kind of matter---the only true matter in its opinion---which will no longer have anything but purely geometrical qualities, and the atoms of which will be mathematical points subject to the laws of dynamics alone.  And yet he will try to represent to himself, by an unconscious contradiction, these invisible and colourless atoms, and therefore to bring them as close as possible to ordinary matter.
    
    Then only will he be thoroughly satisfied, and he will then imagine that he has penetrated the secret of the universe.  Even if the satisfaction is fallacious, it is none the less difficult to give it up.  Thus, on opening the pages of Maxwell, a Frenchman expects to find a theoretical whole, as logical and as precise as the physical optics that is founded on the hypothesis of the ether.  He is thus preparing for himself a disappointment which I should like the reader to avoid; so I will warn him at once of what he will find and what he will not find in Maxwell.  
    
    Maxwell does not give a mechanical explanation of electricity and magnetism; he confines himself to showing that such an explanation is possible.  He shows that the phenomena of optics are only a particular case of electro-magnetic phenomena.  From the whole theory of electricity a theory of light can be immediately deduced.  
    \citep[p. 213-216]{Poincare1952}
\end{quote}


\begin{quote}
    \emph{The Mechanical Explanation of Physical Phenomena}
    
    In every physical phenomenon there is a certain number of parameters which are reached directly by experiment, and which can be measured.  I shall call them the parameters $q$.  Observation next teaches us the laws of the variations of these parameters, and these laws can be generally stated in the form of differential equations which connect together the parameters $q$ and time.  What can be done to give a mechanical interpretation to such a phenomenon?  We may endeavor to explain it, either by the movements of ordinary matter, or by those of one or more hypothetical fluids.  These fluids will be considered as formed of a very large number of isolated molecules $m$.  When may we say that we have a complete mechanical explanation of the phenomenon?  It will be, on the one hand, when we know the differential equations which are satisfied by the coordinates of these hypothetical molecules $m$, equations which must, in addition, conform to the laws of dynamics; and, on the other hand, when we know the relations which define the coordinates of the molecules $m$ as functions of the parameters $q$, attainable by experiment.  These equations, as I have said, should conform to the principles of dynamics, and, in particular, to the principle of the conservation of energy, and to that of least action.  
    
    The first of these two principles teaches us that the total energy is constant, and may be divided into two parts:
    
    (1) Kinetic energy, or \emph{vis viva}, which depends on the masses of the hypothetical molecules $m$, and on their velocities.  This I shall call $T$.  (2) The potential energy which depends only on the coordinates of these molecules, and this I shall call $U$.  It is the sum of the energies $T$ and $U$ that is constant.
    
    Now what are we taught by the principle of least action?  It teaches us that to pass from the initial position occupied at the instant $t_0$ to the final position occupied at the instant $t_1$, the system must describe such a path that in the interval of time between the instant $t_0$ and $t_1$, the mean value of the action---\emph{i.e.}, the \emph{difference} between the two energies $T$ and $U$, must be as small as possible.  The first of these two principles is, moreover, a consequence of the second.  If we know the functions $T$ and $U$, this second principle is sufficient to determine the equations of motion.  
    
    Among the paths which enable us to pass from one position to another, there is clearly one for which the mean value of the action is smaller than for all the others.  In addition, there is only [one] such path; and it follows from this, that the principle of least action is sufficient to determine the path followed, and therefore the equations of motion.  We thus obtain what are called the equations of Lagrange.  In these equations the independent variables are the coordinates of the hypothetical molecules $m$; but I now assume that we take for the variables the parameters $q$, which are directly accessible to experiment.
    
    The two parts of the energy should then be expressed as a function of the parameters $q$ and their derivatives; it is clear that it is under this form that they will appear to the experimenter.  The latter will naturally endeavor to define kinetic and potential energy by the aid of quantities he can directly observe.  If this be granted, the system will always proceed from one position to another by such a path that the mean value of the action is a minimum.  It matters little that $T$ and $U$ are now expressed by the aid of the parameters $q$ and their derivatives; it matters little that it is also by the aid of these parameters that we define the initial and final positions; the principle of least action will always remain true.
    
    Now here again, of the whole of the paths which lead from one position to another, there is one and only one for which the mean action is a minimum.  The principle of least action is therefore sufficient for the determination of the differential equations which define the variations of the parameters $q$.  The equations thus obtained are another form of Lagrange's equations.
    
    To form these equations we need not know the relations which connect the parameters $q$ with the coordinates of the hypothetical molecules, nor the masses of the molecules, nor the expression of $U$ as a function of the coordinates of these molecules.  All we need know is the expression of $U$ as a function of the parameters $q$, and that of $T$ as a function of the parameters $q$ and their derivatives---\emph{i.e.}, the expressions of the kinetic and potential energy in terms of experimental data.
    
    One of two things must now happen.  Either for a convenient choice of $T$ and $U$ the Lagrangian equations, constructed as we have indicated, will be identical with the differential equations deduced from experiment, or there will be no functions $T$ and $U$ for which this identity takes place.  In the latter case it is clear that no mechanical explanation is possible.  The \emph{necessary} condition for a mechanical explanation to be possible is therefore this: that we may choose the functions $T$ and $U$ so as to satisfy the principle of least action, and of the conservation of energy.  Besides, this condition is \emph{sufficient}.  Suppose, in fact, that we have found a function $U$ of the parameters $q$, which represents one of the parts of energy, and that the part of the energy which we represent by $T$ is a function of the parameters $q$ and their derivatives; that it is a polynomial of the second degree with respect to its derivatives, and finally that the Lagrangian equations formed by the aid of these two functions $T$ and $U$ are in conformity with the data of the experiment.  How can we deduce from this a mechanical explanation?  $U$ must be regarded as the potential energy of a system of which $T$ is the kinetic energy.  There is no difficulty as far as $U$ is concerned, but can $T$ be regarded as the \emph{vis viva} of a material system?
    
    It is easily shown that this is always possible, and in an unlimited number of ways.  I will be content with referring the reader to the pages of the preface of my \emph{\'Electricit\'e et Optique} for further details.  Thus, if the principle of least action cannot be satisfied, no mechanical explanation is possible; if it can be satisfied, there is not only one explanation, but an unlimited number, whence it follows that since there is one there must be an unlimited number.
    
    One more remark.  Among the quantities that may be reached by experiment directly we shall consider some as the coordinates of our hypothetical molecules, some will be our parameters $q$, and the rest will be regarded as dependent not only on the coordinates but on the velocities---or what comes to the same thing, we look on them as derivatives of the parameters $q$, or as combinations of these parameters and their derivatives.
    
    Here then a question occurs: among all these quantities measured experimentally which shall we choose to represent the parameters $q$? and which shall we prefer to regard as the derivatives of these parameters?  This choice remains arbitrary to a large extent, but a mechanical explanation will be possible if it is done so as to satisfy the principle of least action.
    
    Next, Maxwell asks: Can this choice and that of the two energies $T$ and $U$ be made so that electric phenomena will satisfy this principle?  Experiment shows us that the energy of an electro-magnetic field decomposes into electro-static and electro-dynamic energy.  Maxwell recognised that if we regard the former as the potential energy $U$, and the latter as the kinetic energy $T$, and that if on the other hand we take the electro-static charges of the conductiors as the parameters $q$---under these conditions, Maxwell has recognised that electric phenomena satisfies the principle of least action.  He was then certain of a mechanical explanation.  If he had expounded this theory at the beginning of his first volume, instead of relegating it to a corner of the second, it would not have escaped the attention of most readers.  If therefore a phenomenon allows of a complete mechanical explanation, it allows of an unlimited number of others, which will equally take into account all the particulars revealed by experiment.  And this is confirmed by the history of every branch of physics.  In Optics, for instance, Fresnel believed vibration to be perpendicular to the plane of polarisation; Neumann holds that it is parallel to that plane.  For a long time an \emph{experimentum crucis} was sought for, which would enable us to decide between these two theories, but in vain.  In the same way, without going out of the domain of electricity, we find that the theory of two fluids and the single fluid theory equally account in a satisfactory manner for all the laws of electro-statics.  All these facts are easily explained, thanks to the properties of the Lagrange equations.
    
    It is easy now to understand Maxwell's fundamental idea.  To demonstrate the possibility of a mechanical explanation of electricity we need not trouble to find the explanation itself; we need only know the expression of the two functions $T$ and $U$, which are the two parts of energy, and to form with these two functions Lagrange's equations, and then to compare these equations with the experimental laws.
    
    How shall we choose from all the possible explanations one in which the help of experiment will be wanting?  The day will perhaps come when physicists will no longer concern themselves with questions which are inaccessible to positive methods, and will leave them to the metaphysicians.  That day has not yet come; man does not so easily resign himself to remaining for ever ignorant of the causes of things.  Our choice cannot be therefore any longer guided by considerations in which personal appreciation plays too large a part.  There are, however, solutions which all will reject because of their fantastic nature, and others which all will prefer because of their simplicity.  As far as magnetism and electricity are concerned, Maxwell abstained from making any choice.  It is not that he has a systematic contempt for all that positive methods cannot reach, as may be seen from the time he has devoted to the kinetic theory of gases.  I may add that if in his \emph{magnum opus} he develops no complete explanation, he has attempted one in an article in the \emph{Philosophical Magazine}.  The strangeness and the complexity of the hypotheses he found himself compelled to make, led him afterwards to withdraw it.  
    
    The same spirit is found throughout his whole work.  He throws into relief the essential---\emph{i.e.}, what is common to all theories; everything that suits only a particular theory is passed over almost in silence.  The reader therefore finds himself in the presence of form nearly devoid of matter, which at first he is tempted to take as a fugitive and unassailable phantom.  But the efforts he is thus compelled to make force him to think, and eventually he sees that there is often something rather artificial in the theoretical ``aggregates'' which he once admired.
    
    \citep[p. 217-224]{Poincare1952}
\end{quote}

- ch. 13 electrodynamics, ampere vs helmholtz regarding faraday unipolar induction experiment.  a bit hard to follow

\begin{quote}
    III. \emph{Difficulties raised by these Theories.}---Helmholtz's theory is an advance on that of Amp\`ere; it is necessary, however, that every difficulty should be removed.  In both, the name ``magnetic field'' has no meaning, or, if we give it one by a more or less artificial convention, the ordinary laws so familiar to electricians no longer applly; and it is thus that the electro-motive force induced in a wire is no longer measured by the number of lines of force met by that wire.  And our objections do not proceed only from the fact that it is difficult to give up deeply rooted habits of language and thought.  There is something more.  If we do not believe in actions at a distance, electrodynamic phenomena must be explained by a modification of the medium.  And this medium is precisely what we call ``magnetic field,'' and then the electromagnetic effects should only depend on that field.  All these difficulties arise from the hypothesis of open currents.
    
    IV.  \emph{Maxwell's Theory.}---Such were the difficulties raised by the current theories, when Maxwell with the stroke of a pen caused them to vanish.  To his mind, in fact, all currents are closed currents.  Maxwell admits that if in a dielectric, the electric field happens to vary, this dielectric becomes the seat of a particular phenomenon acting on the galvanometer like a current and called the \emph{current of displacement}.  If, then, two conductors bearing positive and negative charges are placed in connection by means of a wire, during the discharge there is an open current of conduction in that wire; but there are produced at the same time in the surrounding dielectric currents of conduction.  We know that Maxwell's theory leads to the explanation of optical phenomena which would be due to extremely rapid electrical oscillations.  At that period such a conception was only a daring hypothesis which could be supported by no experiment; but after twenty years Maxwell's ideas received the confirmation of experiment.  Hertz succeeded in producing systems of electric oscillations which reproduce all the properties of light, and only differ by the length of their wave---that is to say, as violet differs from red.  In some measure he made a synthesis of light.  It might be said that Hertz has not directly proved Maxwell's fundamental idea of the action of the current of displacement on the galvanometer.  That is true in a sense.  What he has shown directly is that electromagnetic induction is not instantaneously propagated, as was supposed, but its speed is the speed of light.  Yet, to suppose there is no current of displacement, and that induction is with the speed of light; or, rather, to suppose that the currents of displacement produce inductive effects, and that the induction takes place instantaneously---\emph{comes to the same thing}.  This cannot be seen at the first glance, but it is proved by an analysis of which I must not even think of giving even a summary here.
    
    \citep[p. 238-240]{Poincare1952}
\end{quote}

- Rowland's experiment, Lorentz's theory

\begin{quote}
    According to Lorentz's theory, currents of conduction would themselves be true convection currents.  Electricity would remain indissolubly connected with certain material particles called \emph{electrons}.  The circulation of these electrons through bodies would produce voltaic currents, and what would distinguish conductors from insulators would be that the one could be traversed by these electrons, while the others would check the movement of the electrons.  Lorentz's theory is very attractive.  It gives a very simple explanation of certain phenomena, which the earlier theories---even Maxwell's in its primitive form---could only deal with in an unsatisfactory manner; for example, the aberration of light, the partial impulse of luminous waves, magnetic polarisation, and Zeeman's experiment.  
    
    A few objections still remained.  The phenomena of an electric system seemed to depend on the absolute velocity of translation of the centre of gravity of this system, which is contrary to the idea that we have of the relativity of space.  Supported by M. Cr\'emieu, M. Lippman has presented this objection in a very striking form.  Imagine two charged conductors with the same velocity of translation.  They are relatively at rest.  However, each of them being equivalent to a current of convection, they ought to attract one another, and by measuring this attraction we could measure their absolute velocity.  ``No!'' replied the partisans of Lorentz.  ``What we could measure in that way is not their absolute velocity, but their relative velocity \emph{with respect to the ether}, so that the principle of relativity is safe.''  Whatever there may be in these objections, the edifice of electrodynamics seemed, at any rate in its broad lines, definitively constructed.  Everything was presented under the most satisfactory aspect.  The theories of Amp\`ere and Helmholtz, which were made for the open currents that no longer existed, seem to have no more than purely historic interest, and the inextricable complications to which these theories led have been almost forgotten.  This quiescence has been recently disturbed by the experiments of M. Cr\'emieu, which have contradicted, or at least have seemed to contradict, the results formerly obtained by Rowland.  Numberous investigators have endeavoured to solve the question, and fresh experiments have been undertaken.  What result will they give?  I shall take care not to risk a prophecy which might be falsified between the day this book is ready for the press and the day on which it is placed before the public.  
    
    THE END
    
    \citep[p. 242-244]{Poincare1952}
    
    
\end{quote}

% \section{Hints of Intuitionism}

% Poincare, Brouwer, Weyl, 


% \section{Cartwright}

% -anti-realist, accepts phenomenological laws not theoretical

% Phenomenological vs. fundamental laws

% -argues that phenomenological are better off to pass tests than fundamental

% -explanatory power != truth

% -fundamental laws don't get the facts right

% -simulacrum account explanation

% \begin{quote}
%     The route from theory to reality is from theory to model, and then from model to phenomenological law.  The phenomenological laws are indeed true of the objects in reality---or might be; but the fundamental laws are true only of objects in the model.  \citep[p. 4]{Cartwright1983}
% \end{quote}

% -Against IBE

% -radiometer example

% \begin{quote}
%     I will argue that the falsehood of fundamental laws is a consequence of their great explanatory power.  This is the exact opposite of what is assumed by a well-known and widely discussed argument form---inference to the best explanation.  The basic idea of this argument is: if a hypothesis explains a sufficiently wide variety of phenomena well enough, we can infer that the hypothesis is true.  Advocates of this argument form may disagree about what counts as well enough, or how much variety is necessary.  But they all think that explanatory power, far from being at odds with truth, leads us to it.  My first line of argument in these essays denies that explanation is a guide to truth.
    
%     Numerous traditional philosophical positions bar inferences to best explanations.  Scepticism, idealism, and positivism are examples.  But the most powerful argument I know is found in Pierre Duhem's \emph{Aim and Structure of Physical Theory}, reformulated in a particularly pointed way by Bas van Fraassen in his recent book \emph{The Scientific Image}.  Van Fraassen asks, what has explanatory power to do with truth?  He offers more a challenge than an argument: show exactly what about the explanatory relationship tends to guarantee that if $x$ explains $y$ and $y$ is true, then $x$ should be true as well.  This challenge has an answer in the case of \emph{causal} explanation, but \emph{only} in the case of causal explanation.  That is my thesis in `When Explanation Leads to Inference'.  Suppose we describe the concrete causal process by which a phenomenon is brought about.  That kind of explanation succeeds only if the process described actually occurs.  To the extent that we find the causal explanation acceptable, we must believe in the causes described.
    
%     \citep[p. 4-5]{Cartwright1983}
% \end{quote}

% \begin{quote}
%     Causal reasoning provides good grounds for our beliefs in theoretical entities.  Given our general knowledge about what kinds of conditions and happenings are possible in the circumstances, we reason backwards from the detailed structure of the effects to exactly what characteristics the causes must have in order to bring them about.  I have sometimes summarized my view about explanation this way: no inference to best explanation; only inference to most likely cause.  But that is right only if we are very careful about what makes a cause `likely'.  We must have reason to think that this cause, and no other, is the only practical possibility, and it should take a good deal of critical experience to convince us of this.  
    
%     We make our best causal inferences in very special situations---situations where our general view of the world makes us insist that a known phenomenon has a cause; where the cause we cite is the kind of thing that could bring about the effect and there is an appropriate process connecting the cause and the effect; and where the likelihood of other causes is ruled out.  This is why controlled experiments are so important in finding out about entities and processes which we cannot observe.  Seldom outside of the controlled conditions of an experiment are we in a situation where cause can legitimately be inferred.  \citep[p. 6]{Cartwright1983}
% \end{quote}

% Ashby?  Isn't `causality' just a summarizing convenience (following Poincar\'e) applied to a certain class of transitions between states of the world?  In other words, won't it have problems like a fuzzy boundary due to similar reasons that realism about theoretical entities does?

% ``Experiments are made to isolate true causes and to eliminate false starts.''\citep[p. 7]{Cartwright1983}

% \begin{quote}
%     Explanatory power is no guarantee of truth, unless van Fraassen's challenge can be met.  I argue that, in the very special case of causal explanation, the challenge is met.  In causal explanations truth is essential to explanatory success.  But it is only the truth of low-level causal principles and concrete phenomenological laws.  Is there no further account that secures the truth of abstract laws as well; no story of explanation that shows that abstract laws must be true if they are to explain?  There are two models of theoretical explanation that could do so.  I discuss them in Essay 6.  Both have serious flaws.  The other essays in this volume that argue against inference to the best explanation are `When Explanation Leads to Inference', and `The Reality of Causes in a World of Instrumental Laws'.  \citep[p. 10]{Cartwright1983}
% \end{quote}

% -Composition of causes

% \begin{quote}
%     `For Phenomenological Laws' argues this point.  Much of this essay is taken from a joint paper with Jon Nordby and it begins from a view we both share: there are no rigorous solutions for real life problems.  Approximations and adjustments are required whenever theory treats reality. \citep[p. 13]{Cartwright1983}
% \end{quote}

% -Nordby \emph{ad vero} approximations

% \begin{quote}
%     How do we fit a phenomenon into a general theoretical framework?
    
%     Prima facie, the covering-law model seems ideally suited to answer: we fit a phenomenon into a theory by showing how various phenomenological laws which are true of it derive from the theory's basic laws and equations.  This way of speaking already differentiates me from the covering-law theorist.  I do not talk about explaining a feature of a phenomenon by deriving a description of that feature; but rather of treating a phenomenon by deriving a variety of phenomenological laws about it.  But this is not the primary difference.  The `covering' of `covering-law model' is a powerful metaphor.  It teaches not only that phenomenological laws can be derived from fundamental laws, but also that the fundamental laws are laws that govern the phenomena.  They are laws that cover the phenomena, perhaps under a more general or abstract description, perhaps in virtue of some hidden micro-structural features; but still the fundamental laws apply to the phenomena and describe how they occur.  
    
%     I propose instead a `simulacrum' account.  That is not a word we use any more, but one of its dictionary definitions captures exactly what I mean.  According to the second entry in the Oxford English Dictionary, a simulacrum is `something having merely the form or appearance of a certain thing, without possessing its substance or proper qualities'.  On the simulacrum account, to explain a phenomenon is to construct a model which fits the phenomenon into a theory.  The fundamental laws of the theory are true of the objects in the model, and they are used to derive a specific account of how these objects behave.  But the objects of the model have only `the form or appearance of things' and, in a very strong sense, not their `substance or proper qualities'.
    
%     The covering-law account supposes that there is, in principle, one `right' explanation for each phenomenon.  The simulacrum account denies this.  The success of an explanatory model depends on how well the derived laws approximate the phenomenological laws and the specific causal principles which are true of the objects modelled.  There are always more phenomenological laws to be had, and they can be approximated in better and in different ways.  There is no single explanation which is the right one, even in the limit, or relative to the information at hand.  Theoretical explanation is, by its very nature, redundant.  This is one of the endemic features of explanation in physics which the deductive-nomological (D-N) account misses, albeit with the plea that this annoying feature will no longer be present when the end of physics is achieved.  \citep[p. 16-17]{Cartwright1983}
% \end{quote}

% \begin{quote}
%     The lesson for the truth of fundamental laws is clear: fundamental laws do not govern objects in reality; they govern only objects in models. \citep[p. 18]{Cartwright1983}
% \end{quote}

% - positivist conviction ``there is no better reality besides the reality we have to hand.'' p. 19

% \begin{quote}
%     Richard Feynman talks about explaining in physics as fitting phenomena into `the patterns of nature'.  But where are the patterns?  Things happen in nature.  Often they happen in regular ways when the circumstances are similar; the same kinds of causal processes recur; there are analogies between what happens in some situations and what happens in others.  As Duhem suggests, what happens may even be organized into natural kinds in a way that makes prediction easy for us (see the last section of `When Explanation Leads to Inference').  But there is only what happens, and what we say about it.  Nature tends to a wild profusion, which our thinking does not wholly confine.  
    
%     The metaphysical picture that underlies these essays is an Aristotelian belief in the richness and variety of the concrete and particular.  Things are made to look the same only when we fail to examine them too closely.  Pierre Duhem distinguished two kinds of thinkers: the deep but narrow minds of the French, and the broad but shallow minds of the English.  The French mind sees things in an elegant, unified way.  It takes Newton's three laws of motion and turns them into the beautiful, abstract mathematics of Lagrangian mechanics.  The English mind, says Duhem, is an exact contrast.  It engineers bits of gears, and pulleys, and keeps the strings from tangling up.  It holds a thousand different details all at once, without imposing much abstract order or organization.  The difference between the realist and me is almost theological.  The realist thinks that the creator of the universe worked like a French mathematician.  But I think that God has the untidy mind of the English.
    
%     \citep[p. 19]{Cartwright1983}
% \end{quote}

% \subsection{On Measurement Problem}

% \begin{quote}
%     Unitarity is a property of operators.  Those operators that are unitary represent motions that are indeterministic.  Unitarity plays no causal role in the theory; nothing else about its use argues for interpreting it as a real property either.  Yet there is a tendency to think of it not only as a mathematical characteristic of operators, but also as a genuine property of the situations represented by the operators.  This, I claim, is the source of the notorious measurement problem in quantum mechanics.  Unitarity marks no real property in quantum theory, and if we do not suppose that it must do so we have no interesting philosophical problem about measurement.  \citep[p. 18]{Cartwright1983}
% \end{quote}

% - (but issue accounting for EPR)

\section{Riezler Quotes}

Subtitle of book: Lectures of Aristotle on Modern Physics at an International Congress of Science

Riezler is channeling or pretending for argumentative and dialectic purposes to be ``Aristotle'' in his address and critiques of modern science after the turn of the century.

\begin{quote}
     The declination of your psi functions in quantum theory refers to secondary not to primary, to compound not to simple movements. The psi functions report the chances of an observation to find a place $A$ for a charge $B$, or for a charge $X$ a place $Y$. They distribute the chances of a charge to places, the chances of a place to charges. The change of chance cannot be primary motion. Chance is chance for an event. Instead of the 'ether' the probability wave does the vibrating. But what vibrates? The chance for an event.

     Again, what is an event? Here you have no answer, except the answer of classical physics. But you cannot apply this unless you decide to lift yourselves up by your own bootstraps. The situation is curious. You proceed from discovery to discovery; that I do not deny. These discoveries are firmly rooted in shifting ground. They are rules for the coincidences of numbers signifying chances for events.

     In this situation you turn to philosophy to provide you with a theory of knowledge enabling you to get around any troublesome question. It is the old dodge: the real is the observable---at least for the physicist. You first define the physicist, setting his task. Then you limit the observable: the pointer readings of possible instruments. This is the `reality' relative to your anonymous observer. I do not know whet11er this can be called theory of knowledge. Anyway it is not philosophy. It seems to me merely a definition of physics.

    But that we have already discussed. Applying this so-called theory to your new situation you argue: The only knowledge I shall and can have is knowledge of psi functions. I know all that `is' when I know all I can. It may be and usually is the case that I do not know the psi function or know it insufficiently. Then the probability this psi function reports is but relative to my insufficient knowledge. However, if I have a `maximum knowledge' of the psi function, this psi function is the condition of physics, the maximum knowledge is the thing itself.

    I understand why you assert this. You want to prevent na\"ive perceptions from interfering with the numbers of the anonymous observer. If an accurate location of an electron is not observable, then an accurate location should not be postulated. An `accurate location' of an electron is for the physicist a senseless term, to which nothing real corresponds. I approve your intention. The anonymous observer should not mix into his numbers
    concepts he cannot legitimate. Neverthe1ess, you cannot stop here. Probabilities are probabilities of something. A probability of nothing is still more senseless than an accurate location of an electron.

    The physicists of past times have developed your preconceptions of tho measured and measurable quantities on the strength of occurrences on a large scale---without any insight into the microworld. Now you find that these quantities are measurable with but limited accuracy. Perhaps they are not really the right concepts. If they are not, then the task would be to discover the right concepts, the true building stones of Being. But this you do not attempt. Numbers, psi functions, are observable and therefore real, even though they are probabilities of nothing. No! my friends.

    \citep[p. 31-32]{Riezler1940}
\end{quote}

\section{Idealism and the Unity of Subject and Object}


Adorno paper
Hegel

Husserl moving from limitations in phenomenology towards Hegelian idealism



\section{Transcendental Epistemology in the Tangent Space}

A tangent space is an abstract mathematical space, characterized by 

We can presume that the point on a manifold from which the tangent space is constructed is considered to be the object of realism and anti-realism debates.  It is characterized e.g. by matter and natural dynamical laws.  The tangent space, on the other hand, contains much more information.  I argue that many fundamental epistemological and metaphysical debates actually occur in the tangent space, and it is helpful to realize this.

For example, Heisenberg talks about potentialities in quantum mechanics.  Are these potentialities properties of the supposed real dynamics of the world, or are they things we can ``see'' in the tangent space?  In other words, the potentialities are transcendental objects characterized by epistemology tangent to the phenomenological manifold.

The manifold points are the synthetic objects [WEYL, KANT, HEGEL?] comprised of the epistemological schema in the tangent space, and theory-laden yet phenomenologically adequate laws predicting measurement outcomes.  

\section{Structures as Synthetic Idealist Objects}

Not objects of realism but objects of idealism.

\subsection{Probabilities as Synthetic Objects}

Grant that we are structuralists of some sort, dealing with the phenomenological or mathematical structures of experiences or the theory that may account for the phenomenological experiences in observation.  

Say we assume group theory is a framework for characterizing either of these kinds of structures, whether they are mathematically explicit or presumed possible in some future state of epistemology (if philosophers can manage to improve upon our present situation).

Where are probabilities, particularly quantum probabilities, appropriately characterized in the structuralist landscape?  Are they like rotations (and the group constituted by a set of rotations), rather more formal and mathematical?  Or are they like conceptual or phenomenological structures, of a more epistemological character?  

If a set of operations 






\subsection{It from Bit}

Instead of going the participatory realism route, like Wheeler [FRENCH AND BITBOL TOO?] we can go with Weyl and Eddington and Cassirer towards rendering objects of fundamental physical theories as epistemological, and ideal.

This section needs Fuchs, French, Bitbol citations/discussion added

\subsection{Kant and Geometry}

A structural realist might say that what Euclidean geometry gets right (for understanding space and the physical world) is the approximate aspects of our reality, under certain limits, that are more or less invariant in non-Euclidean geometrical parts of modern physics.  These invariant parts correspond, in Riemannian geometry, for example, to roughly the Minkowski parts of tangent spaces.  So, in a space tangential to the Riemannian manifold, which we suppose has some better correspondence to measurable physics, under certain approximate conditions there is a structure which resembles that of a Euclidean structure.




\section{Eddington on Quantum Probabilities}
\sectionmark{Eddington Q. Prob.}

If we are interested in some aspects of potential consistecy between Eddington's views and PR or Qbism, it is also important to note before getting to some of the particular quantum probability statements, that Eddington does at least appear to adhere to one epistemological tenet about beliefs---that they can come in degrees.  For many Bayesians, the probability calculus is about subjective degrees of belief.  That is, the numbers are subjective or epistemological or ideal or synthetic objects.

\begin{quote}
    One believes with varying degrees of confidence.  My belief that I know the exact number of protons and electrons in the universe does not rank among my strongest scientific convictions, but I should describe it as a fair average sort of belief.  I am, however, strongly convinced that, if I have got the number wrong, it is just a silly mistake, which would speedily be corrected if there were more workers in this field.  In short, to know the exact number of particles in the universe is a perfectly legitimate aspiration of the physicist.  \citep[p. 171]{Eddington1939}
\end{quote}




\begin{quote}
    It seems to me that the ``enlarged'' physics which is to include the objective as well as the subjective is just \emph{science}; and the objective, which has no reason to conform to the pattern of systematisation that distinguishes present-day physics, is to be found in the non-physical part of science.  We should look for it in the part of biology (if any) which is not covered by biophysics; in the part of psychology which is not covered by psychophysics; and perhaps in the part of theology which is not covered by theophysics.  The purely objective sources of the objective element in our observational knowledge have already been named; they are \emph{life, consciousness, spirit}.
    
    We reach then the position of idealist, as opposed to materialist, philosophy.  The purely objective world is the spiritual world; and the material world is subjective in the sense of selective subjectivism.
    
    \citep[p. 68-69]{Eddington1939}
\end{quote}

- Quoting the entire section VI of chapter V (Epistemology and Relativity Theory) as it expresses I think fairly clearly an intersubjective idealism about observational physics.  Also note the comment about a subjective interpretation of probability.

\begin{quote}
    I have been continually emphasizing the subjectivity of the universe described in physical science.  But, you may ask, was it not the boast of the theory of relativity that it penetrated beyond the relative (subjective) aspect of phenomena and dealt with the absolute?  For example, it showed that the usual separation of space and time is subjective, being dependent on the observer's motion, and it substituted a four-dimensional space-time independent of the observer.  It may seem difficult to reconcile this view of Einstein's theory as lifting the veil of relativity which hides the absolute from us, with my present account of modern physics as acquiescing in, and making the bet of, a partially subjective universe.

    It is necessary to remember that there has been thirty years' progress.  Relativity began like a new broom, sweeping away all the subjectivity it found.  But, as we have advanced, other influences of subjectivity have been detected which are not so easily eliminated.  Probability, in particular, is frankly subjective, being relative to the knowledge which we happen to possess.  Instead of being swept away, it has been exalted by wave mechanics into the main theme of physical law.

    The subjectivity referred to in these lectures is that which arises from the sensory and intellectual equipment of the observer.  Without varying this equipment, he can vary in position, velocity and acceleration.  Such variations will produce subjective changes in the appearance of the universe to him; in particular the changes depending on his velocity and acceleration are more subtle than was realised in classical theory.  Relativity theory allows us to remove (if we wish) the subjective effects of these \emph{personal} characteristics of the observer; but it does not remove the subjective effects of \emph{generic} characteristics common to all ``good'' observers---although it has helped to bring them to light.

    Confining attention to the personal, as distinguished from the generic, subjectivity, let us see precisely what is meant by removing this subjectivity.  There does not seem to be much difficulty in conceiving the universe as a three-dimensional structure viewed from no particular position; and I suppose we can, after a fashion, conceive it without any standard of rest or of non-acceleration.  It is perhaps rather unfortunate that it is, or seems to be, so easy to conceive; because the conception is liable to be mischievous from the observational point of view.  Since physical knowledge must in all cases be an assertion of the results of observation (actual or hypothetical), we cannot avoid setting up a dummy observer; and the observations which he is supposed to make are subjectively affected by his position, velocity and acceleration.  The nearest we can get to a non-subjective, but nevertheless observational, view is to have before us the reports of all possible dummy observers, and pass in our minds so rapidly from one to another that we identify ourselves, as it were, with all the dummy observers at once.  To achieve this we seem to need a revolving brain.  

    Nature not having endowed us with revolving brains, we appeal to the mathematician to help us.  He has invented a transformation process which enables us to pass very quickly from one dummy observer's account to another's.  The knowledge is expressed in terms of tensors which have a fixed system of interlocking assigned to them; so that when one tensor is altered all the other tensors are altered, each in a determinate way.  By assigning each physical quantity to an appropriate class of tensor, we can arrange that, when one quantity is changed to correspond to the change from dummy observer $A$ to dummy observer $B$, all the other quantities change automatically and correctly.  We have only to let one item of knowledge run through its changes---to turn one handle---to get in succession the complete observational knowledge of all the dummy observers.

    The mathematician goes one step farther; he eliminates the turning of the handle.  He conceives a tensor symbol as containing in itself all its possible changes; so that when he looks at a tensor equation, he sees all its terms changing in synchronised rotation.  This is nothing out of the way for a mathematician; his symbols commonly stand for unknown quantities, and functions of unknown quantities; they are everything at once until he chooses to specify the unknown quantity.  And so he writes down the expressions which are symbolically the knowledge of all the dummy observers at once---until he chooses to specify a particular dummy observer.

    But, after all, this device is only a translation into symbolism of what we have called a revolving brain.  A tensor may be said to symbolise absolute knowledge; but that is because it stands for the subjective knowledge of all possible subjects at once.  

    This applies to personal subjectivity.  To remove the generic subjectivity, due say to our intellectual equipment, we should have similarly to symbolise the knowledge as it would be apprehended by all possible types of intellect at once.  But this could scarcely be accomplished by a mathematical transformation theory.  And what would be the result if it were accomplished?  According to Chapter IV, if we remove all subjectivity we remove all the fundamental laws of nature and all the constants of nature.  But, after all, these subjective laws and facts happen to be important to beings who are not equipped with revolving brains and variable intellects.  And if the physicist does not take charge of them, no one else is qualified to do so.  Even in relativity theory, which deals with the absolute (in a somewhat limited sense), we continually hark back to the relative to examine how our results will appear in the experience of an individual observer.  We are not so eager now as we were twenty years ago to eliminate the observer from our world view.  Sometimes it may be desirable to banish him and his subjective distortion of things for a time, but we are bound to bring him back in the end; for he stands for---ourselves. \citep[p. 85-88]{Eddington1939}
\end{quote}

\subsubsection{Chapter VI: Epistemology and Quantum Theory}

\begin{quote}
    I must still keep hammering at the question, What do we really observe?  Relativity theory has returned one answer---we only observe \emph{relations}.  Quantum theory returns another answer---we only observe \emph{probabilities}. \citep[p. 89]{Eddington1939}
\end{quote}

- Heisenberg uncertainty principle as consequence of different measurements as source for irreducible indeterminism in QM

\begin{quote}
    The suggestion is that in the new physics the so-called probabilities are actually the real entities---the elemental stuff of the physical universe.  We have precise knowledge of \emph{them}; and it would seem retrogressive to postulate other entities behind them of which our knowledge must always be uncertain.  

    I think that this idea is at the back of a rather common suggestion that a proper reformulation of our elementary concepts would banish the present indeterminism from the system of physics.  The idea is that the indeterminism revealed by the new physics is not intrinsic in the universe, but appears only in our attempt to connect it with the obsolete universe of classical physics.  Probability would then be merely the funnel through which the new wine is poured into old bottles.  

    But the suggestion overlooks the essential feature of the indeterminism of the present system of physics, namely that the quantities which it can predict only with uncertainty are quantities which, \emph{when the time comes}, we shall be able to observe with high precision.  The fault is therefore not in our having chosen concepts inappropriate to observational knowledge.  For example, Heisenberg's principle tells us that the position and velocity of an electron at any moment can only be known with a mutually related uncertainty; and, taking the most favourable combination, the position of the electron one second later is uncertain to about 4 centimetres.  This is the uncertainty of the prediction from the best possible knowledge we can have at the time.  But one second later the position can be observed with an uncertainty of no more than a fraction of a millimetre.  It has often been argued that the impossibility of knowing simultaneously the exact position and exact velocity only shows that position and velocity are unsuitable conceptions to use in expressing our knowledge.  I have no special attachment to these conceptions; and I will grant, if you like, that our knowledge of the universe at the present moment can be regarded as perfectly determinate (the supposed indeterminacy being introduced in translating it into an inappropriate frame of conception).  But that does not remove the ``indeterminism'' (which is distinct from the ``indeterminacy''), namely that this knowledge, however expressed, is inadequate to predict quantities which, independently of our frame of conception, can be directly observed when the time comes.  
    
    Returning to the more general aspect of the probability conception, we find that it cannot be got rid of by any transformation of outlook.  It is not possible to transform the current system of physics, which by its equations links probabilities in the future with probabilities in the present, into a system which links ordinary physical quantities in the future with ordinary physical quantities in the present, without altering its observable content.  The bar to such a transformation is that probability is not an ``ordinary physical quantity''.  At first sight it appears to be one; we obtain knowledge of it from observation, or from a mixture of observation and deduction, as we obtain knowledge of other physical quantities.  But it is differentiated from them by a peculiar irreversibility of its relation to observation.  The result of an observation determines definitely a probability distribution of some quantity, or a modification of a previously existing probability distribution; but the connection is not reversible, and a probability distribution does not determine definitely the result of an observation.  For an ordinary physical quantity there is no difference between making a new determination and verifying a predicted value; but for probability the procedures are distinct.  

    Thus we may expand the answer of quantum theory that ``we only observe probabilities'' into the form: The synthesis of knowledge which constitutes theoretical physics is connected with observation by an \emph{irreversible} relation of the formal type familiar to us in the concept of probability.
    \citep[p. 90-91]{Eddington1939}
\end{quote}

- End of quote above talking about probability as structural invariant in some sense like Cassirer would general covariance (does Ryckman also notice this?)

- Irreversibility illustrated through bag w/ colored ball example, comparing to wave packet probability distributions

\begin{quote}
    According to wave mechanics, an observation determines or produces a concentrated wave packet in the probability distribution.  This wave packet diffuses according to laws embodied in the equations of the theory; and we can calculate the form into which the wave packet will have spread one unit of time later.  \emph{But the theory does not assert that this is the form of wave packet which would be produced by an observation made one unit of time later.}  On the other hand, if from the observationally determined form of a sound wave at one instant we calculate the form into which it will have spread one unit of time later, the whole point of the theory is that we obtain the form which would be determined by observations made one unit of time later.  \citep[p. 93]{Eddington1939}
\end{quote}

- ``an observation'' vs ``an item of observational knowledge''.  Holistic view, Quine?

\begin{quote}
    More generally we must recognise that an item of observational knowledge involves, besides a primary pointer reading, secondary pointer readings identifying the circumstances in which the primary pointer reading occurred.  It must be admitted that even an isolated pointer reading is an item of knowledge of a sort; but it is not with such items that the scientific method deals.  For scientific knowledge the association with other pointer readings is an essential condition; and we may therefore describe physical knowledge as a knowledge of the associations of pointer readings.  \citep[p. 100]{Eddington1939}
\end{quote}

- Referring to other book, criticizing older position.  Alluding to uncertainty principle: pointer reading interference.  Wave mechanics(!)  Scope of physical knowledge and defining physical universe.

\begin{quote}
    In \emph{The Nature of the Physical World} it is emphasised that physical knowledge is concerned with the connection of pointer readings rather than with the pointer readings themselves; and it is concluded that the connectivity of pointer readings, as expressed by the laws of physics, supplies the common background which realistic problems always demand---the background described by the tertiary pointer readings which are not determined afresh for each individual item of knowledge.  But, if I may venture to criticise the author of that book, he does not seem to have appreciated the difficulty which arises through the interference of pointer readings with one another when we contemplate such an unlimited multiplicity of pointer readings.  It is true that the interference is negligible in molar physics (to which the discussion in \emph{The Nature of the Physical World} was limited).  But in a fundamental discussion of this kind it is not legitimate to separate molar physics from microscopic physics; for we have seen (p. 76) that neither branch is logically complete in itself.  
    
    Our definition of the physical universe is that it is the world which physical knowledge is formulated to describe.  The interference of observations creates a difficulty which must be met in one of two ways.  Either we must take the complete description of the physical universe to embody more than the totality of our possible knowledge of it; so that, whichever of two interfering observations we choose to make, there will be a place for it in the description.  Or we must adopt a \emph{flexible} universe containing nothing which is not represented by our actual knowledge (or in theoretical discussions by the supposedly actual knowledge furnished as data of the problem considered).  In the first alternative we cannot consistently suppose all the items of the complete description to be represented by actual pointer readings; and it is therefore not true to say that its structure is a connectivity of pointer readings.  The second alternative is adopted in wave mechanics, which accepts as leading features of the physical universe the probability waves created by actual observation of the physical quantities with which they are associated.  Clearly there is no more than a formal distinction between the study of a universe flexible according to the knowledge we happen to have of it and a direct study of the knowledge itself.  Either alternative brings us back to the conclusion that the common background is required to connect one item of knowledge with the rest of knowledge, rather than one element of an external universe with the rest of the universe.
    \citep[p. 100-102]{Eddington1939}
\end{quote}

- Eddington provides a summary (section V of ch. VI Epistemology and Quantum Theory) which will be useful to have (I feel like I'm typing the whole book...)  Adapting very slightly the enumeration to be LaTeX friendly

\begin{quote}
    The following summary will recall the principal conclusions that we have so far reached:
    \begin{enumerate}
        \item Physical knowledge (by definition) includes only knowledge capable of observational test; an item of physical knowledge must therefore assert the result of a specified observational procedure.
        \item The definitions of the terms used in expressing physical knowledge must be such as to secure that (1) is satisfied.  In particular the definition of a physical quantity must specify unambiguously a method of measuring it.  
        \item Strict adherence to (2) involves a number of modifications of the conceptions and practice of classical physics; and indeed there still survive glaring violations of it in current quantum theory.  The points (4) to (9) below arise when the definitions are scrutinised from this point of view.
        \item The first definitions required are those of length and time-interval, since the definitions of other physical quantities presuppose these.  The standards of length and time must be structures specified by pure numbers only (since no other quantitative terms are available at this early stage).  This means that the standards must be reproducible from a quantum specification.
        \item Only short standards, suitable for measuring infinitesimal displacements in space and time, are provided by such specifications; and it must not be assumed that the infinitesimal displacements so measured are integrable.
        \item Owing to the interference of exact observations with one another, an attempt to define observationally the exact conditions under which the measurement of a physical quantity is intended to be carried out breaks down.  It is therefore necessary to leave the minor details to chance.
        \item In this way the probability conception is incorporated in the fundamental definitions.  It introduces an irreversible relation between observation and formulated observational knowledge.  This irreversibility makes the existing system of physics indeterministic, considered as a system of prediction of what can be observed at a future time.
        \item Certain quantities used in the formulation of physical  knowledge in classical physics are found to have no definition satisfying (2).  These are unobservables, e.g. absolute simultaneity at a distance.
        \item Other quantities, conditionally observable, have been employed in conditions in which they are unobservable.  For example, the definition of relative coordinates presupposes that the particles are distinguishable, but ordinary relative coordinates are still used erroneously in problems concerning indistinguishable particles.
        \item The conclusions (4) to (9) are reached by considering the way in which physical knowledge is obtained and formulated. We refer to them as epistemological or \emph{a priori} conclusions, to distinguish them from \emph{a posteriori} conclusions derived from a study of the results of observations which have been obtained and formulated in this way.
        \item Although epistemological conclusions are of the nature of truisms, they have far-reaching consequences in physics.  Thus the unobservability of absolute simultaneity (8) leads to the special theory of relativity; the non-integrability of displacement (5) leads to Einstein's theory of gravitation; the introduction of the probability conception in a fundamental way (7) leads to the method of wave mechanics.
        \item In the modified theories which result, epistemological principles play a part which was formerly taken by physical hypotheses, i.e. generalisations suggested by an \emph{a posteriori} study of the results of observation.
        \item Current relativity theory and quantum theory, as usually accepted, have not yet taken full advantage of this epistemological method.  It appears that when the epistemological scrutiny of definitions is systematically applied, and its consequences are followed up mathematically, we are able to determine all the ``fundamental'' laws of nature (including purely numerical constants of nature) without any physical hypothesis.
        \item This means that the fundamental laws and constants of physics are wholly subjective, being the mark of the observer's sensory and intellectual equipment on the knowledge obtained through such equipment; for we could not have this kind of \emph{a priori} knowledge of laws governing an objective universe.
        \item It is not suggested that the physical universe is wholly subjective.  Physical knowledge comprises, besides ``laws of nature'', a vast amount of special information about the particular objects surrounding us.  This information is doubtless partly objective as well as partly subjective.
        \item The subjective laws are a consequence of the conceptual frame of thought into which our observational knowledge is forced by our method of formulating it, and can be discovered \emph{a priori} by scrutinising the frame of thought as well as \emph{a posteriori} by examining the actual knowledge which has been forced into it.
        \item The characteristic form of the fundamental laws of physics is the stamp of subjectivity.  If there are also laws of objective origin, they may be expected to be of a different type.  It seems probable that wherever effects of objective governance have appeared they have been regarded as an indication that the subject is ``outside physics'', e.g. conscious volition, or possibly life.
        \item Epistemological laws (if correctly deduced) are compulsory, universal, and exact.  Since the fundamental laws of physics are epistemological, they have this character---contrary to the view usually advocated in scientific philosophy, which has assumed that they are merely empirical regularities.\citep[p. 102-105]{Eddington1939}
    \end{enumerate}
\end{quote}

\subsubsection{Later in the book}

\begin{quote}
    Since then microscopic physics has made great progress, and its laws have turned out to be comprehensible to the mind; but, as I have endeavoured to show, it also turns out that they have been imposed by the mind---by our forms of thought---in the same way that the molar laws are imposed. \citep[p. 180]{Eddington1939}
\end{quote}



- applicability of ``laws of chance'' vs. Heisenberg uncertainty limits and quantum probabilities??? !!!

\begin{quote}
    In current physical theory the undetermined element in the behaviour of a system is treated as a matter of chance.  If there were serious deviations from the law of chance, observation and theory would not agree.  We may therefore say that it is a hypothesis in physics, supported by observation, that there are no objective laws of governance---unless chance is described as a law.

    Nevertheless, if we take a wider view than that of physics, I think it would be misleading to regard chance as the characteristic feature of the objective world.  The denial of objective laws of governance is not so much a hypothesis of physics as a limitation of its subject matter.  Deviations from chance occur, but they are regarded as manifestations of something outside physics, namely consciousness or (more debatably) life.  There is in a human being some portion of the brain, perhaps a mere speck of brain-matter, perhaps an extensive region, in which the physical effects of his volitions begin, and from which they are propagated to the nerves and muscles which translate the volition into action.  We will call this portion of the brain-matter ``conscious matter''.  It must be exactly like inorganic matter in its obedience to the fundamental laws of physics which, being of epistemological origin, are compulsory for all matter; but it cannot be identical in all respects with inorganic matter, for that would reduce the body to an automaton acting independently of consciousness.  The difference must necessarily lie in the undetermined part of the behaviour; the part of the behaviour which is undetermined by the fundamental laws of physics must in conscious matter be governed by objective law or direction instead of being wholly a field of chance.  

    The term ``law of chance'' tends to mislead, because it is applied to what is merely an absence of law in the usual sense of the term.  It is clearer to describe the conditions by reference to correlation.  The hypothesis of current physical theory, which is confirmed by observation of inorganic phenomena, is that there is no correlation of the undetermined behaviour of the individual particles.  

    Accordingly the distinction between ordinary matter and conscious matter is that in ordinary matter there is no correlation in the undetermined parts of the behaviours of the particles, whereas in conscious matter correlation may occur.  Such correlation is looked upon as an interference with the ordinary course of nature, due to the association of consciousness with the matter; in other words, it is the physical aspect of a volition.  This does not mean that, in order to execute a volition, consciousness must direct each individual particle in such a way that correlation occurs.  The particles are merely a representation of our knowledge in the frame of thought corresponding to the concept of analysis and the atomic concept.  When we apply the system of analysis which gives this representation, we cannot foresee whether the resulting particles will have correlated or uncorrelated behaviour; that depends entirely on the objective characteristics of whatever it is that we are analysing.  When non-correlation is assumed, as is customary in physics, it is assumed as a hypothesis.  But, without making any hypothesis, we can say that correlation and non-correlation are representations in our frame of thought of different objective characteristics; and since non-correlation admittedly represents the objective characteristic of systems to which the ordinary formulae of physics apply, correlation must represent another objective characteristic which---since it is not characteristic of systems to which the formulae of physics apply---is regarded by us as something ``outside physics''.

    In the discussion of freewill provoked by the modern physical theories, it has, I think, generally been assumed that, since the ordinary laws of inorganic matter leave its behaviour undetermined within a certain narrow range, there can be no scientific objection to allowing a volition of consciousness to decide the exact behaviour within the limits of the aforesaid range.  I will call this hypothesis $A$.  For any system on a molar scale the permitted range is exceedingly small; and very far-fetched suppositions are necessary to enable volition, working in so small a range, to produce large muscular movements.  To obtain a wider range we must admit correlation of the behaviour of the particles.  This is the theory we have been discussing, and will be called hypothesis $B$.  In former writings I have advocated hypothesis $B$ mainly on the ground of the inadequacy of hypothesis $A$; but in the present mode of approach hypothesis $B$ presents itself as the obvious and natural solution.  

    Although leading to the same conclusion, my earlier discussions\footnote{\emph{The Nature of the Physical World}, pp. 310-315.  \emph{New Pathways in Science}, p. 88.} were marred by a failure to recognise that hypothesis $A$ is nonsense; so that I was more apologetic than I need have been for going beyond it.  There is no half-way house between random and correlated behaviour.  Either the behaviour is wholly a matter of chance, in which case the precise behaviour within the Heisenberg limits of uncertainty depends on chance and not on volition.  Or it is not wholly a matter of chance, in which case the Heisenberg limits, which are calculated on the assumption of non-correlation, are irrelevant.  If we apply the law of chance to the tossing of a coin, the number of heads in 1000 throws is undetermined within the limits, say, 450 to 550.  But if a coin-tossing machine is used which picks up and throws the coin not entirely at random, the non-chance element is not a factor deciding which number between 450 and 550 will turn up; a correlation, or systematic tendency in tossing, may produce any number of heads from 0 to 1000.  

    The fallacy of hypothesis $A$ was that it assumed the behaviour to be restricted by the ordinary laws of physics including the hypothesis of non-correlation or ``law of chance'', and then to be further restricted (or decided) by a non-chance factor (volition).  But we cannot suppose the behaviour to be restricted by chance and non-chance (non-correlation and correlation) simultaneously.  The applicability of the law of chance is a hypothesis; the admission that the behaviour is not governed solely by chance denies the hypothesis.  So if we admit volition at all, we must not forget first to remove the hypothesis of chance if we have been applying it; in particular we must drop the Heisenberg limits which apply only to non-correlated behaviour.  If volition operates on the system, it does so without regard to the Heisenberg limits.  Its only limits are those imposed by the fundamental epistemological laws.  

    Our volitions are not entirely unconsequential; so that there must be laws of some kind applying to them and connecting them with other constituents of consciousness, though such laws are not expected to be of the mathematically exact type characteristic of subjective law.  Primarily the sphere of objective law is the interplay of thoughts, emotions, memories and volitions in consciousness.  In controlling volitions objective law controls also the correlations which are the physical counterparts of volitions.  

    Our philosophy has led to the view that in so far as we can separate the subjective and objective elements in our experience, the subjective is to be identified with the physical and the objective with the conscious and spiritual aspects of experience.  To this we now add, as a helpful analogy provided it is not pressed too far, that conscious purpose is the ``matter'' and chance the ``empty space'' of the objective world.  In the physical universe matter occupies only a small region compared with the empty space; but, rightly or wrongly, we look on it as the more significant part.  In the same way we look on consciousness as the significant part of the objective universe, though it appears to occur only in isolated centres in a background of chaos.  \citep[p. 180-184]{Eddington1939}
\end{quote}

\subsection{Probabilities as Structural Objects}

EPISTEMOLOGICAL (Compare to modern Bayesian DOB, Qbism)

Intersubjective, communicable

Convergence?

Convention?

Poincare --> not arbitrary

persistent?  --> uranoid

\subsection{Uranoids}

In some of the most interesting epistemologically sophisticated treatises on the foundations of physics, it is not uncommon to find authors consciously label an important concept for ease of reference as they build and explicate their thoughts.  For context, I am thinking Bohm's notion of rheomode, for example.

\cite{Eddington1939} does something similar with the concept of a uranoid.  It is a word used as shorthand to refer to an important focus point of his structuralist views on the epistemology of physics.  Specifically, it refers to the structure ``that is contemplated as continually existing''.  \citep[p. 166]{Eddington1939}

\subsection{Qbism, Selective Subjectivism, Participatory Realism}

From de Finetti, Ramsey, and subsequently championed by others, the Bayesian interpretation of probabilities holds that probabilities are not frequencies [FISHER?], not propensities [POPPER?], not logically derived [KEYNES?].  Probabilities are \emph{subjective degrees of belief}. Regardless of the manner in which an agent comes to justify their subjective degrees of belief, there are very good reasons why these subjective degrees of belief should, at a minimum, \emph{not} violate the axioms of probability (non-negativity, finite additivity, sum to 1).

Probabilities, under this interpretation, can perhaps be taken as mental conventions that are apparently useful for epistemology, rationality, statistics, and science.  While conventional, that doesn't mean any or all subjective degrees of belief \emph{are} or \emph{should be} arbitrary.  A similar point was made by Poincar\'e in his conventionalist philosophy of mathematics about geometry in particular.  

Quantum Bayesianism, or Qbism for short, tries to think similarly about quantum probabilities.  This is not the place to argue all of the finer points, but suffice to say for present purposes that there are rules for quantum probabilities that seem like more than just conventions or subjective degrees of belief in the way that Bayesian probabilities can be used to characterize uncertainty in other scenarios.  Don't quantum probabilities correspond to something more substantive or lawlike?


\section{Comparing Selective Subjectivism and Participatory Realism}

While perhaps agreeing on the fundamentals, it is striking that Eddington (who I'm using as a caricature for the moment) considers his position to be much more aligned with what he calls ``idealism''.  Perhaps he was unaware of phenomenology or Husserl, but it brings up an important question that it seems to me should also be addressed with newer interpretations in quantum foundations, in particular participatory realism and any connections to the view of quantum probabilities as subjective degrees of belief (Qbism).

What is the proper philosophical context for understanding, is it phenomenology or idealism?  Is it transcendental phenomenological idealism?  Using Husserl as a reference, are we talking about his earlier views or later views where he may have distanced himself from his earlier phenomenology?  I think Michel Bitbol will have some thoughts on this particular point.


\section{Is Idealism Smuggling in Quantum Mysticism?}

NO.

But the ``observer effect'' will need to be sorted out from participatory realism and selective subjectivism etc.

\textbf{This section is very important!}

- spectrum of Berkeley, Solipsism very different from sophisticated transcendental phenomenological idealism of Cassirer or Eddington  

- very many reasons why forms of quantum mysticism are... not correct, and not to be confused with sophisticated philosophical idealism program.  extremely important that we make that clear for a number of reasons, not least to make sure that a major strain in philosophy and philosophy of science is not disregarded and guilty by association






\subsection{Formal Epistemology and the Structure of Physical Experience}

THIS SEEMS OUT OF PLACE

Eddington treats the true or right things about the foundations of physics as epistemological principles, and not statements about an objective external world (realism).  The structures that physicists talk about are more experiential and phenomenological, and \emph{more} normatively compelling than if we supposed they corresponded to realist structures out there in the world.  

Normatively compelling epistemological principles are perhaps the most interesting part of formal epistemology.  For example, in Bayesian epistemology, the axioms of probability theory are normatively compelling for an idealized agent's subjective degrees of belief.  





\section{Weyl}

\subsection{On Open Systems}

Hartmann and Cuffaro papers

Ch. 4 in Weyl collection 

Comments in \cite{Weyl1949} in the context of infinity and the continuum touches on aspects of process philosophy.

\begin{quote}
    Space is infinite not only in the sense that it never comes to an end; but at every place it is, so to speak, inwardly infinite, inasmuch as a point can only be fixed step-by-step by a process of subdivision which progresses \emph{ad infinitum.}  This is in contrast with the resting and complete existence that intuition ascribes to space.  The `open' character is communicated by the continuous space and the continuously graded qualities to the things of the external world.  A real thing can never be given adequately, its `inner horizon' is unfolded by an infinitely continued process of ever new and more exact experiences; it is, as emphasized by Husserl, a limiting idea in the Kantian sense.  For this reason it is impossible to posit the real thing as existing, closed and complete in itself.  The continuum problem thus drives one toward epistemological idealism.  Leibniz, among others, testifies that it was the search for a way out of the ``labyrinth of the continuum'' which first suggested to him the conception of space and time as orders of the phenomena.  ``From the fact that a mathematical solid cannot be resolved into primal elements it follows immediately that it is nothing real but merely an ideal construct designating only a possibility of parts'' (correspondence Leibniz-De Volder, Leibniz, \emph{Philosophische Schriften}, II, p. 268).

    \citep[p. 41]{Weyl1949}
\end{quote}


\subsection{On Quantum Probabilities}

Weyl seems to have a physicalist interpretation of probabilities, which I find odd given the intuitionist and idealist strains in his thought.  See e.g. Appendix C in \citep{Weyl1949}.

But he does say that the formalist (Hilbert) is in line with idealist Kant (p.  64), and so maybe it would make sense to  discuss whether it makes more sense to characterize quantum probabilities as idealist or intuitionist... Have to think about that some more.

In his section on Brouwer's intuitive foundation for mathematics, Weyl 

\begin{quote}
    If I consider an insight a valuable treasure, then the propositional abstract is merely a document indicating the presence of a treasure without disclosing its location.  Its only value may lie in the fact that it causes me to look for the treasure.  It is a worthless piece of paper as long as it is not endorsed by a real proposition such as `2 is an even number.'  Whenever nothing but the \emph{possibility} of a construction is being asserted, we have no meaningful proposition; only by virtue of an effective construction, an executed proof, does an existential statement acquire meaning.  In any of the numerous existential theorems in mathematics, what is valuable in each case is not the theorem as such but the construction carried out in its proof; without it the theorem is an empty shadow.

    \citep[p. 51]{Weyl1949}
\end{quote}

Actually, now that I think about it, Weyl is probably indeed having the position I think he has.  For \emph{pure} mathematics, he will go with constructive intuitionism.  For natural science where the symbols represent some epistemological relationship to an external reality, the symbols \emph{must} be a synthetic combination of ideal and intuitionistic \emph{and also} something transcendental in the external world (e.g. the quantum world).  

If they are synthetic in this way, then indeed one would naturally have to have some kind of ``participatory'' relationship.

Which brings back to Eddington's selective subjectivism, but also Cassirer's analysis in e.g. Cusanus and renaissance philosophy.  

Measurement is like construction in a proof, but it requires an interaction with the world. See p. 65 \citep[p. 65]{Weyl1949}

[IS THAT RIGHT? THINK ABOUT IT SOME MORE]

\begin{quote}
    The stages through which research in the foundations of mathematics has passed in recent times correspond to the three basic possibilities of epistemological attitude.  The set-theoretical approach is the stage of \emph{naive realism} which is unaware of the transition from the given to the transcendent.  Brouwer represents \emph{idealism}, by demanding the reduction of all truth to the intuitively given.  In axiomatic formalism, finally, consciousness makes the attempt to `jump over its own shadow,' to leave behind the stuff of the given, to represent the \emph{transcendent}---but, how could it be otherwise?, only through the \emph{symbol}.  Basically, the idealist viewpoint in epistemology has been adhered to by occidental philosophy since Descartes; nevertheless, it has searched again and again in metaphysics for an access to the realm of the absolute, and Kant, who meant to shoot the bolt once and for all, was yet followed by Fichte, Schelling, and Hegel.  It cannot be denied that a theoretical desire, incomprehensible from the merely phenomenal point of view, is alive in us which urges toward totality. Mathematics shows that with particular clarity; but it also teaches us that that desire can be fulfilled on one condition only, namely, that we are satisfied with the symbol and renounce the mystical error of expecting the transcendent ever to fall within the lighted circle of our intuition.  So far, only in mathematics and physics has symbolical-theoretical construction gained that solidity which makes it compelling for everyone whose mind is open to these sciences.  Their philosophical interest is primarily based on this fact.

    \citep[p. 65-66]{Weyl1949}
\end{quote}

% \section{Autobiography of a Philosopher of Physics}

% [Perhaps this can be used later, but it also helps my memory (and I hope it isn't fabricating anything false...)]

% Like many who have had their eye on the philosophical foundations of quantum mechanics for some time, I have been unsatisfied.  Part of this lack of satisfaction stemmed from realist intuitions, and wanting a visualizable picture of what is going on.  

% To hastily summarize my trajectory, I first read Heisenberg and Bohm's popular treatises aimed towards philosophers.  I found Heisenberg unsatisfying, and Bohm very satisfying.  As luck would have it, my academic journey brought me to Munich in 2012, where, at LMU, an unlikely hold out of Bohmian mechanics had formed around Detlef D\"urr.  I remember a talk he had given early after my arrival at the MCMP, and, if my memory is to be trusted, I remember a brief interaction with Stephan Hartmann (later to be my Ph.D. supervisor) after the talk: Stephan was unconvinced.  Stephan, also a physicist, was to be instrumental in keeping me on my toes as a non-physicist.  

% Yet, I have never been able to shake my intuitions about the foundations.  It should be mentioned that, in my time in Amsterdam (2010-2011), I had read Schlick's \emph{Philosophy of Nature} as well as a peculiar self-published book by a man called Dewey Larson, \emph{The Case Against the Nuclear Atom} where, among other arguments, the author questions what we are actually justified to infer from Rutherford's experiments.






\bibliographystyle{apacite}
\bibliography{nonlocal.bib}



%\end{document}
